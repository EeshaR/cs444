{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Q-Learning ","metadata":{}},{"cell_type":"markdown","source":"Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down.","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/EeshaR/cs444.git","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:34:51.489459Z","iopub.execute_input":"2024-05-01T05:34:51.489779Z","iopub.status.idle":"2024-05-01T05:34:55.069704Z","shell.execute_reply.started":"2024-05-01T05:34:51.489753Z","shell.execute_reply":"2024-05-01T05:34:55.068462Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'cs444'...\nremote: Enumerating objects: 345, done.\u001b[K\nremote: Counting objects: 100% (202/202), done.\u001b[K\nremote: Compressing objects: 100% (202/202), done.\u001b[K\nremote: Total 345 (delta 94), reused 0 (delta 0), pack-reused 143\u001b[K\nReceiving objects: 100% (345/345), 21.29 MiB | 12.83 MiB/s, done.\nResolving deltas: 100% (141/141), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install gym pyvirtualdisplay\n!sudo apt-get install -y xvfb python-opengl ffmpeg","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:34:58.784479Z","iopub.execute_input":"2024-05-01T05:34:58.785277Z","iopub.status.idle":"2024-05-01T05:35:26.156003Z","shell.execute_reply.started":"2024-05-01T05:34:58.785236Z","shell.execute_reply":"2024-05-01T05:35:26.155023Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gym in /opt/conda/lib/python3.10/site-packages (0.26.2)\nCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym) (0.0.8)\nDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\nxvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.17).\nThe following additional packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python2 python2-minimal python2.7 python2.7-minimal\nSuggested packages:\n  python-tk python-numpy libgle3 python2-doc python2.7-doc binfmt-support\nThe following NEW packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python-opengl python2 python2-minimal python2.7\n  python2.7-minimal\n0 upgraded, 10 newly installed, 0 to remove and 65 not upgraded.\nNeed to get 4540 kB of archives.\nAfter this operation, 22.7 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-minimal amd64 2.7.18-1~20.04.4 [335 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7-minimal amd64 2.7.18-1~20.04.4 [1280 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-stdlib amd64 2.7.18-1~20.04.4 [1887 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7 amd64 2.7.18-1~20.04.4 [248 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7072 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libglu1-mesa amd64 9.0.1-1build1 [168 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\nFetched 4540 kB in 2s (2674 kB/s)       \nSelecting previously unselected package libpython2.7-minimal:amd64.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../0-libpython2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2.7-minimal.\nPreparing to unpack .../1-python2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking python2.7-minimal (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2-minimal.\nPreparing to unpack .../2-python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking python2-minimal (2.7.17-2ubuntu4) ...\nSelecting previously unselected package libpython2.7-stdlib:amd64.\nPreparing to unpack .../3-libpython2.7-stdlib_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2.7.\nPreparing to unpack .../4-python2.7_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking python2.7 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package libpython2-stdlib:amd64.\nPreparing to unpack .../5-libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\nSetting up libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\nSetting up python2.7-minimal (2.7.18-1~20.04.4) ...\nLinking and byte-compiling packages for runtime python2.7...\nSetting up python2-minimal (2.7.17-2ubuntu4) ...\nSelecting previously unselected package python2.\n(Reading database ... 114554 files and directories currently installed.)\nPreparing to unpack .../python2_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking python2 (2.7.17-2ubuntu4) ...\nSelecting previously unselected package freeglut3:amd64.\nPreparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\nUnpacking freeglut3:amd64 (2.8.1-3) ...\nSelecting previously unselected package libglu1-mesa:amd64.\nPreparing to unpack .../libglu1-mesa_9.0.1-1build1_amd64.deb ...\nUnpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\nSelecting previously unselected package python-opengl.\nPreparing to unpack .../python-opengl_3.1.0+dfsg-2build1_all.deb ...\nUnpacking python-opengl (3.1.0+dfsg-2build1) ...\nSetting up freeglut3:amd64 (2.8.1-3) ...\nSetting up libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\nSetting up libglu1-mesa:amd64 (9.0.1-1build1) ...\nSetting up python2.7 (2.7.18-1~20.04.4) ...\nSetting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\nSetting up python2 (2.7.17-2ubuntu4) ...\nSetting up python-opengl (3.1.0+dfsg-2build1) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install --upgrade setuptools --user\n!pip3 install ez_setup \n!pip3 install gym[atari] \n!pip3 install gym[accept-rom-license] ","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:35:30.035901Z","iopub.execute_input":"2024-05-01T05:35:30.036853Z","iopub.status.idle":"2024-05-01T05:36:40.064843Z","shell.execute_reply.started":"2024-05-01T05:35:30.036815Z","shell.execute_reply":"2024-05-01T05:36:40.063691Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (69.0.3)\nCollecting setuptools\n  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed setuptools-69.5.1\nCollecting ez_setup\n  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: ez_setup\n  Building wheel for ez_setup (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ez_setup: filename=ez_setup-0.9-py3-none-any.whl size=10995 sha256=96666f0f8249010aa9cbf0bfc6444ac6e7857dcb16ca8c6511edafdab71691f6\n  Stored in directory: /root/.cache/pip/wheels/7a/d6/77/8f495e85fb7df23d41c328b9ea3cf0d9e83631b20bba479293\nSuccessfully built ez_setup\nInstalling collected packages: ez_setup\nSuccessfully installed ez_setup-0.9\nRequirement already satisfied: gym[atari] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (0.0.8)\nCollecting ale-py~=0.8.0 (from gym[atari])\n  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.0->gym[atari]) (6.1.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.0->gym[atari]) (4.9.0)\nDownloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py\nSuccessfully installed ale-py-0.8.1\nRequirement already satisfied: gym[accept-rom-license] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (0.0.8)\nCollecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (8.1.7)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (4.66.1)\nCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2024.2.2)\nDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: AutoROM.accept-rom-license\n  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=a8139a851e06c36dd804ab2b49b8ef84954ce36c7fa09e2dc4d61957d97500fa\n  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\nSuccessfully built AutoROM.accept-rom-license\nInstalling collected packages: AutoROM.accept-rom-license, autorom\nSuccessfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__.","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport sys\n\n# Add the path to the directory containing the `gan` package to sys.path\nsys.path.append('/kaggle/working/cs444/assignment5')\n\nimport sys\nimport gym\nimport torch\nimport pylab\nimport random\nimport numpy as np\nfrom collections import deque\nfrom datetime import datetime\nfrom copy import deepcopy\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom utils import find_max_lives, check_live, get_frame, get_init_state\nfrom model import DQN, DQN_LSTM\nfrom config import *\n\nimport matplotlib.pyplot as plt\n# %load_ext autoreload\n# %autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:36:48.220250Z","iopub.execute_input":"2024-05-01T05:36:48.220629Z","iopub.status.idle":"2024-05-01T05:36:52.485956Z","shell.execute_reply.started":"2024-05-01T05:36:48.220595Z","shell.execute_reply":"2024-05-01T05:36:52.485166Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the environment","metadata":{}},{"cell_type":"markdown","source":"In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n\nIn breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right.","metadata":{}},{"cell_type":"code","source":"env = gym.make('BreakoutDeterministic-v4')\nstate = env.reset()","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:37:03.248288Z","iopub.execute_input":"2024-05-01T05:37:03.248751Z","iopub.status.idle":"2024-05-01T05:37:03.592844Z","shell.execute_reply.started":"2024-05-01T05:37:03.248722Z","shell.execute_reply":"2024-05-01T05:37:03.591840Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n[Powered by Stella]\n","output_type":"stream"}]},{"cell_type":"code","source":"number_lives = find_max_lives(env)\nstate_size = env.observation_space.shape\naction_size = 3 #fire, left, and right","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:37:05.898908Z","iopub.execute_input":"2024-05-01T05:37:05.899316Z","iopub.status.idle":"2024-05-01T05:37:05.920086Z","shell.execute_reply.started":"2024-05-01T05:37:05.899283Z","shell.execute_reply":"2024-05-01T05:37:05.919201Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n  if not isinstance(terminated, (bool, np.bool8)):\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating a DQN Agent","metadata":{}},{"cell_type":"markdown","source":"Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n\n__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n\n__Frame__ : Number of frames processed in total.\n\n__Memory Size__ : The current size of the replay memory.","metadata":{}},{"cell_type":"code","source":"double_dqn = False # set to True if using double DQN agent\n\nif double_dqn:\n    from agent_double import Agent\nelse:\n    from agent import Agent\n\nagent = Agent(action_size)\nevaluation_reward = deque(maxlen=evaluation_reward_length)\nframe = 0\nmemory_size = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-01T05:37:09.428303Z","iopub.execute_input":"2024-05-01T05:37:09.428671Z","iopub.status.idle":"2024-05-01T05:37:11.942940Z","shell.execute_reply.started":"2024-05-01T05:37:09.428640Z","shell.execute_reply":"2024-05-01T05:37:11.942116Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Main Training Loop","metadata":{}},{"cell_type":"markdown","source":"In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\"","metadata":{}},{"cell_type":"code","source":"import os\n\n# Create the directory for saving graphs if it does not exist\nif not os.path.exists(\"./save_graph\"):\n    os.makedirs(\"./save_graph\")\n    \nif not os.path.exists(\"./save_model\"):\n    os.makedirs(\"./save_model\")\n\nrewards, episodes = [], []\nbest_eval_reward = 0\n\nfor e in range(EPISODES):\n    done = False\n    score = 0\n\n    history = np.zeros([5, 84, 84], dtype=np.uint8)\n    step = 0\n    state, _ = env.reset()\n    next_state = state\n    life = number_lives\n\n    get_init_state(history, state, HISTORY_SIZE)\n\n    while not done:\n        step += 1\n        frame += 1\n\n        # Perform a fire action if ball is no longer on screen to continue onto next life\n        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n            action = torch.tensor([[0]]).cuda()\n        else:\n            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n        state = next_state\n        \n        # next_state, reward, done, _, info = env.step(action + 1)\n        next_state, reward, terminated, truncated, info = env.step(action + 1)\n        done = terminated or truncated\n\n        frame_next_state = get_frame(next_state)\n        history[4, :, :] = frame_next_state\n        terminal_state = check_live(life, info['lives'])\n\n        life = info['lives']\n        r = reward\n\n        # Store the transition in memory \n        agent.memory.push(deepcopy(frame_next_state), action.cpu(), r, terminal_state)\n        # Start training after random sample generation\n        if(frame >= train_frame): # You can set train_frame to a lower value while testing your starts training earlier\n            agent.train_policy_net(frame)\n            # Update the target network only for Double DQN only\n            if double_dqn and (frame % update_target_network_frequency)== 0:\n                agent.update_target_net()\n        score += reward\n        history[:4, :, :] = history[1:, :, :]\n            \n        if done:\n            evaluation_reward.append(score)\n            rewards.append(np.mean(evaluation_reward))\n            episodes.append(e)\n            pylab.plot(episodes, rewards, 'b')\n            pylab.xlabel('Episodes')\n            pylab.ylabel('Rewards') \n            pylab.title('Episodes vs Reward')\n            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n            \n            # every episode, plot the play time\n            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n\n            # if the mean of scores of last 100 episode is bigger than 5 save model\n            ### Change this save condition to whatever you prefer ###\n            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n                best_eval_reward = np.mean(evaluation_reward)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-01T05:37:15.019474Z","iopub.execute_input":"2024-05-01T05:37:15.019981Z","iopub.status.idle":"2024-05-01T17:26:32.894408Z","shell.execute_reply.started":"2024-05-01T05:37:15.019951Z","shell.execute_reply":"2024-05-01T17:26:32.881158Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"episode: 0   score: 4.0   memory length: 295   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 4.0\nepisode: 1   score: 3.0   memory length: 560   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 3.5\nepisode: 2   score: 2.0   memory length: 758   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 3.0\nepisode: 3   score: 0.0   memory length: 881   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.25\nepisode: 4   score: 0.0   memory length: 1004   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8\nepisode: 5   score: 2.0   memory length: 1225   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.8333333333333333\nepisode: 6   score: 2.0   memory length: 1422   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.8571428571428572\nepisode: 7   score: 0.0   memory length: 1545   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.625\nepisode: 8   score: 1.0   memory length: 1713   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5555555555555556\nepisode: 9   score: 0.0   memory length: 1836   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 10   score: 0.0   memory length: 1959   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2727272727272727\nepisode: 11   score: 2.0   memory length: 2157   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3333333333333333\nepisode: 12   score: 2.0   memory length: 2355   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3846153846153846\nepisode: 13   score: 0.0   memory length: 2478   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2857142857142858\nepisode: 14   score: 4.0   memory length: 2752   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.4666666666666666\nepisode: 15   score: 0.0   memory length: 2875   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.375\nepisode: 16   score: 2.0   memory length: 3094   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.411764705882353\nepisode: 17   score: 0.0   memory length: 3216   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3333333333333333\nepisode: 18   score: 1.0   memory length: 3366   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.3157894736842106\nepisode: 19   score: 0.0   memory length: 3488   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.25\nepisode: 20   score: 0.0   memory length: 3610   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.1904761904761905\nepisode: 21   score: 0.0   memory length: 3732   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.1363636363636365\nepisode: 22   score: 3.0   memory length: 3979   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.2173913043478262\nepisode: 23   score: 1.0   memory length: 4149   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.2083333333333333\nepisode: 24   score: 1.0   memory length: 4301   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2\nepisode: 25   score: 2.0   memory length: 4499   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.2307692307692308\nepisode: 26   score: 1.0   memory length: 4668   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.2222222222222223\nepisode: 27   score: 0.0   memory length: 4791   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1785714285714286\nepisode: 28   score: 0.0   memory length: 4914   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1379310344827587\nepisode: 29   score: 0.0   memory length: 5037   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1\nepisode: 30   score: 2.0   memory length: 5236   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.1290322580645162\nepisode: 31   score: 1.0   memory length: 5404   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.125\nepisode: 32   score: 2.0   memory length: 5602   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.1515151515151516\nepisode: 33   score: 2.0   memory length: 5820   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.1764705882352942\nepisode: 34   score: 0.0   memory length: 5943   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1428571428571428\nepisode: 35   score: 0.0   memory length: 6066   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1111111111111112\nepisode: 36   score: 1.0   memory length: 6235   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.1081081081081081\nepisode: 37   score: 2.0   memory length: 6455   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.131578947368421\nepisode: 38   score: 3.0   memory length: 6720   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.1794871794871795\nepisode: 39   score: 3.0   memory length: 6988   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.225\nepisode: 40   score: 2.0   memory length: 7189   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.2439024390243902\nepisode: 41   score: 2.0   memory length: 7386   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.2619047619047619\nepisode: 42   score: 5.0   memory length: 7692   epsilon: 1.0    steps: 306    lr: 0.0001     evaluation reward: 1.3488372093023255\nepisode: 43   score: 2.0   memory length: 7889   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.3636363636363635\nepisode: 44   score: 4.0   memory length: 8184   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.4222222222222223\nepisode: 45   score: 2.0   memory length: 8381   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.434782608695652\nepisode: 46   score: 4.0   memory length: 8679   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.4893617021276595\nepisode: 47   score: 6.0   memory length: 9077   epsilon: 1.0    steps: 398    lr: 0.0001     evaluation reward: 1.5833333333333333\nepisode: 48   score: 3.0   memory length: 9345   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.6122448979591837\nepisode: 49   score: 0.0   memory length: 9468   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 50   score: 1.0   memory length: 9636   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5686274509803921\nepisode: 51   score: 2.0   memory length: 9859   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.5769230769230769\nepisode: 52   score: 1.0   memory length: 10030   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5660377358490567\nepisode: 53   score: 0.0   memory length: 10152   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.537037037037037\nepisode: 54   score: 1.0   memory length: 10303   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5272727272727273\nepisode: 55   score: 4.0   memory length: 10599   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.5714285714285714\nepisode: 56   score: 3.0   memory length: 10845   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5964912280701755\nepisode: 57   score: 0.0   memory length: 10967   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5689655172413792\nepisode: 58   score: 1.0   memory length: 11136   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5593220338983051\nepisode: 59   score: 9.0   memory length: 11649   epsilon: 1.0    steps: 513    lr: 0.0001     evaluation reward: 1.6833333333333333\nepisode: 60   score: 2.0   memory length: 11865   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.6885245901639345\nepisode: 61   score: 0.0   memory length: 11987   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6612903225806452\nepisode: 62   score: 1.0   memory length: 12159   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.6507936507936507\nepisode: 63   score: 1.0   memory length: 12328   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.640625\nepisode: 64   score: 1.0   memory length: 12479   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6307692307692307\nepisode: 65   score: 1.0   memory length: 12629   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.621212121212121\nepisode: 66   score: 2.0   memory length: 12827   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.626865671641791\nepisode: 67   score: 2.0   memory length: 13024   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.6323529411764706\nepisode: 68   score: 3.0   memory length: 13253   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.6521739130434783\nepisode: 69   score: 3.0   memory length: 13481   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.6714285714285715\nepisode: 70   score: 1.0   memory length: 13651   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6619718309859155\nepisode: 71   score: 2.0   memory length: 13848   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.6666666666666667\nepisode: 72   score: 0.0   memory length: 13970   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.643835616438356\nepisode: 73   score: 0.0   memory length: 14092   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6216216216216217\nepisode: 74   score: 0.0   memory length: 14214   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 75   score: 4.0   memory length: 14491   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.631578947368421\nepisode: 76   score: 1.0   memory length: 14660   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6233766233766234\nepisode: 77   score: 2.0   memory length: 14844   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.6282051282051282\nepisode: 78   score: 3.0   memory length: 15087   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.6455696202531647\nepisode: 79   score: 2.0   memory length: 15285   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 80   score: 0.0   memory length: 15408   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6296296296296295\nepisode: 81   score: 0.0   memory length: 15530   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6097560975609757\nepisode: 82   score: 1.0   memory length: 15698   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6024096385542168\nepisode: 83   score: 2.0   memory length: 15899   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.6071428571428572\nepisode: 84   score: 1.0   memory length: 16067   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6\nepisode: 85   score: 4.0   memory length: 16344   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.627906976744186\nepisode: 86   score: 1.0   memory length: 16512   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6206896551724137\nepisode: 87   score: 1.0   memory length: 16682   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6136363636363635\nepisode: 88   score: 0.0   memory length: 16804   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.595505617977528\nepisode: 89   score: 2.0   memory length: 17004   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6\nepisode: 90   score: 0.0   memory length: 17127   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5824175824175823\nepisode: 91   score: 0.0   memory length: 17249   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.565217391304348\nepisode: 92   score: 5.0   memory length: 17557   epsilon: 1.0    steps: 308    lr: 0.0001     evaluation reward: 1.6021505376344085\nepisode: 93   score: 1.0   memory length: 17708   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5957446808510638\nepisode: 94   score: 2.0   memory length: 17926   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6\nepisode: 95   score: 1.0   memory length: 18095   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59375\nepisode: 96   score: 1.0   memory length: 18264   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5876288659793814\nepisode: 97   score: 3.0   memory length: 18508   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.6020408163265305\nepisode: 98   score: 1.0   memory length: 18679   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.595959595959596\nepisode: 99   score: 0.0   memory length: 18802   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 100   score: 1.0   memory length: 18974   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.55\nepisode: 101   score: 2.0   memory length: 19171   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 102   score: 0.0   memory length: 19294   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 103   score: 1.0   memory length: 19463   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 104   score: 2.0   memory length: 19661   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\nepisode: 105   score: 1.0   memory length: 19812   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.54\nepisode: 106   score: 0.0   memory length: 19935   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 107   score: 2.0   memory length: 20133   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\nepisode: 108   score: 1.0   memory length: 20304   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.54\nepisode: 109   score: 3.0   memory length: 20551   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.57\nepisode: 110   score: 0.0   memory length: 20674   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 111   score: 0.0   memory length: 20796   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.55\nepisode: 112   score: 0.0   memory length: 20919   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 113   score: 1.0   memory length: 21090   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.54\nepisode: 114   score: 2.0   memory length: 21288   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\nepisode: 115   score: 3.0   memory length: 21555   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.55\nepisode: 116   score: 3.0   memory length: 21818   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.56\nepisode: 117   score: 3.0   memory length: 22063   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.59\nepisode: 118   score: 0.0   memory length: 22186   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 119   score: 2.0   memory length: 22383   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.6\nepisode: 120   score: 1.0   memory length: 22553   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\nepisode: 121   score: 2.0   memory length: 22751   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.63\nepisode: 122   score: 0.0   memory length: 22874   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 123   score: 2.0   memory length: 23072   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.61\nepisode: 124   score: 1.0   memory length: 23223   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 125   score: 2.0   memory length: 23426   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.61\nepisode: 126   score: 3.0   memory length: 23653   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.63\nepisode: 127   score: 0.0   memory length: 23775   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.63\nepisode: 128   score: 3.0   memory length: 24022   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.66\nepisode: 129   score: 0.0   memory length: 24145   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\nepisode: 130   score: 0.0   memory length: 24268   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 131   score: 2.0   memory length: 24466   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 132   score: 2.0   memory length: 24665   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.65\nepisode: 133   score: 2.0   memory length: 24863   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 134   score: 2.0   memory length: 25043   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.67\nepisode: 135   score: 0.0   memory length: 25166   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 136   score: 3.0   memory length: 25415   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.69\nepisode: 137   score: 3.0   memory length: 25678   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.7\nepisode: 138   score: 2.0   memory length: 25898   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.69\nepisode: 139   score: 4.0   memory length: 26172   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.7\nepisode: 140   score: 1.0   memory length: 26323   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.69\nepisode: 141   score: 2.0   memory length: 26521   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\nepisode: 142   score: 1.0   memory length: 26691   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.65\nepisode: 143   score: 0.0   memory length: 26814   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 144   score: 1.0   memory length: 26965   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6\nepisode: 145   score: 1.0   memory length: 27134   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 146   score: 2.0   memory length: 27334   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.57\nepisode: 147   score: 4.0   memory length: 27630   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.55\nepisode: 148   score: 0.0   memory length: 27752   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 149   score: 0.0   memory length: 27874   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 150   score: 2.0   memory length: 28071   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.53\nepisode: 151   score: 7.0   memory length: 28492   epsilon: 1.0    steps: 421    lr: 0.0001     evaluation reward: 1.58\nepisode: 152   score: 0.0   memory length: 28615   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 153   score: 3.0   memory length: 28845   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.6\nepisode: 154   score: 1.0   memory length: 29015   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6\nepisode: 155   score: 2.0   memory length: 29232   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.58\nepisode: 156   score: 2.0   memory length: 29449   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.57\nepisode: 157   score: 1.0   memory length: 29618   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\nepisode: 158   score: 1.0   memory length: 29769   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 159   score: 2.0   memory length: 29968   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.51\nepisode: 160   score: 0.0   memory length: 30091   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 161   score: 1.0   memory length: 30260   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\nepisode: 162   score: 1.0   memory length: 30411   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\nepisode: 163   score: 1.0   memory length: 30581   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5\nepisode: 164   score: 0.0   memory length: 30704   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 165   score: 1.0   memory length: 30873   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 166   score: 0.0   memory length: 30996   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 167   score: 2.0   memory length: 31194   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\nepisode: 168   score: 1.0   memory length: 31365   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.45\nepisode: 169   score: 1.0   memory length: 31517   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.43\nepisode: 170   score: 0.0   memory length: 31639   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 171   score: 1.0   memory length: 31810   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.41\nepisode: 172   score: 3.0   memory length: 32053   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.44\nepisode: 173   score: 3.0   memory length: 32318   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.47\nepisode: 174   score: 1.0   memory length: 32469   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\nepisode: 175   score: 0.0   memory length: 32592   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 176   score: 0.0   memory length: 32715   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 177   score: 1.0   memory length: 32884   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 178   score: 1.0   memory length: 33056   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.4\nepisode: 179   score: 2.0   memory length: 33256   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.4\nepisode: 180   score: 2.0   memory length: 33454   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\nepisode: 181   score: 0.0   memory length: 33576   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 182   score: 1.0   memory length: 33727   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\nepisode: 183   score: 1.0   memory length: 33899   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.41\nepisode: 184   score: 1.0   memory length: 34050   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\nepisode: 185   score: 3.0   memory length: 34294   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.4\nepisode: 186   score: 2.0   memory length: 34491   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.41\nepisode: 187   score: 1.0   memory length: 34660   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 188   score: 2.0   memory length: 34879   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.43\nepisode: 189   score: 2.0   memory length: 35078   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.43\nepisode: 190   score: 2.0   memory length: 35275   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\nepisode: 191   score: 1.0   memory length: 35427   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.46\nepisode: 192   score: 0.0   memory length: 35550   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 193   score: 1.0   memory length: 35700   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.41\nepisode: 194   score: 2.0   memory length: 35898   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\nepisode: 195   score: 0.0   memory length: 36021   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 196   score: 2.0   memory length: 36242   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.41\nepisode: 197   score: 1.0   memory length: 36411   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\nepisode: 198   score: 0.0   memory length: 36533   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\nepisode: 199   score: 1.0   memory length: 36702   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\nepisode: 200   score: 1.0   memory length: 36852   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.39\nepisode: 201   score: 1.0   memory length: 37021   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.38\nepisode: 202   score: 1.0   memory length: 37171   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.39\nepisode: 203   score: 0.0   memory length: 37294   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 204   score: 0.0   memory length: 37417   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\nepisode: 205   score: 0.0   memory length: 37540   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 206   score: 0.0   memory length: 37663   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 207   score: 3.0   memory length: 37909   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.36\nepisode: 208   score: 0.0   memory length: 38031   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\nepisode: 209   score: 3.0   memory length: 38275   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.35\nepisode: 210   score: 3.0   memory length: 38543   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.38\nepisode: 211   score: 2.0   memory length: 38760   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\nepisode: 212   score: 0.0   memory length: 38883   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 213   score: 1.0   memory length: 39034   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\nepisode: 214   score: 1.0   memory length: 39185   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\nepisode: 215   score: 2.0   memory length: 39382   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.38\nepisode: 216   score: 2.0   memory length: 39580   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\nepisode: 217   score: 2.0   memory length: 39778   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.36\nepisode: 218   score: 1.0   memory length: 39929   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\nepisode: 219   score: 3.0   memory length: 40175   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.38\nepisode: 220   score: 1.0   memory length: 40325   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.38\nepisode: 221   score: 0.0   memory length: 40447   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.36\nepisode: 222   score: 2.0   memory length: 40665   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.38\nepisode: 223   score: 2.0   memory length: 40884   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.38\nepisode: 224   score: 1.0   memory length: 41035   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.38\nepisode: 225   score: 2.0   memory length: 41216   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.38\nepisode: 226   score: 1.0   memory length: 41366   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.36\nepisode: 227   score: 2.0   memory length: 41565   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.38\nepisode: 228   score: 2.0   memory length: 41762   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.37\nepisode: 229   score: 1.0   memory length: 41912   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.38\nepisode: 230   score: 3.0   memory length: 42160   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.41\nepisode: 231   score: 3.0   memory length: 42409   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.42\nepisode: 232   score: 4.0   memory length: 42701   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.44\nepisode: 233   score: 2.0   memory length: 42900   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.44\nepisode: 234   score: 1.0   memory length: 43069   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\nepisode: 235   score: 3.0   memory length: 43316   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.46\nepisode: 236   score: 1.0   memory length: 43487   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.44\nepisode: 237   score: 0.0   memory length: 43610   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 238   score: 2.0   memory length: 43809   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.41\nepisode: 239   score: 2.0   memory length: 44008   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\nepisode: 240   score: 3.0   memory length: 44254   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.41\nepisode: 241   score: 1.0   memory length: 44405   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\nepisode: 242   score: 4.0   memory length: 44677   epsilon: 1.0    steps: 272    lr: 0.0001     evaluation reward: 1.43\nepisode: 243   score: 0.0   memory length: 44799   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 244   score: 0.0   memory length: 44922   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 245   score: 4.0   memory length: 45201   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.45\nepisode: 246   score: 2.0   memory length: 45398   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\nepisode: 247   score: 4.0   memory length: 45689   epsilon: 1.0    steps: 291    lr: 0.0001     evaluation reward: 1.45\nepisode: 248   score: 1.0   memory length: 45857   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.46\nepisode: 249   score: 1.0   memory length: 46009   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.47\nepisode: 250   score: 1.0   memory length: 46180   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.46\nepisode: 251   score: 0.0   memory length: 46303   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 252   score: 3.0   memory length: 46570   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.42\nepisode: 253   score: 0.0   memory length: 46693   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 254   score: 1.0   memory length: 46863   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\nepisode: 255   score: 1.0   memory length: 47031   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.38\nepisode: 256   score: 3.0   memory length: 47298   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.39\nepisode: 257   score: 0.0   memory length: 47420   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\nepisode: 258   score: 0.0   memory length: 47542   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 259   score: 2.0   memory length: 47760   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.37\nepisode: 260   score: 9.0   memory length: 48134   epsilon: 1.0    steps: 374    lr: 0.0001     evaluation reward: 1.46\nepisode: 261   score: 1.0   memory length: 48303   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 262   score: 4.0   memory length: 48581   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.49\nepisode: 263   score: 1.0   memory length: 48733   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.49\nepisode: 264   score: 0.0   memory length: 48856   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 265   score: 0.0   memory length: 48979   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 266   score: 1.0   memory length: 49151   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.49\nepisode: 267   score: 3.0   memory length: 49397   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5\nepisode: 268   score: 0.0   memory length: 49519   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\nepisode: 269   score: 3.0   memory length: 49788   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.51\nepisode: 270   score: 0.0   memory length: 49911   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 271   score: 1.0   memory length: 50081   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.51\nepisode: 272   score: 4.0   memory length: 50356   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.52\nepisode: 273   score: 0.0   memory length: 50479   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 274   score: 0.0   memory length: 50601   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 275   score: 4.0   memory length: 50879   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.52\nepisode: 276   score: 0.0   memory length: 51002   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 277   score: 3.0   memory length: 51245   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.54\nepisode: 278   score: 2.0   memory length: 51442   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.55\nepisode: 279   score: 2.0   memory length: 51645   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.55\nepisode: 280   score: 0.0   memory length: 51767   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 281   score: 2.0   memory length: 51949   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.55\nepisode: 282   score: 0.0   memory length: 52072   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 283   score: 0.0   memory length: 52195   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 284   score: 2.0   memory length: 52411   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.54\nepisode: 285   score: 2.0   memory length: 52634   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.53\nepisode: 286   score: 0.0   memory length: 52757   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 287   score: 0.0   memory length: 52879   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\nepisode: 288   score: 1.0   memory length: 53030   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 289   score: 3.0   memory length: 53256   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.5\nepisode: 290   score: 2.0   memory length: 53456   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.5\nepisode: 291   score: 0.0   memory length: 53579   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 292   score: 2.0   memory length: 53777   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\nepisode: 293   score: 2.0   memory length: 53974   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.52\nepisode: 294   score: 1.0   memory length: 54143   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\nepisode: 295   score: 4.0   memory length: 54436   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.55\nepisode: 296   score: 2.0   memory length: 54652   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.55\nepisode: 297   score: 1.0   memory length: 54821   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.55\nepisode: 298   score: 2.0   memory length: 55018   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.57\nepisode: 299   score: 1.0   memory length: 55169   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\nepisode: 300   score: 0.0   memory length: 55292   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 301   score: 1.0   memory length: 55443   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\nepisode: 302   score: 0.0   memory length: 55566   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 303   score: 3.0   memory length: 55792   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.58\nepisode: 304   score: 0.0   memory length: 55914   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 305   score: 1.0   memory length: 56065   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.59\nepisode: 306   score: 0.0   memory length: 56188   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 307   score: 2.0   memory length: 56385   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.58\nepisode: 308   score: 0.0   memory length: 56507   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 309   score: 1.0   memory length: 56658   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\nepisode: 310   score: 1.0   memory length: 56826   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.54\nepisode: 311   score: 2.0   memory length: 57023   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 312   score: 0.0   memory length: 57145   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\nepisode: 313   score: 1.0   memory length: 57314   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.54\nepisode: 314   score: 0.0   memory length: 57436   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 315   score: 2.0   memory length: 57633   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.53\nepisode: 316   score: 0.0   memory length: 57756   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 317   score: 0.0   memory length: 57878   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\nepisode: 318   score: 1.0   memory length: 58029   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 319   score: 1.0   memory length: 58198   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.47\nepisode: 320   score: 2.0   memory length: 58416   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.48\nepisode: 321   score: 1.0   memory length: 58586   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.49\nepisode: 322   score: 3.0   memory length: 58858   epsilon: 1.0    steps: 272    lr: 0.0001     evaluation reward: 1.5\nepisode: 323   score: 0.0   memory length: 58981   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 324   score: 2.0   memory length: 59199   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.49\nepisode: 325   score: 2.0   memory length: 59397   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 326   score: 1.0   memory length: 59566   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 327   score: 1.0   memory length: 59716   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.48\nepisode: 328   score: 0.0   memory length: 59838   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\nepisode: 329   score: 0.0   memory length: 59960   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.45\nepisode: 330   score: 2.0   memory length: 60158   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\nepisode: 331   score: 3.0   memory length: 60425   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.44\nepisode: 332   score: 1.0   memory length: 60594   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 333   score: 1.0   memory length: 60747   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.4\nepisode: 334   score: 1.0   memory length: 60919   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.4\nepisode: 335   score: 1.0   memory length: 61090   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.38\nepisode: 336   score: 0.0   memory length: 61212   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 337   score: 7.0   memory length: 61532   epsilon: 1.0    steps: 320    lr: 0.0001     evaluation reward: 1.44\nepisode: 338   score: 0.0   memory length: 61655   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 339   score: 0.0   memory length: 61778   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 340   score: 3.0   memory length: 62043   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.4\nepisode: 341   score: 2.0   memory length: 62241   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\nepisode: 342   score: 2.0   memory length: 62438   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.39\nepisode: 343   score: 0.0   memory length: 62560   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\nepisode: 344   score: 2.0   memory length: 62776   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.41\nepisode: 345   score: 0.0   memory length: 62898   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 346   score: 4.0   memory length: 63179   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.39\nepisode: 347   score: 0.0   memory length: 63302   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 348   score: 2.0   memory length: 63481   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.36\nepisode: 349   score: 2.0   memory length: 63678   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.37\nepisode: 350   score: 0.0   memory length: 63800   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.36\nepisode: 351   score: 0.0   memory length: 63923   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\nepisode: 352   score: 1.0   memory length: 64074   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.34\nepisode: 353   score: 1.0   memory length: 64244   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\nepisode: 354   score: 3.0   memory length: 64453   epsilon: 1.0    steps: 209    lr: 0.0001     evaluation reward: 1.37\nepisode: 355   score: 1.0   memory length: 64622   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.37\nepisode: 356   score: 1.0   memory length: 64793   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.35\nepisode: 357   score: 5.0   memory length: 65110   epsilon: 1.0    steps: 317    lr: 0.0001     evaluation reward: 1.4\nepisode: 358   score: 4.0   memory length: 65387   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.44\nepisode: 359   score: 0.0   memory length: 65509   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 360   score: 1.0   memory length: 65677   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.34\nepisode: 361   score: 1.0   memory length: 65828   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.34\nepisode: 362   score: 3.0   memory length: 66054   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.33\nepisode: 363   score: 1.0   memory length: 66205   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.33\nepisode: 364   score: 0.0   memory length: 66328   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\nepisode: 365   score: 1.0   memory length: 66478   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.34\nepisode: 366   score: 3.0   memory length: 66704   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.36\nepisode: 367   score: 3.0   memory length: 66968   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.36\nepisode: 368   score: 2.0   memory length: 67166   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\nepisode: 369   score: 2.0   memory length: 67364   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\nepisode: 370   score: 1.0   memory length: 67533   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.38\nepisode: 371   score: 5.0   memory length: 67880   epsilon: 1.0    steps: 347    lr: 0.0001     evaluation reward: 1.42\nepisode: 372   score: 2.0   memory length: 68077   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4\nepisode: 373   score: 1.0   memory length: 68246   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 374   score: 1.0   memory length: 68397   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\nepisode: 375   score: 1.0   memory length: 68548   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\nepisode: 376   score: 3.0   memory length: 68763   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.42\nepisode: 377   score: 2.0   memory length: 68981   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\nepisode: 378   score: 1.0   memory length: 69132   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\nepisode: 379   score: 2.0   memory length: 69329   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4\nepisode: 380   score: 1.0   memory length: 69480   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\nepisode: 381   score: 2.0   memory length: 69698   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\nepisode: 382   score: 3.0   memory length: 69964   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.44\nepisode: 383   score: 3.0   memory length: 70212   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.47\nepisode: 384   score: 2.0   memory length: 70429   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.47\nepisode: 385   score: 3.0   memory length: 70675   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.48\nepisode: 386   score: 0.0   memory length: 70797   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 387   score: 2.0   memory length: 71015   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\nepisode: 388   score: 1.0   memory length: 71186   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\nepisode: 389   score: 3.0   memory length: 71450   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.5\nepisode: 390   score: 1.0   memory length: 71601   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 391   score: 0.0   memory length: 71724   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 392   score: 2.0   memory length: 71943   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\nepisode: 393   score: 0.0   memory length: 72066   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 394   score: 3.0   memory length: 72313   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.49\nepisode: 395   score: 1.0   memory length: 72481   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.46\nepisode: 396   score: 3.0   memory length: 72731   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.47\nepisode: 397   score: 2.0   memory length: 72948   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.48\nepisode: 398   score: 1.0   memory length: 73098   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.47\nepisode: 399   score: 3.0   memory length: 73327   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.49\nepisode: 400   score: 2.0   memory length: 73543   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.51\nepisode: 401   score: 0.0   memory length: 73666   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 402   score: 1.0   memory length: 73817   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.51\nepisode: 403   score: 1.0   memory length: 73986   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 404   score: 0.0   memory length: 74109   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 405   score: 1.0   memory length: 74260   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 406   score: 2.0   memory length: 74480   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.51\nepisode: 407   score: 1.0   memory length: 74649   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\nepisode: 408   score: 2.0   memory length: 74865   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.52\nepisode: 409   score: 1.0   memory length: 75034   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\nepisode: 410   score: 0.0   memory length: 75157   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 411   score: 2.0   memory length: 75355   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\nepisode: 412   score: 4.0   memory length: 75633   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.55\nepisode: 413   score: 2.0   memory length: 75830   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.56\nepisode: 414   score: 4.0   memory length: 76123   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.6\nepisode: 415   score: 4.0   memory length: 76420   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.62\nepisode: 416   score: 1.0   memory length: 76590   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.63\nepisode: 417   score: 2.0   memory length: 76771   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.65\nepisode: 418   score: 1.0   memory length: 76922   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.65\nepisode: 419   score: 2.0   memory length: 77119   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.66\nepisode: 420   score: 3.0   memory length: 77365   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.67\nepisode: 421   score: 0.0   memory length: 77488   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\nepisode: 422   score: 4.0   memory length: 77777   epsilon: 1.0    steps: 289    lr: 0.0001     evaluation reward: 1.67\nepisode: 423   score: 3.0   memory length: 78028   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.7\nepisode: 424   score: 3.0   memory length: 78256   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.71\nepisode: 425   score: 0.0   memory length: 78378   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.69\nepisode: 426   score: 2.0   memory length: 78593   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.7\nepisode: 427   score: 3.0   memory length: 78839   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.72\nepisode: 428   score: 0.0   memory length: 78962   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.72\nepisode: 429   score: 0.0   memory length: 79085   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.72\nepisode: 430   score: 1.0   memory length: 79256   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.71\nepisode: 431   score: 0.0   memory length: 79379   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\nepisode: 432   score: 1.0   memory length: 79548   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.68\nepisode: 433   score: 2.0   memory length: 79746   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\nepisode: 434   score: 0.0   memory length: 79869   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\nepisode: 435   score: 2.0   memory length: 80085   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.69\nepisode: 436   score: 0.0   memory length: 80208   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.69\nepisode: 437   score: 4.0   memory length: 80503   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.66\nepisode: 438   score: 0.0   memory length: 80625   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.66\nepisode: 439   score: 1.0   memory length: 80793   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.67\nepisode: 440   score: 6.0   memory length: 81187   epsilon: 1.0    steps: 394    lr: 0.0001     evaluation reward: 1.7\nepisode: 441   score: 1.0   memory length: 81356   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.69\nepisode: 442   score: 0.0   memory length: 81479   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 443   score: 1.0   memory length: 81648   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.68\nepisode: 444   score: 1.0   memory length: 81816   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.67\nepisode: 445   score: 2.0   memory length: 82013   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.69\nepisode: 446   score: 2.0   memory length: 82230   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.67\nepisode: 447   score: 0.0   memory length: 82353   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 448   score: 0.0   memory length: 82476   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\nepisode: 449   score: 1.0   memory length: 82644   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.64\nepisode: 450   score: 2.0   memory length: 82842   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\nepisode: 451   score: 2.0   memory length: 83040   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.68\nepisode: 452   score: 2.0   memory length: 83241   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.69\nepisode: 453   score: 2.0   memory length: 83441   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.7\nepisode: 454   score: 0.0   memory length: 83564   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 455   score: 2.0   memory length: 83762   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.68\nepisode: 456   score: 3.0   memory length: 84013   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.7\nepisode: 457   score: 1.0   memory length: 84164   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\nepisode: 458   score: 0.0   memory length: 84286   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.62\nepisode: 459   score: 4.0   memory length: 84564   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.66\nepisode: 460   score: 1.0   memory length: 84733   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.66\nepisode: 461   score: 0.0   memory length: 84855   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.65\nepisode: 462   score: 2.0   memory length: 85052   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.64\nepisode: 463   score: 1.0   memory length: 85223   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.64\nepisode: 464   score: 1.0   memory length: 85392   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.65\nepisode: 465   score: 4.0   memory length: 85690   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.68\nepisode: 466   score: 1.0   memory length: 85858   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.66\nepisode: 467   score: 2.0   memory length: 86058   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.65\nepisode: 468   score: 2.0   memory length: 86256   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 469   score: 2.0   memory length: 86454   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 470   score: 0.0   memory length: 86577   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 471   score: 3.0   memory length: 86823   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.62\nepisode: 472   score: 3.0   memory length: 87066   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.63\nepisode: 473   score: 0.0   memory length: 87189   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 474   score: 2.0   memory length: 87386   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.63\nepisode: 475   score: 0.0   memory length: 87509   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 476   score: 2.0   memory length: 87708   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.61\nepisode: 477   score: 1.0   memory length: 87878   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6\nepisode: 478   score: 2.0   memory length: 88098   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.61\nepisode: 479   score: 0.0   memory length: 88221   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 480   score: 4.0   memory length: 88498   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.62\nepisode: 481   score: 1.0   memory length: 88667   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 482   score: 1.0   memory length: 88836   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 483   score: 5.0   memory length: 89161   epsilon: 1.0    steps: 325    lr: 0.0001     evaluation reward: 1.61\nepisode: 484   score: 2.0   memory length: 89361   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.61\nepisode: 485   score: 4.0   memory length: 89653   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.62\nepisode: 486   score: 0.0   memory length: 89776   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 487   score: 2.0   memory length: 89994   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.62\nepisode: 488   score: 0.0   memory length: 90117   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 489   score: 3.0   memory length: 90348   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.61\nepisode: 490   score: 3.0   memory length: 90574   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.63\nepisode: 491   score: 1.0   memory length: 90743   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.64\nepisode: 492   score: 3.0   memory length: 90969   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.65\nepisode: 493   score: 2.0   memory length: 91167   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.67\nepisode: 494   score: 0.0   memory length: 91290   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 495   score: 1.0   memory length: 91459   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.64\nepisode: 496   score: 0.0   memory length: 91582   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 498   score: 3.0   memory length: 92075   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.64\nepisode: 499   score: 4.0   memory length: 92330   epsilon: 1.0    steps: 255    lr: 0.0001     evaluation reward: 1.65\nepisode: 500   score: 1.0   memory length: 92499   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.64\nepisode: 501   score: 0.0   memory length: 92622   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 548   score: 0.0   memory length: 101167   epsilon: 0.9976873600000502    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 549   score: 2.0   memory length: 101366   epsilon: 0.9972933400000588    steps: 199    lr: 0.0001     evaluation reward: 1.64\nepisode: 550   score: 1.0   memory length: 101517   epsilon: 0.9969943600000652    steps: 151    lr: 0.0001     evaluation reward: 1.63\nepisode: 551   score: 0.0   memory length: 101640   epsilon: 0.9967508200000705    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 552   score: 2.0   memory length: 101838   epsilon: 0.996358780000079    steps: 198    lr: 0.0001     evaluation reward: 1.61\nepisode: 553   score: 0.0   memory length: 101961   epsilon: 0.9961152400000843    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 554   score: 1.0   memory length: 102112   epsilon: 0.9958162600000908    steps: 151    lr: 0.0001     evaluation reward: 1.6\nepisode: 555   score: 0.0   memory length: 102235   epsilon: 0.9955727200000961    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 556   score: 0.0   memory length: 102358   epsilon: 0.9953291800001014    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 557   score: 3.0   memory length: 102625   epsilon: 0.9948005200001129    steps: 267    lr: 0.0001     evaluation reward: 1.57\nepisode: 558   score: 1.0   memory length: 102775   epsilon: 0.9945035200001193    steps: 150    lr: 0.0001     evaluation reward: 1.58\nepisode: 559   score: 2.0   memory length: 102993   epsilon: 0.9940718800001287    steps: 218    lr: 0.0001     evaluation reward: 1.56\nepisode: 560   score: 2.0   memory length: 103191   epsilon: 0.9936798400001372    steps: 198    lr: 0.0001     evaluation reward: 1.57\nepisode: 561   score: 3.0   memory length: 103401   epsilon: 0.9932640400001462    steps: 210    lr: 0.0001     evaluation reward: 1.6\nepisode: 562   score: 0.0   memory length: 103523   epsilon: 0.9930224800001515    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 563   score: 2.0   memory length: 103739   epsilon: 0.9925948000001608    steps: 216    lr: 0.0001     evaluation reward: 1.59\nepisode: 564   score: 1.0   memory length: 103908   epsilon: 0.992260180000168    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 565   score: 1.0   memory length: 104080   epsilon: 0.9919196200001754    steps: 172    lr: 0.0001     evaluation reward: 1.56\nepisode: 566   score: 0.0   memory length: 104202   epsilon: 0.9916780600001807    steps: 122    lr: 0.0001     evaluation reward: 1.55\nepisode: 567   score: 3.0   memory length: 104447   epsilon: 0.9911929600001912    steps: 245    lr: 0.0001     evaluation reward: 1.56\nepisode: 568   score: 1.0   memory length: 104618   epsilon: 0.9908543800001985    steps: 171    lr: 0.0001     evaluation reward: 1.55\nepisode: 569   score: 1.0   memory length: 104787   epsilon: 0.9905197600002058    steps: 169    lr: 0.0001     evaluation reward: 1.54\nepisode: 570   score: 2.0   memory length: 104985   epsilon: 0.9901277200002143    steps: 198    lr: 0.0001     evaluation reward: 1.56\nepisode: 571   score: 2.0   memory length: 105201   epsilon: 0.9897000400002236    steps: 216    lr: 0.0001     evaluation reward: 1.55\nepisode: 572   score: 3.0   memory length: 105463   epsilon: 0.9891812800002349    steps: 262    lr: 0.0001     evaluation reward: 1.55\nepisode: 573   score: 1.0   memory length: 105614   epsilon: 0.9888823000002414    steps: 151    lr: 0.0001     evaluation reward: 1.56\nepisode: 574   score: 3.0   memory length: 105860   epsilon: 0.9883952200002519    steps: 246    lr: 0.0001     evaluation reward: 1.57\nepisode: 575   score: 4.0   memory length: 106158   epsilon: 0.9878051800002647    steps: 298    lr: 0.0001     evaluation reward: 1.61\nepisode: 576   score: 1.0   memory length: 106309   epsilon: 0.9875062000002712    steps: 151    lr: 0.0001     evaluation reward: 1.6\nepisode: 577   score: 1.0   memory length: 106479   epsilon: 0.9871696000002785    steps: 170    lr: 0.0001     evaluation reward: 1.6\nepisode: 578   score: 0.0   memory length: 106601   epsilon: 0.9869280400002838    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 579   score: 1.0   memory length: 106773   epsilon: 0.9865874800002912    steps: 172    lr: 0.0001     evaluation reward: 1.59\nepisode: 580   score: 2.0   memory length: 106991   epsilon: 0.9861558400003005    steps: 218    lr: 0.0001     evaluation reward: 1.57\nepisode: 581   score: 2.0   memory length: 107191   epsilon: 0.9857598400003091    steps: 200    lr: 0.0001     evaluation reward: 1.58\nepisode: 582   score: 1.0   memory length: 107363   epsilon: 0.9854192800003165    steps: 172    lr: 0.0001     evaluation reward: 1.58\nepisode: 583   score: 0.0   memory length: 107485   epsilon: 0.9851777200003218    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 584   score: 0.0   memory length: 107608   epsilon: 0.9849341800003271    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 585   score: 2.0   memory length: 107806   epsilon: 0.9845421400003356    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 586   score: 1.0   memory length: 107977   epsilon: 0.9842035600003429    steps: 171    lr: 0.0001     evaluation reward: 1.5\nepisode: 587   score: 1.0   memory length: 108149   epsilon: 0.9838630000003503    steps: 172    lr: 0.0001     evaluation reward: 1.49\nepisode: 588   score: 1.0   memory length: 108300   epsilon: 0.9835640200003568    steps: 151    lr: 0.0001     evaluation reward: 1.5\nepisode: 589   score: 0.0   memory length: 108423   epsilon: 0.9833204800003621    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 590   score: 1.0   memory length: 108591   epsilon: 0.9829878400003693    steps: 168    lr: 0.0001     evaluation reward: 1.45\nepisode: 591   score: 3.0   memory length: 108858   epsilon: 0.9824591800003808    steps: 267    lr: 0.0001     evaluation reward: 1.47\nepisode: 592   score: 3.0   memory length: 109103   epsilon: 0.9819740800003913    steps: 245    lr: 0.0001     evaluation reward: 1.47\nepisode: 593   score: 0.0   memory length: 109226   epsilon: 0.9817305400003966    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 594   score: 0.0   memory length: 109348   epsilon: 0.9814889800004019    steps: 122    lr: 0.0001     evaluation reward: 1.45\nepisode: 595   score: 1.0   memory length: 109519   epsilon: 0.9811504000004092    steps: 171    lr: 0.0001     evaluation reward: 1.45\nepisode: 596   score: 0.0   memory length: 109642   epsilon: 0.9809068600004145    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 597   score: 3.0   memory length: 109892   epsilon: 0.9804118600004252    steps: 250    lr: 0.0001     evaluation reward: 1.45\nepisode: 598   score: 0.0   memory length: 110014   epsilon: 0.9801703000004305    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 599   score: 3.0   memory length: 110261   epsilon: 0.9796812400004411    steps: 247    lr: 0.0001     evaluation reward: 1.41\nepisode: 600   score: 0.0   memory length: 110383   epsilon: 0.9794396800004463    steps: 122    lr: 0.0001     evaluation reward: 1.4\nepisode: 601   score: 4.0   memory length: 110700   epsilon: 0.97881202000046    steps: 317    lr: 0.0001     evaluation reward: 1.44\nepisode: 602   score: 2.0   memory length: 110899   epsilon: 0.9784180000004685    steps: 199    lr: 0.0001     evaluation reward: 1.46\nepisode: 603   score: 2.0   memory length: 111096   epsilon: 0.978027940000477    steps: 197    lr: 0.0001     evaluation reward: 1.48\nepisode: 604   score: 2.0   memory length: 111313   epsilon: 0.9775982800004863    steps: 217    lr: 0.0001     evaluation reward: 1.48\nepisode: 605   score: 1.0   memory length: 111481   epsilon: 0.9772656400004935    steps: 168    lr: 0.0001     evaluation reward: 1.48\nepisode: 606   score: 3.0   memory length: 111749   epsilon: 0.9767350000005051    steps: 268    lr: 0.0001     evaluation reward: 1.49\nepisode: 607   score: 1.0   memory length: 111900   epsilon: 0.9764360200005116    steps: 151    lr: 0.0001     evaluation reward: 1.5\nepisode: 608   score: 2.0   memory length: 112098   epsilon: 0.9760439800005201    steps: 198    lr: 0.0001     evaluation reward: 1.5\nepisode: 609   score: 2.0   memory length: 112296   epsilon: 0.9756519400005286    steps: 198    lr: 0.0001     evaluation reward: 1.51\nepisode: 610   score: 2.0   memory length: 112493   epsilon: 0.975261880000537    steps: 197    lr: 0.0001     evaluation reward: 1.53\nepisode: 611   score: 0.0   memory length: 112616   epsilon: 0.9750183400005423    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 612   score: 1.0   memory length: 112784   epsilon: 0.9746857000005495    steps: 168    lr: 0.0001     evaluation reward: 1.49\nepisode: 613   score: 2.0   memory length: 113002   epsilon: 0.9742540600005589    steps: 218    lr: 0.0001     evaluation reward: 1.51\nepisode: 614   score: 3.0   memory length: 113227   epsilon: 0.9738085600005686    steps: 225    lr: 0.0001     evaluation reward: 1.53\nepisode: 615   score: 2.0   memory length: 113424   epsilon: 0.9734185000005771    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 616   score: 0.0   memory length: 113547   epsilon: 0.9731749600005823    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 617   score: 1.0   memory length: 113719   epsilon: 0.9728344000005897    steps: 172    lr: 0.0001     evaluation reward: 1.52\nepisode: 618   score: 0.0   memory length: 113841   epsilon: 0.972592840000595    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 619   score: 3.0   memory length: 114086   epsilon: 0.9721077400006055    steps: 245    lr: 0.0001     evaluation reward: 1.54\nepisode: 620   score: 2.0   memory length: 114304   epsilon: 0.9716761000006149    steps: 218    lr: 0.0001     evaluation reward: 1.52\nepisode: 621   score: 0.0   memory length: 114427   epsilon: 0.9714325600006202    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 622   score: 4.0   memory length: 114727   epsilon: 0.9708385600006331    steps: 300    lr: 0.0001     evaluation reward: 1.51\nepisode: 623   score: 2.0   memory length: 114924   epsilon: 0.9704485000006415    steps: 197    lr: 0.0001     evaluation reward: 1.5\nepisode: 624   score: 2.0   memory length: 115121   epsilon: 0.97005844000065    steps: 197    lr: 0.0001     evaluation reward: 1.51\nepisode: 625   score: 3.0   memory length: 115347   epsilon: 0.9696109600006597    steps: 226    lr: 0.0001     evaluation reward: 1.54\nepisode: 626   score: 3.0   memory length: 115573   epsilon: 0.9691634800006694    steps: 226    lr: 0.0001     evaluation reward: 1.57\nepisode: 627   score: 1.0   memory length: 115724   epsilon: 0.9688645000006759    steps: 151    lr: 0.0001     evaluation reward: 1.56\nepisode: 628   score: 3.0   memory length: 115991   epsilon: 0.9683358400006874    steps: 267    lr: 0.0001     evaluation reward: 1.55\nepisode: 629   score: 3.0   memory length: 116237   epsilon: 0.967848760000698    steps: 246    lr: 0.0001     evaluation reward: 1.58\nepisode: 630   score: 3.0   memory length: 116485   epsilon: 0.9673577200007086    steps: 248    lr: 0.0001     evaluation reward: 1.57\nepisode: 631   score: 1.0   memory length: 116635   epsilon: 0.9670607200007151    steps: 150    lr: 0.0001     evaluation reward: 1.58\nepisode: 632   score: 4.0   memory length: 116909   epsilon: 0.9665182000007269    steps: 274    lr: 0.0001     evaluation reward: 1.62\nepisode: 633   score: 0.0   memory length: 117032   epsilon: 0.9662746600007321    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 634   score: 0.0   memory length: 117154   epsilon: 0.9660331000007374    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 635   score: 3.0   memory length: 117399   epsilon: 0.9655480000007479    steps: 245    lr: 0.0001     evaluation reward: 1.61\nepisode: 636   score: 1.0   memory length: 117571   epsilon: 0.9652074400007553    steps: 172    lr: 0.0001     evaluation reward: 1.6\nepisode: 637   score: 0.0   memory length: 117694   epsilon: 0.9649639000007606    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 638   score: 3.0   memory length: 117943   epsilon: 0.9644708800007713    steps: 249    lr: 0.0001     evaluation reward: 1.59\nepisode: 639   score: 1.0   memory length: 118113   epsilon: 0.9641342800007786    steps: 170    lr: 0.0001     evaluation reward: 1.58\nepisode: 640   score: 0.0   memory length: 118236   epsilon: 0.9638907400007839    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 641   score: 5.0   memory length: 118537   epsilon: 0.9632947600007968    steps: 301    lr: 0.0001     evaluation reward: 1.61\nepisode: 642   score: 0.0   memory length: 118659   epsilon: 0.9630532000008021    steps: 122    lr: 0.0001     evaluation reward: 1.57\nepisode: 643   score: 2.0   memory length: 118857   epsilon: 0.9626611600008106    steps: 198    lr: 0.0001     evaluation reward: 1.55\nepisode: 644   score: 2.0   memory length: 119054   epsilon: 0.9622711000008191    steps: 197    lr: 0.0001     evaluation reward: 1.53\nepisode: 645   score: 0.0   memory length: 119177   epsilon: 0.9620275600008243    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 646   score: 1.0   memory length: 119349   epsilon: 0.9616870000008317    steps: 172    lr: 0.0001     evaluation reward: 1.53\nepisode: 647   score: 1.0   memory length: 119521   epsilon: 0.9613464400008391    steps: 172    lr: 0.0001     evaluation reward: 1.51\nepisode: 648   score: 0.0   memory length: 119644   epsilon: 0.9611029000008444    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 649   score: 1.0   memory length: 119812   epsilon: 0.9607702600008516    steps: 168    lr: 0.0001     evaluation reward: 1.5\nepisode: 650   score: 1.0   memory length: 119980   epsilon: 0.9604376200008589    steps: 168    lr: 0.0001     evaluation reward: 1.5\nepisode: 651   score: 3.0   memory length: 120250   epsilon: 0.9599030200008705    steps: 270    lr: 0.0001     evaluation reward: 1.53\nepisode: 652   score: 0.0   memory length: 120373   epsilon: 0.9596594800008758    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 653   score: 2.0   memory length: 120571   epsilon: 0.9592674400008843    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 654   score: 1.0   memory length: 120740   epsilon: 0.9589328200008915    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 655   score: 0.0   memory length: 120863   epsilon: 0.9586892800008968    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 656   score: 1.0   memory length: 121032   epsilon: 0.9583546600009041    steps: 169    lr: 0.0001     evaluation reward: 1.54\nepisode: 657   score: 2.0   memory length: 121230   epsilon: 0.9579626200009126    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 658   score: 3.0   memory length: 121475   epsilon: 0.9574775200009231    steps: 245    lr: 0.0001     evaluation reward: 1.55\nepisode: 659   score: 3.0   memory length: 121741   epsilon: 0.9569508400009346    steps: 266    lr: 0.0001     evaluation reward: 1.56\nepisode: 660   score: 1.0   memory length: 121912   epsilon: 0.9566122600009419    steps: 171    lr: 0.0001     evaluation reward: 1.55\nepisode: 661   score: 0.0   memory length: 122035   epsilon: 0.9563687200009472    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 662   score: 2.0   memory length: 122250   epsilon: 0.9559430200009564    steps: 215    lr: 0.0001     evaluation reward: 1.54\nepisode: 663   score: 1.0   memory length: 122419   epsilon: 0.9556084000009637    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 664   score: 2.0   memory length: 122616   epsilon: 0.9552183400009722    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 665   score: 1.0   memory length: 122786   epsilon: 0.9548817400009795    steps: 170    lr: 0.0001     evaluation reward: 1.54\nepisode: 666   score: 1.0   memory length: 122937   epsilon: 0.954582760000986    steps: 151    lr: 0.0001     evaluation reward: 1.55\nepisode: 667   score: 0.0   memory length: 123060   epsilon: 0.9543392200009913    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 668   score: 0.0   memory length: 123182   epsilon: 0.9540976600009965    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 669   score: 1.0   memory length: 123351   epsilon: 0.9537630400010038    steps: 169    lr: 0.0001     evaluation reward: 1.51\nepisode: 670   score: 0.0   memory length: 123473   epsilon: 0.953521480001009    steps: 122    lr: 0.0001     evaluation reward: 1.49\nepisode: 671   score: 1.0   memory length: 123624   epsilon: 0.9532225000010155    steps: 151    lr: 0.0001     evaluation reward: 1.48\nepisode: 672   score: 1.0   memory length: 123775   epsilon: 0.952923520001022    steps: 151    lr: 0.0001     evaluation reward: 1.46\nepisode: 673   score: 3.0   memory length: 124010   epsilon: 0.9524582200010321    steps: 235    lr: 0.0001     evaluation reward: 1.48\nepisode: 674   score: 1.0   memory length: 124181   epsilon: 0.9521196400010394    steps: 171    lr: 0.0001     evaluation reward: 1.46\nepisode: 675   score: 2.0   memory length: 124382   epsilon: 0.9517216600010481    steps: 201    lr: 0.0001     evaluation reward: 1.44\nepisode: 676   score: 3.0   memory length: 124629   epsilon: 0.9512326000010587    steps: 247    lr: 0.0001     evaluation reward: 1.46\nepisode: 677   score: 3.0   memory length: 124874   epsilon: 0.9507475000010692    steps: 245    lr: 0.0001     evaluation reward: 1.48\nepisode: 678   score: 1.0   memory length: 125043   epsilon: 0.9504128800010765    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 679   score: 1.0   memory length: 125194   epsilon: 0.950113900001083    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 680   score: 0.0   memory length: 125316   epsilon: 0.9498723400010882    steps: 122    lr: 0.0001     evaluation reward: 1.47\nepisode: 681   score: 4.0   memory length: 125572   epsilon: 0.9493654600010992    steps: 256    lr: 0.0001     evaluation reward: 1.49\nepisode: 682   score: 0.0   memory length: 125695   epsilon: 0.9491219200011045    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 683   score: 0.0   memory length: 125817   epsilon: 0.9488803600011098    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 684   score: 1.0   memory length: 125968   epsilon: 0.9485813800011162    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 685   score: 1.0   memory length: 126136   epsilon: 0.9482487400011235    steps: 168    lr: 0.0001     evaluation reward: 1.48\nepisode: 686   score: 3.0   memory length: 126383   epsilon: 0.9477596800011341    steps: 247    lr: 0.0001     evaluation reward: 1.5\nepisode: 687   score: 0.0   memory length: 126506   epsilon: 0.9475161400011394    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 688   score: 0.0   memory length: 126629   epsilon: 0.9472726000011447    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 689   score: 0.0   memory length: 126752   epsilon: 0.94702906000115    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 690   score: 1.0   memory length: 126903   epsilon: 0.9467300800011564    steps: 151    lr: 0.0001     evaluation reward: 1.48\nepisode: 691   score: 3.0   memory length: 127149   epsilon: 0.946243000001167    steps: 246    lr: 0.0001     evaluation reward: 1.48\nepisode: 692   score: 0.0   memory length: 127272   epsilon: 0.9459994600011723    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 693   score: 0.0   memory length: 127395   epsilon: 0.9457559200011776    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 694   score: 2.0   memory length: 127612   epsilon: 0.9453262600011869    steps: 217    lr: 0.0001     evaluation reward: 1.47\nepisode: 695   score: 2.0   memory length: 127830   epsilon: 0.9448946200011963    steps: 218    lr: 0.0001     evaluation reward: 1.48\nepisode: 696   score: 0.0   memory length: 127952   epsilon: 0.9446530600012015    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 697   score: 1.0   memory length: 128124   epsilon: 0.9443125000012089    steps: 172    lr: 0.0001     evaluation reward: 1.46\nepisode: 698   score: 0.0   memory length: 128246   epsilon: 0.9440709400012142    steps: 122    lr: 0.0001     evaluation reward: 1.46\nepisode: 699   score: 5.0   memory length: 128584   epsilon: 0.9434017000012287    steps: 338    lr: 0.0001     evaluation reward: 1.48\nepisode: 700   score: 0.0   memory length: 128706   epsilon: 0.9431601400012339    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 701   score: 0.0   memory length: 128829   epsilon: 0.9429166000012392    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 702   score: 1.0   memory length: 128998   epsilon: 0.9425819800012465    steps: 169    lr: 0.0001     evaluation reward: 1.43\nepisode: 703   score: 3.0   memory length: 129224   epsilon: 0.9421345000012562    steps: 226    lr: 0.0001     evaluation reward: 1.44\nepisode: 704   score: 1.0   memory length: 129392   epsilon: 0.9418018600012634    steps: 168    lr: 0.0001     evaluation reward: 1.43\nepisode: 835   score: 4.0   memory length: 154720   epsilon: 0.8916524200023521    steps: 299    lr: 0.0001     evaluation reward: 1.83\nepisode: 836   score: 3.0   memory length: 154987   epsilon: 0.8911237600023636    steps: 267    lr: 0.0001     evaluation reward: 1.84\nepisode: 837   score: 1.0   memory length: 155156   epsilon: 0.8907891400023709    steps: 169    lr: 0.0001     evaluation reward: 1.84\nepisode: 838   score: 1.0   memory length: 155325   epsilon: 0.8904545200023781    steps: 169    lr: 0.0001     evaluation reward: 1.82\nepisode: 974   score: 0.0   memory length: 180632   epsilon: 0.8403466600034659    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 975   score: 1.0   memory length: 180801   epsilon: 0.8400120400034732    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 976   score: 0.0   memory length: 180924   epsilon: 0.8397685000034785    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 977   score: 1.0   memory length: 181075   epsilon: 0.839469520003485    steps: 151    lr: 0.0001     evaluation reward: 1.53\nepisode: 987   score: 3.0   memory length: 182975   epsilon: 0.8357075200035666    steps: 227    lr: 0.0001     evaluation reward: 1.57\nepisode: 988   score: 2.0   memory length: 183173   epsilon: 0.8353154800035751    steps: 198    lr: 0.0001     evaluation reward: 1.59\nepisode: 989   score: 0.0   memory length: 183295   epsilon: 0.8350739200035804    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 990   score: 2.0   memory length: 183494   epsilon: 0.8346799000035889    steps: 199    lr: 0.0001     evaluation reward: 1.58\nepisode: 991   score: 3.0   memory length: 183743   epsilon: 0.8341868800035996    steps: 249    lr: 0.0001     evaluation reward: 1.59\nepisode: 992   score: 4.0   memory length: 184018   epsilon: 0.8336423800036115    steps: 275    lr: 0.0001     evaluation reward: 1.63\nepisode: 993   score: 0.0   memory length: 184141   epsilon: 0.8333988400036167    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 994   score: 0.0   memory length: 184264   epsilon: 0.833155300003622    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 995   score: 3.0   memory length: 184509   epsilon: 0.8326702000036326    steps: 245    lr: 0.0001     evaluation reward: 1.61\nepisode: 996   score: 0.0   memory length: 184632   epsilon: 0.8324266600036379    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 997   score: 2.0   memory length: 184851   epsilon: 0.8319930400036473    steps: 219    lr: 0.0001     evaluation reward: 1.57\nepisode: 998   score: 4.0   memory length: 185126   epsilon: 0.8314485400036591    steps: 275    lr: 0.0001     evaluation reward: 1.59\nepisode: 999   score: 2.0   memory length: 185324   epsilon: 0.8310565000036676    steps: 198    lr: 0.0001     evaluation reward: 1.61\nepisode: 1000   score: 1.0   memory length: 185493   epsilon: 0.8307218800036749    steps: 169    lr: 0.0001     evaluation reward: 1.62\nepisode: 1001   score: 1.0   memory length: 185644   epsilon: 0.8304229000036814    steps: 151    lr: 0.0001     evaluation reward: 1.62\nepisode: 1002   score: 3.0   memory length: 185892   epsilon: 0.829931860003692    steps: 248    lr: 0.0001     evaluation reward: 1.63\nepisode: 1003   score: 2.0   memory length: 186112   epsilon: 0.8294962600037015    steps: 220    lr: 0.0001     evaluation reward: 1.6\nepisode: 1004   score: 0.0   memory length: 186235   epsilon: 0.8292527200037068    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 1005   score: 3.0   memory length: 186461   epsilon: 0.8288052400037165    steps: 226    lr: 0.0001     evaluation reward: 1.59\nepisode: 1006   score: 1.0   memory length: 186611   epsilon: 0.8285082400037229    steps: 150    lr: 0.0001     evaluation reward: 1.6\nepisode: 1007   score: 4.0   memory length: 186886   epsilon: 0.8279637400037347    steps: 275    lr: 0.0001     evaluation reward: 1.64\nepisode: 1008   score: 0.0   memory length: 187008   epsilon: 0.82772218000374    steps: 122    lr: 0.0001     evaluation reward: 1.62\nepisode: 1009   score: 1.0   memory length: 187177   epsilon: 0.8273875600037472    steps: 169    lr: 0.0001     evaluation reward: 1.62\nepisode: 1010   score: 3.0   memory length: 187422   epsilon: 0.8269024600037578    steps: 245    lr: 0.0001     evaluation reward: 1.64\nepisode: 1011   score: 2.0   memory length: 187602   epsilon: 0.8265460600037655    steps: 180    lr: 0.0001     evaluation reward: 1.61\nepisode: 1012   score: 4.0   memory length: 187868   epsilon: 0.826019380003777    steps: 266    lr: 0.0001     evaluation reward: 1.62\nepisode: 1013   score: 0.0   memory length: 187991   epsilon: 0.8257758400037822    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 1014   score: 4.0   memory length: 188246   epsilon: 0.8252709400037932    steps: 255    lr: 0.0001     evaluation reward: 1.63\nepisode: 1015   score: 1.0   memory length: 188414   epsilon: 0.8249383000038004    steps: 168    lr: 0.0001     evaluation reward: 1.6\nepisode: 1016   score: 2.0   memory length: 188612   epsilon: 0.8245462600038089    steps: 198    lr: 0.0001     evaluation reward: 1.62\nepisode: 1017   score: 1.0   memory length: 188782   epsilon: 0.8242096600038162    steps: 170    lr: 0.0001     evaluation reward: 1.62\nepisode: 1018   score: 2.0   memory length: 188980   epsilon: 0.8238176200038247    steps: 198    lr: 0.0001     evaluation reward: 1.61\nepisode: 1019   score: 4.0   memory length: 189273   epsilon: 0.8232374800038373    steps: 293    lr: 0.0001     evaluation reward: 1.61\nepisode: 1020   score: 1.0   memory length: 189425   epsilon: 0.8229365200038439    steps: 152    lr: 0.0001     evaluation reward: 1.6\nepisode: 1021   score: 1.0   memory length: 189576   epsilon: 0.8226375400038504    steps: 151    lr: 0.0001     evaluation reward: 1.59\nepisode: 1022   score: 2.0   memory length: 189774   epsilon: 0.8222455000038589    steps: 198    lr: 0.0001     evaluation reward: 1.57\nepisode: 1023   score: 2.0   memory length: 189993   epsilon: 0.8218118800038683    steps: 219    lr: 0.0001     evaluation reward: 1.56\nepisode: 1024   score: 2.0   memory length: 190191   epsilon: 0.8214198400038768    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 1025   score: 0.0   memory length: 190314   epsilon: 0.8211763000038821    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 1026   score: 0.0   memory length: 190437   epsilon: 0.8209327600038874    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 1027   score: 3.0   memory length: 190705   epsilon: 0.8204021200038989    steps: 268    lr: 0.0001     evaluation reward: 1.56\nepisode: 1028   score: 0.0   memory length: 190828   epsilon: 0.8201585800039042    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 1029   score: 3.0   memory length: 191075   epsilon: 0.8196695200039148    steps: 247    lr: 0.0001     evaluation reward: 1.53\nepisode: 1030   score: 2.0   memory length: 191273   epsilon: 0.8192774800039233    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 1031   score: 0.0   memory length: 191396   epsilon: 0.8190339400039286    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 1032   score: 2.0   memory length: 191576   epsilon: 0.8186775400039363    steps: 180    lr: 0.0001     evaluation reward: 1.53\nepisode: 1033   score: 1.0   memory length: 191748   epsilon: 0.8183369800039437    steps: 172    lr: 0.0001     evaluation reward: 1.52\nepisode: 1034   score: 1.0   memory length: 191920   epsilon: 0.8179964200039511    steps: 172    lr: 0.0001     evaluation reward: 1.52\nepisode: 1035   score: 1.0   memory length: 192090   epsilon: 0.8176598200039584    steps: 170    lr: 0.0001     evaluation reward: 1.5\nepisode: 1036   score: 3.0   memory length: 192335   epsilon: 0.817174720003969    steps: 245    lr: 0.0001     evaluation reward: 1.53\nepisode: 1037   score: 2.0   memory length: 192533   epsilon: 0.8167826800039775    steps: 198    lr: 0.0001     evaluation reward: 1.55\nepisode: 1038   score: 0.0   memory length: 192656   epsilon: 0.8165391400039828    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 1039   score: 2.0   memory length: 192854   epsilon: 0.8161471000039913    steps: 198    lr: 0.0001     evaluation reward: 1.54\nepisode: 1040   score: 2.0   memory length: 193051   epsilon: 0.8157570400039997    steps: 197    lr: 0.0001     evaluation reward: 1.56\nepisode: 1041   score: 0.0   memory length: 193174   epsilon: 0.815513500004005    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 1042   score: 2.0   memory length: 193372   epsilon: 0.8151214600040135    steps: 198    lr: 0.0001     evaluation reward: 1.54\nepisode: 1043   score: 2.0   memory length: 193569   epsilon: 0.814731400004022    steps: 197    lr: 0.0001     evaluation reward: 1.56\nepisode: 1044   score: 1.0   memory length: 193720   epsilon: 0.8144324200040285    steps: 151    lr: 0.0001     evaluation reward: 1.57\nepisode: 1045   score: 3.0   memory length: 193967   epsilon: 0.8139433600040391    steps: 247    lr: 0.0001     evaluation reward: 1.6\nepisode: 1046   score: 1.0   memory length: 194118   epsilon: 0.8136443800040456    steps: 151    lr: 0.0001     evaluation reward: 1.57\nepisode: 1047   score: 3.0   memory length: 194344   epsilon: 0.8131969000040553    steps: 226    lr: 0.0001     evaluation reward: 1.58\nepisode: 1048   score: 3.0   memory length: 194558   epsilon: 0.8127731800040645    steps: 214    lr: 0.0001     evaluation reward: 1.6\nepisode: 1049   score: 1.0   memory length: 194709   epsilon: 0.812474200004071    steps: 151    lr: 0.0001     evaluation reward: 1.59\nepisode: 1050   score: 3.0   memory length: 194959   epsilon: 0.8119792000040817    steps: 250    lr: 0.0001     evaluation reward: 1.61\nepisode: 1051   score: 3.0   memory length: 195205   epsilon: 0.8114921200040923    steps: 246    lr: 0.0001     evaluation reward: 1.63\nepisode: 1052   score: 0.0   memory length: 195328   epsilon: 0.8112485800040976    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 1053   score: 6.0   memory length: 195679   epsilon: 0.8105536000041127    steps: 351    lr: 0.0001     evaluation reward: 1.65\nepisode: 1054   score: 3.0   memory length: 195948   epsilon: 0.8100209800041243    steps: 269    lr: 0.0001     evaluation reward: 1.66\nepisode: 1055   score: 4.0   memory length: 196224   epsilon: 0.8094745000041361    steps: 276    lr: 0.0001     evaluation reward: 1.68\nepisode: 1056   score: 3.0   memory length: 196453   epsilon: 0.809021080004146    steps: 229    lr: 0.0001     evaluation reward: 1.66\nepisode: 1057   score: 3.0   memory length: 196699   epsilon: 0.8085340000041565    steps: 246    lr: 0.0001     evaluation reward: 1.69\nepisode: 1058   score: 3.0   memory length: 196908   epsilon: 0.8081201800041655    steps: 209    lr: 0.0001     evaluation reward: 1.72\nepisode: 1059   score: 3.0   memory length: 197155   epsilon: 0.8076311200041761    steps: 247    lr: 0.0001     evaluation reward: 1.74\nepisode: 1060   score: 0.0   memory length: 197278   epsilon: 0.8073875800041814    steps: 123    lr: 0.0001     evaluation reward: 1.72\nepisode: 1061   score: 0.0   memory length: 197400   epsilon: 0.8071460200041867    steps: 122    lr: 0.0001     evaluation reward: 1.72\nepisode: 1062   score: 2.0   memory length: 197598   epsilon: 0.8067539800041952    steps: 198    lr: 0.0001     evaluation reward: 1.71\nepisode: 1063   score: 2.0   memory length: 197796   epsilon: 0.8063619400042037    steps: 198    lr: 0.0001     evaluation reward: 1.71\nepisode: 1064   score: 0.0   memory length: 197918   epsilon: 0.8061203800042089    steps: 122    lr: 0.0001     evaluation reward: 1.69\nepisode: 1065   score: 2.0   memory length: 198100   epsilon: 0.8057600200042168    steps: 182    lr: 0.0001     evaluation reward: 1.7\nepisode: 1066   score: 2.0   memory length: 198317   epsilon: 0.8053303600042261    steps: 217    lr: 0.0001     evaluation reward: 1.72\nepisode: 1067   score: 0.0   memory length: 198439   epsilon: 0.8050888000042313    steps: 122    lr: 0.0001     evaluation reward: 1.72\nepisode: 1068   score: 0.0   memory length: 198562   epsilon: 0.8048452600042366    steps: 123    lr: 0.0001     evaluation reward: 1.71\nepisode: 1069   score: 2.0   memory length: 198760   epsilon: 0.8044532200042451    steps: 198    lr: 0.0001     evaluation reward: 1.73\nepisode: 1070   score: 2.0   memory length: 198958   epsilon: 0.8040611800042536    steps: 198    lr: 0.0001     evaluation reward: 1.74\nepisode: 1071   score: 2.0   memory length: 199156   epsilon: 0.8036691400042622    steps: 198    lr: 0.0001     evaluation reward: 1.76\nepisode: 1072   score: 2.0   memory length: 199353   epsilon: 0.8032790800042706    steps: 197    lr: 0.0001     evaluation reward: 1.75\nepisode: 1073   score: 3.0   memory length: 199599   epsilon: 0.8027920000042812    steps: 246    lr: 0.0001     evaluation reward: 1.78\nepisode: 1074   score: 0.0   memory length: 199722   epsilon: 0.8025484600042865    steps: 123    lr: 0.0001     evaluation reward: 1.78\nepisode: 1075   score: 2.0   memory length: 199920   epsilon: 0.802156420004295    steps: 198    lr: 0.0001     evaluation reward: 1.79\nepisode: 1076   score: 0.0   memory length: 200043   epsilon: 0.8019128800043003    steps: 123    lr: 4e-05     evaluation reward: 1.79\nepisode: 1077   score: 2.0   memory length: 200241   epsilon: 0.8015208400043088    steps: 198    lr: 4e-05     evaluation reward: 1.8\nepisode: 1078   score: 1.0   memory length: 200392   epsilon: 0.8012218600043153    steps: 151    lr: 4e-05     evaluation reward: 1.78\nepisode: 1079   score: 2.0   memory length: 200589   epsilon: 0.8008318000043237    steps: 197    lr: 4e-05     evaluation reward: 1.77\nepisode: 1080   score: 3.0   memory length: 200815   epsilon: 0.8003843200043335    steps: 226    lr: 4e-05     evaluation reward: 1.78\nepisode: 1081   score: 3.0   memory length: 201059   epsilon: 0.799901200004344    steps: 244    lr: 4e-05     evaluation reward: 1.78\nepisode: 1082   score: 2.0   memory length: 201257   epsilon: 0.7995091600043525    steps: 198    lr: 4e-05     evaluation reward: 1.78\nepisode: 1083   score: 4.0   memory length: 201514   epsilon: 0.7990003000043635    steps: 257    lr: 4e-05     evaluation reward: 1.81\nepisode: 1084   score: 2.0   memory length: 201732   epsilon: 0.7985686600043729    steps: 218    lr: 4e-05     evaluation reward: 1.83\nepisode: 1085   score: 3.0   memory length: 201958   epsilon: 0.7981211800043826    steps: 226    lr: 4e-05     evaluation reward: 1.84\nepisode: 1086   score: 0.0   memory length: 202080   epsilon: 0.7978796200043878    steps: 122    lr: 4e-05     evaluation reward: 1.84\nepisode: 1087   score: 2.0   memory length: 202277   epsilon: 0.7974895600043963    steps: 197    lr: 4e-05     evaluation reward: 1.83\nepisode: 1088   score: 4.0   memory length: 202575   epsilon: 0.7968995200044091    steps: 298    lr: 4e-05     evaluation reward: 1.85\nepisode: 1089   score: 0.0   memory length: 202698   epsilon: 0.7966559800044144    steps: 123    lr: 4e-05     evaluation reward: 1.85\nepisode: 1090   score: 2.0   memory length: 202895   epsilon: 0.7962659200044229    steps: 197    lr: 4e-05     evaluation reward: 1.85\nepisode: 1091   score: 2.0   memory length: 203113   epsilon: 0.7958342800044322    steps: 218    lr: 4e-05     evaluation reward: 1.84\nepisode: 1195   score: 5.0   memory length: 225319   epsilon: 0.7518664000053867    steps: 341    lr: 4e-05     evaluation reward: 2.46\nepisode: 1196   score: 2.0   memory length: 225538   epsilon: 0.7514327800053962    steps: 219    lr: 4e-05     evaluation reward: 2.47\nepisode: 1197   score: 2.0   memory length: 225736   epsilon: 0.7510407400054047    steps: 198    lr: 4e-05     evaluation reward: 2.43\nepisode: 1198   score: 2.0   memory length: 225934   epsilon: 0.7506487000054132    steps: 198    lr: 4e-05     evaluation reward: 2.4\nepisode: 1208   score: 2.0   memory length: 228545   epsilon: 0.7454789200055254    steps: 218    lr: 4e-05     evaluation reward: 2.56\nepisode: 1209   score: 5.0   memory length: 228829   epsilon: 0.7449166000055376    steps: 284    lr: 4e-05     evaluation reward: 2.6\nepisode: 1210   score: 3.0   memory length: 229095   epsilon: 0.744389920005549    steps: 266    lr: 4e-05     evaluation reward: 2.59\nepisode: 1211   score: 2.0   memory length: 229293   epsilon: 0.7439978800055576    steps: 198    lr: 4e-05     evaluation reward: 2.58\nepisode: 1212   score: 3.0   memory length: 229519   epsilon: 0.7435504000055673    steps: 226    lr: 4e-05     evaluation reward: 2.59\nepisode: 1213   score: 1.0   memory length: 229670   epsilon: 0.7432514200055738    steps: 151    lr: 4e-05     evaluation reward: 2.58\nepisode: 1214   score: 3.0   memory length: 229915   epsilon: 0.7427663200055843    steps: 245    lr: 4e-05     evaluation reward: 2.58\nepisode: 1215   score: 3.0   memory length: 230124   epsilon: 0.7423525000055933    steps: 209    lr: 4e-05     evaluation reward: 2.58\nepisode: 1216   score: 4.0   memory length: 230399   epsilon: 0.7418080000056051    steps: 275    lr: 4e-05     evaluation reward: 2.6\nepisode: 1217   score: 5.0   memory length: 230712   epsilon: 0.7411882600056185    steps: 313    lr: 4e-05     evaluation reward: 2.64\nepisode: 1218   score: 1.0   memory length: 230864   epsilon: 0.7408873000056251    steps: 152    lr: 4e-05     evaluation reward: 2.62\nepisode: 1219   score: 3.0   memory length: 231075   epsilon: 0.7404695200056342    steps: 211    lr: 4e-05     evaluation reward: 2.61\nepisode: 1220   score: 3.0   memory length: 231322   epsilon: 0.7399804600056448    steps: 247    lr: 4e-05     evaluation reward: 2.61\nepisode: 1221   score: 3.0   memory length: 231548   epsilon: 0.7395329800056545    steps: 226    lr: 4e-05     evaluation reward: 2.61\nepisode: 1222   score: 1.0   memory length: 231699   epsilon: 0.739234000005661    steps: 151    lr: 4e-05     evaluation reward: 2.57\nepisode: 1223   score: 1.0   memory length: 231868   epsilon: 0.7388993800056682    steps: 169    lr: 4e-05     evaluation reward: 2.55\nepisode: 1224   score: 4.0   memory length: 232126   epsilon: 0.7383885400056793    steps: 258    lr: 4e-05     evaluation reward: 2.59\nepisode: 1225   score: 2.0   memory length: 232324   epsilon: 0.7379965000056878    steps: 198    lr: 4e-05     evaluation reward: 2.61\nepisode: 1226   score: 2.0   memory length: 232523   epsilon: 0.7376024800056964    steps: 199    lr: 4e-05     evaluation reward: 2.63\nepisode: 1227   score: 2.0   memory length: 232720   epsilon: 0.7372124200057049    steps: 197    lr: 4e-05     evaluation reward: 2.64\nepisode: 1228   score: 2.0   memory length: 232918   epsilon: 0.7368203800057134    steps: 198    lr: 4e-05     evaluation reward: 2.64\nepisode: 1229   score: 3.0   memory length: 233129   epsilon: 0.7364026000057224    steps: 211    lr: 4e-05     evaluation reward: 2.65\nepisode: 1230   score: 6.0   memory length: 233487   epsilon: 0.7356937600057378    steps: 358    lr: 4e-05     evaluation reward: 2.7\nepisode: 1231   score: 4.0   memory length: 233746   epsilon: 0.735180940005749    steps: 259    lr: 4e-05     evaluation reward: 2.73\nepisode: 1232   score: 4.0   memory length: 234007   epsilon: 0.7346641600057602    steps: 261    lr: 4e-05     evaluation reward: 2.75\nepisode: 1233   score: 5.0   memory length: 234351   epsilon: 0.733983040005775    steps: 344    lr: 4e-05     evaluation reward: 2.74\nepisode: 1234   score: 2.0   memory length: 234549   epsilon: 0.7335910000057835    steps: 198    lr: 4e-05     evaluation reward: 2.74\nepisode: 1235   score: 1.0   memory length: 234701   epsilon: 0.73329004000579    steps: 152    lr: 4e-05     evaluation reward: 2.72\nepisode: 1236   score: 3.0   memory length: 234949   epsilon: 0.7327990000058007    steps: 248    lr: 4e-05     evaluation reward: 2.73\nepisode: 1237   score: 2.0   memory length: 235147   epsilon: 0.7324069600058092    steps: 198    lr: 4e-05     evaluation reward: 2.73\nepisode: 1238   score: 4.0   memory length: 235404   epsilon: 0.7318981000058202    steps: 257    lr: 4e-05     evaluation reward: 2.73\nepisode: 1239   score: 4.0   memory length: 235700   epsilon: 0.731312020005833    steps: 296    lr: 4e-05     evaluation reward: 2.73\nepisode: 1240   score: 2.0   memory length: 235898   epsilon: 0.7309199800058415    steps: 198    lr: 4e-05     evaluation reward: 2.72\nepisode: 1241   score: 4.0   memory length: 236139   epsilon: 0.7304428000058518    steps: 241    lr: 4e-05     evaluation reward: 2.74\nepisode: 1242   score: 3.0   memory length: 236351   epsilon: 0.7300230400058609    steps: 212    lr: 4e-05     evaluation reward: 2.74\nepisode: 1243   score: 3.0   memory length: 236580   epsilon: 0.7295696200058708    steps: 229    lr: 4e-05     evaluation reward: 2.77\nepisode: 1244   score: 2.0   memory length: 236778   epsilon: 0.7291775800058793    steps: 198    lr: 4e-05     evaluation reward: 2.75\nepisode: 1245   score: 3.0   memory length: 237004   epsilon: 0.728730100005889    steps: 226    lr: 4e-05     evaluation reward: 2.78\nepisode: 1246   score: 1.0   memory length: 237173   epsilon: 0.7283954800058963    steps: 169    lr: 4e-05     evaluation reward: 2.79\nepisode: 1247   score: 5.0   memory length: 237499   epsilon: 0.7277500000059103    steps: 326    lr: 4e-05     evaluation reward: 2.82\nepisode: 1248   score: 5.0   memory length: 237823   epsilon: 0.7271084800059242    steps: 324    lr: 4e-05     evaluation reward: 2.86\nepisode: 1249   score: 2.0   memory length: 238003   epsilon: 0.7267520800059319    steps: 180    lr: 4e-05     evaluation reward: 2.82\nepisode: 1250   score: 4.0   memory length: 238279   epsilon: 0.7262056000059438    steps: 276    lr: 4e-05     evaluation reward: 2.82\nepisode: 1251   score: 1.0   memory length: 238430   epsilon: 0.7259066200059503    steps: 151    lr: 4e-05     evaluation reward: 2.8\nepisode: 1252   score: 2.0   memory length: 238611   epsilon: 0.7255482400059581    steps: 181    lr: 4e-05     evaluation reward: 2.82\nepisode: 1253   score: 3.0   memory length: 238836   epsilon: 0.7251027400059677    steps: 225    lr: 4e-05     evaluation reward: 2.85\nepisode: 1254   score: 0.0   memory length: 238958   epsilon: 0.724861180005973    steps: 122    lr: 4e-05     evaluation reward: 2.83\nepisode: 1255   score: 2.0   memory length: 239138   epsilon: 0.7245047800059807    steps: 180    lr: 4e-05     evaluation reward: 2.8\nepisode: 1256   score: 3.0   memory length: 239384   epsilon: 0.7240177000059913    steps: 246    lr: 4e-05     evaluation reward: 2.82\nepisode: 1257   score: 4.0   memory length: 239659   epsilon: 0.7234732000060031    steps: 275    lr: 4e-05     evaluation reward: 2.85\nepisode: 1258   score: 3.0   memory length: 239922   epsilon: 0.7229524600060144    steps: 263    lr: 4e-05     evaluation reward: 2.87\nepisode: 1259   score: 2.0   memory length: 240140   epsilon: 0.7225208200060238    steps: 218    lr: 4e-05     evaluation reward: 2.89\nepisode: 1260   score: 2.0   memory length: 240358   epsilon: 0.7220891800060332    steps: 218    lr: 4e-05     evaluation reward: 2.89\nepisode: 1261   score: 5.0   memory length: 240657   epsilon: 0.721497160006046    steps: 299    lr: 4e-05     evaluation reward: 2.9\nepisode: 1262   score: 0.0   memory length: 240779   epsilon: 0.7212556000060513    steps: 122    lr: 4e-05     evaluation reward: 2.88\nepisode: 1263   score: 3.0   memory length: 241007   epsilon: 0.7208041600060611    steps: 228    lr: 4e-05     evaluation reward: 2.87\nepisode: 1264   score: 6.0   memory length: 241398   epsilon: 0.7200299800060779    steps: 391    lr: 4e-05     evaluation reward: 2.91\nepisode: 1265   score: 5.0   memory length: 241725   epsilon: 0.7193825200060919    steps: 327    lr: 4e-05     evaluation reward: 2.93\nepisode: 1266   score: 4.0   memory length: 242039   epsilon: 0.7187608000061054    steps: 314    lr: 4e-05     evaluation reward: 2.95\nepisode: 1267   score: 2.0   memory length: 242259   epsilon: 0.7183252000061149    steps: 220    lr: 4e-05     evaluation reward: 2.93\nepisode: 1268   score: 3.0   memory length: 242523   epsilon: 0.7178024800061262    steps: 264    lr: 4e-05     evaluation reward: 2.93\nepisode: 1269   score: 6.0   memory length: 242918   epsilon: 0.7170203800061432    steps: 395    lr: 4e-05     evaluation reward: 2.96\nepisode: 1270   score: 2.0   memory length: 243136   epsilon: 0.7165887400061526    steps: 218    lr: 4e-05     evaluation reward: 2.91\nepisode: 1271   score: 2.0   memory length: 243335   epsilon: 0.7161947200061611    steps: 199    lr: 4e-05     evaluation reward: 2.93\nepisode: 1272   score: 2.0   memory length: 243554   epsilon: 0.7157611000061705    steps: 219    lr: 4e-05     evaluation reward: 2.91\nepisode: 1273   score: 1.0   memory length: 243725   epsilon: 0.7154225200061779    steps: 171    lr: 4e-05     evaluation reward: 2.89\nepisode: 1274   score: 3.0   memory length: 243955   epsilon: 0.7149671200061878    steps: 230    lr: 4e-05     evaluation reward: 2.9\nepisode: 1275   score: 3.0   memory length: 244182   epsilon: 0.7145176600061975    steps: 227    lr: 4e-05     evaluation reward: 2.88\nepisode: 1276   score: 2.0   memory length: 244362   epsilon: 0.7141612600062053    steps: 180    lr: 4e-05     evaluation reward: 2.9\nepisode: 1277   score: 3.0   memory length: 244591   epsilon: 0.7137078400062151    steps: 229    lr: 4e-05     evaluation reward: 2.9\nepisode: 1278   score: 3.0   memory length: 244817   epsilon: 0.7132603600062248    steps: 226    lr: 4e-05     evaluation reward: 2.91\nepisode: 1279   score: 4.0   memory length: 245114   epsilon: 0.7126723000062376    steps: 297    lr: 4e-05     evaluation reward: 2.93\nepisode: 1280   score: 3.0   memory length: 245341   epsilon: 0.7122228400062474    steps: 227    lr: 4e-05     evaluation reward: 2.94\nepisode: 1281   score: 2.0   memory length: 245521   epsilon: 0.7118664400062551    steps: 180    lr: 4e-05     evaluation reward: 2.96\nepisode: 1282   score: 1.0   memory length: 245673   epsilon: 0.7115654800062616    steps: 152    lr: 4e-05     evaluation reward: 2.94\nepisode: 1283   score: 3.0   memory length: 245898   epsilon: 0.7111199800062713    steps: 225    lr: 4e-05     evaluation reward: 2.96\nepisode: 1284   score: 3.0   memory length: 246145   epsilon: 0.7106309200062819    steps: 247    lr: 4e-05     evaluation reward: 2.96\nepisode: 1285   score: 3.0   memory length: 246374   epsilon: 0.7101775000062918    steps: 229    lr: 4e-05     evaluation reward: 2.97\nepisode: 1286   score: 2.0   memory length: 246555   epsilon: 0.7098191200062995    steps: 181    lr: 4e-05     evaluation reward: 2.98\nepisode: 1287   score: 3.0   memory length: 246783   epsilon: 0.7093676800063093    steps: 228    lr: 4e-05     evaluation reward: 2.98\nepisode: 1288   score: 3.0   memory length: 247031   epsilon: 0.70887664000632    steps: 248    lr: 4e-05     evaluation reward: 2.96\nepisode: 1289   score: 2.0   memory length: 247212   epsilon: 0.7085182600063278    steps: 181    lr: 4e-05     evaluation reward: 2.92\nepisode: 1290   score: 4.0   memory length: 247467   epsilon: 0.7080133600063387    steps: 255    lr: 4e-05     evaluation reward: 2.93\nepisode: 1291   score: 3.0   memory length: 247695   epsilon: 0.7075619200063485    steps: 228    lr: 4e-05     evaluation reward: 2.93\nepisode: 1292   score: 5.0   memory length: 248019   epsilon: 0.7069204000063625    steps: 324    lr: 4e-05     evaluation reward: 2.98\nepisode: 1293   score: 4.0   memory length: 248315   epsilon: 0.7063343200063752    steps: 296    lr: 4e-05     evaluation reward: 3.0\nepisode: 1457   score: 4.0   memory length: 290558   epsilon: 0.622693180008191    steps: 275    lr: 4e-05     evaluation reward: 3.83\nepisode: 1465   score: 5.0   memory length: 292667   epsilon: 0.6185173600082816    steps: 304    lr: 4e-05     evaluation reward: 3.93\nepisode: 1466   score: 3.0   memory length: 292899   epsilon: 0.6180580000082916    steps: 232    lr: 4e-05     evaluation reward: 3.93\nepisode: 1467   score: 3.0   memory length: 293145   epsilon: 0.6175709200083022    steps: 246    lr: 4e-05     evaluation reward: 3.89\nepisode: 1468   score: 3.0   memory length: 293377   epsilon: 0.6171115600083121    steps: 232    lr: 4e-05     evaluation reward: 3.9\nepisode: 1469   score: 4.0   memory length: 293672   epsilon: 0.6165274600083248    steps: 295    lr: 4e-05     evaluation reward: 3.9\nepisode: 1470   score: 3.0   memory length: 293917   epsilon: 0.6160423600083353    steps: 245    lr: 4e-05     evaluation reward: 3.91\nepisode: 1471   score: 2.0   memory length: 294098   epsilon: 0.6156839800083431    steps: 181    lr: 4e-05     evaluation reward: 3.89\nepisode: 1472   score: 2.0   memory length: 294296   epsilon: 0.6152919400083516    steps: 198    lr: 4e-05     evaluation reward: 3.89\nepisode: 1473   score: 3.0   memory length: 294545   epsilon: 0.6147989200083623    steps: 249    lr: 4e-05     evaluation reward: 3.89\nepisode: 1474   score: 7.0   memory length: 294913   epsilon: 0.6140702800083782    steps: 368    lr: 4e-05     evaluation reward: 3.93\nepisode: 1475   score: 2.0   memory length: 295111   epsilon: 0.6136782400083867    steps: 198    lr: 4e-05     evaluation reward: 3.89\nepisode: 1476   score: 3.0   memory length: 295337   epsilon: 0.6132307600083964    steps: 226    lr: 4e-05     evaluation reward: 3.87\nepisode: 1477   score: 3.0   memory length: 295563   epsilon: 0.6127832800084061    steps: 226    lr: 4e-05     evaluation reward: 3.86\nepisode: 1478   score: 2.0   memory length: 295761   epsilon: 0.6123912400084146    steps: 198    lr: 4e-05     evaluation reward: 3.86\nepisode: 1479   score: 3.0   memory length: 295988   epsilon: 0.6119417800084244    steps: 227    lr: 4e-05     evaluation reward: 3.87\nepisode: 1480   score: 5.0   memory length: 296278   epsilon: 0.6113675800084368    steps: 290    lr: 4e-05     evaluation reward: 3.9\nepisode: 1481   score: 2.0   memory length: 296477   epsilon: 0.6109735600084454    steps: 199    lr: 4e-05     evaluation reward: 3.87\nepisode: 1482   score: 4.0   memory length: 296736   epsilon: 0.6104607400084565    steps: 259    lr: 4e-05     evaluation reward: 3.9\nepisode: 1483   score: 2.0   memory length: 296938   epsilon: 0.6100607800084652    steps: 202    lr: 4e-05     evaluation reward: 3.87\nepisode: 1484   score: 8.0   memory length: 297385   epsilon: 0.6091757200084844    steps: 447    lr: 4e-05     evaluation reward: 3.87\nepisode: 1485   score: 3.0   memory length: 297615   epsilon: 0.6087203200084943    steps: 230    lr: 4e-05     evaluation reward: 3.82\nepisode: 1486   score: 4.0   memory length: 297877   epsilon: 0.6082015600085056    steps: 262    lr: 4e-05     evaluation reward: 3.8\nepisode: 1487   score: 3.0   memory length: 298090   epsilon: 0.6077798200085147    steps: 213    lr: 4e-05     evaluation reward: 3.8\nepisode: 1488   score: 7.0   memory length: 298516   epsilon: 0.606936340008533    steps: 426    lr: 4e-05     evaluation reward: 3.83\nepisode: 1489   score: 10.0   memory length: 299017   epsilon: 0.6059443600085546    steps: 501    lr: 4e-05     evaluation reward: 3.86\nepisode: 1490   score: 3.0   memory length: 299228   epsilon: 0.6055265800085636    steps: 211    lr: 4e-05     evaluation reward: 3.85\nepisode: 1491   score: 5.0   memory length: 299554   epsilon: 0.6048811000085776    steps: 326    lr: 4e-05     evaluation reward: 3.85\nepisode: 1492   score: 5.0   memory length: 299880   epsilon: 0.6042356200085917    steps: 326    lr: 4e-05     evaluation reward: 3.85\nepisode: 1493   score: 1.0   memory length: 300031   epsilon: 0.6039366400085981    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.81\nepisode: 1494   score: 5.0   memory length: 300375   epsilon: 0.6032555200086129    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.83\nepisode: 1495   score: 6.0   memory length: 300729   epsilon: 0.6025546000086281    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 3.88\nepisode: 1496   score: 5.0   memory length: 301040   epsilon: 0.6019388200086415    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 3.9\nepisode: 1497   score: 5.0   memory length: 301386   epsilon: 0.6012537400086564    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 3.92\nepisode: 1498   score: 3.0   memory length: 301612   epsilon: 0.6008062600086661    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.91\nepisode: 1499   score: 5.0   memory length: 301897   epsilon: 0.6002419600086784    steps: 285    lr: 1.6000000000000003e-05     evaluation reward: 3.91\nepisode: 1500   score: 3.0   memory length: 302166   epsilon: 0.5997093400086899    steps: 269    lr: 1.6000000000000003e-05     evaluation reward: 3.88\nepisode: 1501   score: 2.0   memory length: 302383   epsilon: 0.5992796800086992    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1502   score: 3.0   memory length: 302596   epsilon: 0.5988579400087084    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.84\nepisode: 1503   score: 2.0   memory length: 302794   epsilon: 0.5984659000087169    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.83\nepisode: 1504   score: 4.0   memory length: 303071   epsilon: 0.5979174400087288    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.84\nepisode: 1505   score: 6.0   memory length: 303444   epsilon: 0.5971789000087449    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 3.87\nepisode: 1506   score: 4.0   memory length: 303742   epsilon: 0.5965888600087577    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.85\nepisode: 1507   score: 3.0   memory length: 303968   epsilon: 0.5961413800087674    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.85\nepisode: 1508   score: 7.0   memory length: 304351   epsilon: 0.5953830400087838    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 3.88\nepisode: 1509   score: 3.0   memory length: 304564   epsilon: 0.594961300008793    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.82\nepisode: 1510   score: 7.0   memory length: 304930   epsilon: 0.5942366200088087    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 3.88\nepisode: 1511   score: 3.0   memory length: 305175   epsilon: 0.5937515200088193    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1512   score: 2.0   memory length: 305394   epsilon: 0.5933179000088287    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.85\nepisode: 1513   score: 5.0   memory length: 305699   epsilon: 0.5927140000088418    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 3.87\nepisode: 1514   score: 2.0   memory length: 305880   epsilon: 0.5923556200088496    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.88\nepisode: 1515   score: 4.0   memory length: 306155   epsilon: 0.5918111200088614    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.9\nepisode: 1516   score: 2.0   memory length: 306336   epsilon: 0.5914527400088692    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.88\nepisode: 1517   score: 5.0   memory length: 306680   epsilon: 0.590771620008884    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.89\nepisode: 1518   score: 7.0   memory length: 307072   epsilon: 0.5899954600089008    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 3.94\nepisode: 1519   score: 5.0   memory length: 307360   epsilon: 0.5894252200089132    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 3.95\nepisode: 1520   score: 5.0   memory length: 307685   epsilon: 0.5887817200089271    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.95\nepisode: 1521   score: 6.0   memory length: 308059   epsilon: 0.5880412000089432    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 3.96\nepisode: 1522   score: 4.0   memory length: 308318   epsilon: 0.5875283800089544    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.97\nepisode: 1523   score: 5.0   memory length: 308632   epsilon: 0.5869066600089679    steps: 314    lr: 1.6000000000000003e-05     evaluation reward: 3.99\nepisode: 1524   score: 2.0   memory length: 308830   epsilon: 0.5865146200089764    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.0\nepisode: 1525   score: 3.0   memory length: 309056   epsilon: 0.5860671400089861    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.0\nepisode: 1526   score: 7.0   memory length: 309436   epsilon: 0.5853147400090024    steps: 380    lr: 1.6000000000000003e-05     evaluation reward: 4.02\nepisode: 1527   score: 2.0   memory length: 309634   epsilon: 0.5849227000090109    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.98\nepisode: 1528   score: 9.0   memory length: 310065   epsilon: 0.5840693200090294    steps: 431    lr: 1.6000000000000003e-05     evaluation reward: 4.05\nepisode: 1529   score: 3.0   memory length: 310311   epsilon: 0.58358224000904    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.06\nepisode: 1597   score: 6.0   memory length: 330207   epsilon: 0.5441881600098952    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1598   score: 2.0   memory length: 330407   epsilon: 0.5437921600099038    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1662   score: 6.0   memory length: 349744   epsilon: 0.505504900010735    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1663   score: 5.0   memory length: 350046   epsilon: 0.504906940010748    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1671   score: 6.0   memory length: 352430   epsilon: 0.5001866200108505    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 4.48\nepisode: 1672   score: 4.0   memory length: 352689   epsilon: 0.49967380001085243    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.48\nepisode: 1673   score: 2.0   memory length: 352887   epsilon: 0.49928176001084995    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1674   score: 6.0   memory length: 353224   epsilon: 0.49861450001084573    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 4.52\nepisode: 1675   score: 3.0   memory length: 353450   epsilon: 0.4981670200108429    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.52\nepisode: 1676   score: 3.0   memory length: 353695   epsilon: 0.49768192001083983    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1677   score: 4.0   memory length: 353954   epsilon: 0.4971691000108366    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.5\nepisode: 1678   score: 6.0   memory length: 354329   epsilon: 0.4964266000108319    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.51\nepisode: 1679   score: 3.0   memory length: 354542   epsilon: 0.4960048600108292    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.51\nepisode: 1680   score: 6.0   memory length: 354905   epsilon: 0.49528612001082467    steps: 363    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1681   score: 3.0   memory length: 355151   epsilon: 0.4947990400108216    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1682   score: 3.0   memory length: 355398   epsilon: 0.4943099800108185    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.5\nepisode: 1683   score: 2.0   memory length: 355580   epsilon: 0.4939496200108162    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.5\nepisode: 1684   score: 6.0   memory length: 355956   epsilon: 0.4932051400108115    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1685   score: 4.0   memory length: 356235   epsilon: 0.492652720010808    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.47\nepisode: 1686   score: 5.0   memory length: 356541   epsilon: 0.4920468400108042    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.47\nepisode: 1687   score: 5.0   memory length: 356864   epsilon: 0.49140730001080013    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 4.48\nepisode: 1688   score: 4.0   memory length: 357124   epsilon: 0.4908925000107969    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1689   score: 5.0   memory length: 357453   epsilon: 0.49024108001079275    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.51\nepisode: 1690   score: 3.0   memory length: 357703   epsilon: 0.4897460800107896    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 4.48\nepisode: 1691   score: 5.0   memory length: 358027   epsilon: 0.48910456001078556    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1692   score: 8.0   memory length: 358480   epsilon: 0.4882076200107799    steps: 453    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1693   score: 5.0   memory length: 358804   epsilon: 0.4875661000107758    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.54\nepisode: 1694   score: 4.0   memory length: 359062   epsilon: 0.4870552600107726    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.54\nepisode: 1695   score: 4.0   memory length: 359359   epsilon: 0.4864672000107689    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.54\nepisode: 1696   score: 3.0   memory length: 359572   epsilon: 0.4860454600107662    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.52\nepisode: 1697   score: 7.0   memory length: 359993   epsilon: 0.48521188001076093    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1698   score: 7.0   memory length: 360391   epsilon: 0.48442384001075595    steps: 398    lr: 1.6000000000000003e-05     evaluation reward: 4.58\nepisode: 1699   score: 9.0   memory length: 360868   epsilon: 0.48347938001074997    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 4.62\nepisode: 1700   score: 2.0   memory length: 361068   epsilon: 0.48308338001074747    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.61\nepisode: 1701   score: 7.0   memory length: 361473   epsilon: 0.4822814800107424    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1702   score: 3.0   memory length: 361701   epsilon: 0.48183004001073954    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1703   score: 5.0   memory length: 362014   epsilon: 0.4812103000107356    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1704   score: 9.0   memory length: 362448   epsilon: 0.4803509800107302    steps: 434    lr: 1.6000000000000003e-05     evaluation reward: 4.68\nepisode: 1705   score: 5.0   memory length: 362751   epsilon: 0.4797510400107264    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1706   score: 3.0   memory length: 363001   epsilon: 0.47925604001072325    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1707   score: 6.0   memory length: 363363   epsilon: 0.4785392800107187    steps: 362    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1708   score: 3.0   memory length: 363631   epsilon: 0.47800864001071536    steps: 268    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1709   score: 7.0   memory length: 364073   epsilon: 0.4771334800107098    steps: 442    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1710   score: 5.0   memory length: 364383   epsilon: 0.47651968001070594    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.71\nepisode: 1711   score: 3.0   memory length: 364611   epsilon: 0.4760682400107031    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1712   score: 5.0   memory length: 364900   epsilon: 0.47549602001069946    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.72\nepisode: 1713   score: 3.0   memory length: 365110   epsilon: 0.47508022001069683    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.71\nepisode: 1714   score: 3.0   memory length: 365338   epsilon: 0.474628780010694    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1715   score: 4.0   memory length: 365597   epsilon: 0.47411596001069073    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1716   score: 6.0   memory length: 365940   epsilon: 0.47343682001068643    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.72\nepisode: 1717   score: 4.0   memory length: 366202   epsilon: 0.47291806001068315    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.73\nepisode: 1718   score: 3.0   memory length: 366430   epsilon: 0.4724666200106803    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1719   score: 4.0   memory length: 366708   epsilon: 0.4719161800106768    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1720   score: 6.0   memory length: 367064   epsilon: 0.47121130001067235    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1721   score: 2.0   memory length: 367264   epsilon: 0.47081530001066985    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1722   score: 6.0   memory length: 367600   epsilon: 0.47015002001066564    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 4.68\nepisode: 1723   score: 5.0   memory length: 367904   epsilon: 0.46954810001066183    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1724   score: 1.0   memory length: 368055   epsilon: 0.46924912001065994    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1725   score: 4.0   memory length: 368314   epsilon: 0.4687363000106567    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.62\nepisode: 1726   score: 7.0   memory length: 368681   epsilon: 0.4680096400106521    steps: 367    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1727   score: 6.0   memory length: 369052   epsilon: 0.46727506001064745    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1728   score: 3.0   memory length: 369299   epsilon: 0.46678600001064435    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1729   score: 6.0   memory length: 369654   epsilon: 0.4660831000106399    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1730   score: 3.0   memory length: 369900   epsilon: 0.4655960200106368    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1731   score: 5.0   memory length: 370223   epsilon: 0.4649564800106328    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1732   score: 5.0   memory length: 370511   epsilon: 0.46438624001062917    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1733   score: 5.0   memory length: 370856   epsilon: 0.46370314001062485    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1734   score: 6.0   memory length: 371188   epsilon: 0.4630457800106207    steps: 332    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1735   score: 7.0   memory length: 371597   epsilon: 0.46223596001061557    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 4.71\nepisode: 1736   score: 3.0   memory length: 371844   epsilon: 0.46174690001061247    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1737   score: 3.0   memory length: 372055   epsilon: 0.46132912001060983    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1738   score: 7.0   memory length: 372434   epsilon: 0.4605787000106051    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1739   score: 7.0   memory length: 372845   epsilon: 0.45976492001059993    steps: 411    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1740   score: 4.0   memory length: 373102   epsilon: 0.4592560600105967    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1741   score: 4.0   memory length: 373362   epsilon: 0.45874126001059345    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1742   score: 6.0   memory length: 373673   epsilon: 0.45812548001058956    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1743   score: 3.0   memory length: 373884   epsilon: 0.4577077000105869    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1744   score: 8.0   memory length: 374318   epsilon: 0.4568483800105815    steps: 434    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1745   score: 3.0   memory length: 374531   epsilon: 0.4564266400105788    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1746   score: 5.0   memory length: 374856   epsilon: 0.45578314001057474    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1747   score: 4.0   memory length: 375119   epsilon: 0.45526240001057144    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 4.68\nepisode: 1748   score: 6.0   memory length: 375474   epsilon: 0.454559500010567    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.71\nepisode: 1749   score: 6.0   memory length: 375846   epsilon: 0.45382294001056234    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.73\nepisode: 1750   score: 2.0   memory length: 376028   epsilon: 0.45346258001056006    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.73\nepisode: 1751   score: 3.0   memory length: 376240   epsilon: 0.4530428200105574    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1752   score: 5.0   memory length: 376545   epsilon: 0.4524389200105536    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1753   score: 7.0   memory length: 376924   epsilon: 0.45168850001054883    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1796   score: 12.0   memory length: 390915   epsilon: 0.42398632001037356    steps: 437    lr: 1.6000000000000003e-05     evaluation reward: 5.08\nepisode: 1797   score: 4.0   memory length: 391191   epsilon: 0.4234398400103701    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 5.05\nepisode: 1803   score: 5.0   memory length: 393314   epsilon: 0.4192363000103435    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.1\nepisode: 1804   score: 5.0   memory length: 393622   epsilon: 0.41862646001033965    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.06\nepisode: 1805   score: 3.0   memory length: 393848   epsilon: 0.4181789800103368    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 5.04\nepisode: 1806   score: 4.0   memory length: 394126   epsilon: 0.41762854001033334    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 5.05\nepisode: 1807   score: 4.0   memory length: 394388   epsilon: 0.41710978001033006    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1808   score: 3.0   memory length: 394601   epsilon: 0.4166880400103274    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1809   score: 7.0   memory length: 394987   epsilon: 0.41592376001032255    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1810   score: 2.0   memory length: 395203   epsilon: 0.41549608001031985    steps: 216    lr: 1.6000000000000003e-05     evaluation reward: 5.0\nepisode: 1811   score: 1.0   memory length: 395353   epsilon: 0.41519908001031797    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.98\nepisode: 1812   score: 4.0   memory length: 395613   epsilon: 0.4146842800103147    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.97\nepisode: 1813   score: 2.0   memory length: 395794   epsilon: 0.41432590001031244    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.96\nepisode: 1814   score: 3.0   memory length: 396005   epsilon: 0.4139081200103098    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.96\nepisode: 1815   score: 9.0   memory length: 396462   epsilon: 0.4130032600103041    steps: 457    lr: 1.6000000000000003e-05     evaluation reward: 5.01\nepisode: 1816   score: 6.0   memory length: 396818   epsilon: 0.4122983800102996    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 5.01\nepisode: 1817   score: 6.0   memory length: 397190   epsilon: 0.41156182001029495    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1818   score: 3.0   memory length: 397416   epsilon: 0.4111143400102921    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1819   score: 3.0   memory length: 397645   epsilon: 0.41066092001028925    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.02\nepisode: 1820   score: 6.0   memory length: 397980   epsilon: 0.40999762001028506    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 5.02\nepisode: 1821   score: 3.0   memory length: 398191   epsilon: 0.4095798400102824    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1822   score: 5.0   memory length: 398497   epsilon: 0.4089739600102786    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 5.02\nepisode: 1823   score: 3.0   memory length: 398710   epsilon: 0.4085522200102759    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 5.0\nepisode: 1824   score: 6.0   memory length: 399084   epsilon: 0.4078117000102712    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 5.05\nepisode: 1825   score: 4.0   memory length: 399340   epsilon: 0.407304820010268    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 5.05\nepisode: 1826   score: 5.0   memory length: 399649   epsilon: 0.40669300001026415    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.03\nepisode: 1827   score: 8.0   memory length: 400069   epsilon: 0.4058614000102589    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 5.05\nepisode: 1828   score: 5.0   memory length: 400373   epsilon: 0.4052594800102551    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 5.07\nepisode: 1829   score: 9.0   memory length: 400864   epsilon: 0.40428730001024893    steps: 491    lr: 6.400000000000001e-06     evaluation reward: 5.1\nepisode: 1830   score: 3.0   memory length: 401077   epsilon: 0.40386556001024626    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.1\nepisode: 1831   score: 4.0   memory length: 401319   epsilon: 0.40338640001024323    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.09\nepisode: 1832   score: 3.0   memory length: 401532   epsilon: 0.40296466001024056    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.07\nepisode: 1833   score: 7.0   memory length: 401899   epsilon: 0.40223800001023596    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 5.09\nepisode: 1834   score: 4.0   memory length: 402158   epsilon: 0.4017251800102327    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.07\nepisode: 1835   score: 7.0   memory length: 402526   epsilon: 0.4009965400102281    steps: 368    lr: 6.400000000000001e-06     evaluation reward: 5.07\nepisode: 1836   score: 6.0   memory length: 402871   epsilon: 0.4003134400102238    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 5.1\nepisode: 1837   score: 7.0   memory length: 403289   epsilon: 0.39948580001021855    steps: 418    lr: 6.400000000000001e-06     evaluation reward: 5.14\nepisode: 1838   score: 5.0   memory length: 403613   epsilon: 0.3988442800102145    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 5.12\nepisode: 1839   score: 7.0   memory length: 404019   epsilon: 0.3980404000102094    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 5.12\nepisode: 1840   score: 5.0   memory length: 404325   epsilon: 0.39743452001020557    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 5.13\nepisode: 1841   score: 5.0   memory length: 404650   epsilon: 0.3967910200102015    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 5.14\nepisode: 1842   score: 3.0   memory length: 404876   epsilon: 0.39634354001019867    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 5.11\nepisode: 1843   score: 7.0   memory length: 405302   epsilon: 0.39550006001019333    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 5.15\nepisode: 1844   score: 9.0   memory length: 405766   epsilon: 0.3945813400101875    steps: 464    lr: 6.400000000000001e-06     evaluation reward: 5.16\nepisode: 1845   score: 4.0   memory length: 406026   epsilon: 0.39406654001018426    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.17\nepisode: 1846   score: 6.0   memory length: 406382   epsilon: 0.3933616600101798    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 5.18\nepisode: 1847   score: 3.0   memory length: 406595   epsilon: 0.39293992001017714    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.17\nepisode: 1848   score: 5.0   memory length: 406885   epsilon: 0.3923657200101735    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 5.16\nepisode: 1849   score: 5.0   memory length: 407196   epsilon: 0.3917499400101696    steps: 311    lr: 6.400000000000001e-06     evaluation reward: 5.15\nepisode: 1850   score: 7.0   memory length: 407618   epsilon: 0.3909143800101643    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 1851   score: 3.0   memory length: 407867   epsilon: 0.3904213600101612    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 1852   score: 14.0   memory length: 408398   epsilon: 0.38936998001015455    steps: 531    lr: 6.400000000000001e-06     evaluation reward: 5.29\nepisode: 1853   score: 4.0   memory length: 408653   epsilon: 0.38886508001015135    steps: 255    lr: 6.400000000000001e-06     evaluation reward: 5.26\nepisode: 1854   score: 5.0   memory length: 408997   epsilon: 0.38818396001014704    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 5.28\nepisode: 1855   score: 6.0   memory length: 409387   epsilon: 0.38741176001014216    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 5.3\nepisode: 1856   score: 3.0   memory length: 409612   epsilon: 0.38696626001013934    steps: 225    lr: 6.400000000000001e-06     evaluation reward: 5.3\nepisode: 1857   score: 7.0   memory length: 410005   epsilon: 0.3861881200101344    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 5.31\nepisode: 1914   score: 8.0   memory length: 428847   epsilon: 0.3488809600098984    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 5.64\nepisode: 1915   score: 3.0   memory length: 429059   epsilon: 0.3484612000098957    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.58\nepisode: 1916   score: 3.0   memory length: 429272   epsilon: 0.34803946000989305    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.55\nepisode: 1917   score: 8.0   memory length: 429680   epsilon: 0.34723162000988794    steps: 408    lr: 6.400000000000001e-06     evaluation reward: 5.57\nepisode: 1918   score: 9.0   memory length: 430174   epsilon: 0.34625350000988175    steps: 494    lr: 6.400000000000001e-06     evaluation reward: 5.63\nepisode: 1919   score: 7.0   memory length: 430575   epsilon: 0.34545952000987673    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 5.67\nepisode: 1920   score: 4.0   memory length: 430831   epsilon: 0.3449526400098735    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 5.65\nepisode: 1921   score: 5.0   memory length: 431121   epsilon: 0.3443784400098699    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 5.67\nepisode: 1922   score: 3.0   memory length: 431334   epsilon: 0.3439567000098672    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.65\nepisode: 1923   score: 6.0   memory length: 431691   epsilon: 0.34324984000986275    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 5.68\nepisode: 1924   score: 7.0   memory length: 432097   epsilon: 0.34244596000985766    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 1925   score: 7.0   memory length: 432460   epsilon: 0.3417272200098531    steps: 363    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 1926   score: 3.0   memory length: 432689   epsilon: 0.34127380000985025    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.7\nepisode: 1927   score: 6.0   memory length: 433047   epsilon: 0.34056496000984576    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 5.68\nepisode: 1928   score: 5.0   memory length: 433339   epsilon: 0.3399868000098421    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 5.68\nepisode: 1929   score: 6.0   memory length: 433682   epsilon: 0.3393076600098378    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 5.65\nepisode: 1930   score: 7.0   memory length: 434076   epsilon: 0.3385275400098329    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 1931   score: 10.0   memory length: 434578   epsilon: 0.3375335800098266    steps: 502    lr: 6.400000000000001e-06     evaluation reward: 5.75\nepisode: 1932   score: 5.0   memory length: 434887   epsilon: 0.3369217600098227    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 1933   score: 7.0   memory length: 435270   epsilon: 0.3361634200098179    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 1934   score: 4.0   memory length: 435564   epsilon: 0.33558130000981423    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 1935   score: 4.0   memory length: 435841   epsilon: 0.33503284000981076    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.74\nepisode: 1936   score: 5.0   memory length: 436150   epsilon: 0.3344210200098069    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 1937   score: 7.0   memory length: 436537   epsilon: 0.33365476000980204    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 1938   score: 3.0   memory length: 436750   epsilon: 0.3332330200097994    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.71\nepisode: 1939   score: 6.0   memory length: 437103   epsilon: 0.33253408000979495    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 5.7\nepisode: 1940   score: 8.0   memory length: 437557   epsilon: 0.33163516000978926    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 1941   score: 7.0   memory length: 437977   epsilon: 0.330803560009784    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 5.75\nepisode: 1942   score: 4.0   memory length: 438218   epsilon: 0.330326380009781    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 1943   score: 2.0   memory length: 438418   epsilon: 0.3299303800097785    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 5.71\nepisode: 1944   score: 4.0   memory length: 438681   epsilon: 0.3294096400097752    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.66\nepisode: 1945   score: 6.0   memory length: 439009   epsilon: 0.3287602000097711    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 5.68\nepisode: 1946   score: 7.0   memory length: 439415   epsilon: 0.327956320009766    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 1947   score: 7.0   memory length: 439842   epsilon: 0.32711086000976064    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 1948   score: 5.0   memory length: 440169   epsilon: 0.32646340000975654    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 1949   score: 5.0   memory length: 440462   epsilon: 0.3258832600097529    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 1950   score: 3.0   memory length: 440674   epsilon: 0.3254635000097502    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 1951   score: 6.0   memory length: 441053   epsilon: 0.32471308000974547    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 1952   score: 5.0   memory length: 441358   epsilon: 0.32410918000974165    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 5.63\nepisode: 1953   score: 5.0   memory length: 441649   epsilon: 0.323533000009738    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 5.64\nepisode: 1954   score: 3.0   memory length: 441862   epsilon: 0.32311126000973533    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.62\nepisode: 1955   score: 5.0   memory length: 442185   epsilon: 0.3224717200097313    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 5.61\nepisode: 1956   score: 7.0   memory length: 442609   epsilon: 0.321632200009726    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 5.65\nepisode: 1957   score: 5.0   memory length: 442902   epsilon: 0.3210520600097223    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 5.63\nepisode: 1958   score: 4.0   memory length: 443163   epsilon: 0.32053528000971904    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 5.63\nepisode: 1959   score: 4.0   memory length: 443421   epsilon: 0.3200244400097158    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 5.57\nepisode: 2007   score: 6.0   memory length: 460124   epsilon: 0.28695250000950656    steps: 317    lr: 6.400000000000001e-06     evaluation reward: 5.8\nepisode: 2008   score: 5.0   memory length: 460430   epsilon: 0.28634662000950273    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2009   score: 7.0   memory length: 460822   epsilon: 0.2855704600094978    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2010   score: 7.0   memory length: 461245   epsilon: 0.2847329200094925    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2011   score: 20.0   memory length: 461789   epsilon: 0.2836558000094857    steps: 544    lr: 6.400000000000001e-06     evaluation reward: 5.95\nepisode: 2012   score: 5.0   memory length: 462110   epsilon: 0.2830202200094817    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 5.94\nepisode: 2013   score: 3.0   memory length: 462341   epsilon: 0.2825628400094788    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 5.92\nepisode: 2063   score: 4.0   memory length: 478623   epsilon: 0.2503244800092748    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.0\nepisode: 2064   score: 3.0   memory length: 478834   epsilon: 0.24990670000927218    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 5.94\nepisode: 2065   score: 4.0   memory length: 479097   epsilon: 0.24938596000926888    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.88\nepisode: 2066   score: 6.0   memory length: 479423   epsilon: 0.2487404800092648    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.87\nepisode: 2067   score: 8.0   memory length: 479833   epsilon: 0.24792868000925966    steps: 410    lr: 6.400000000000001e-06     evaluation reward: 5.87\nepisode: 2068   score: 7.0   memory length: 480236   epsilon: 0.2471307400092546    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 5.91\nepisode: 2069   score: 5.0   memory length: 480527   epsilon: 0.24655456000925097    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 5.92\nepisode: 2070   score: 6.0   memory length: 480881   epsilon: 0.24585364000924653    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 5.92\nepisode: 2071   score: 5.0   memory length: 481188   epsilon: 0.2452457800092427    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 5.9\nepisode: 2072   score: 5.0   memory length: 481481   epsilon: 0.24466564000923902    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 5.91\nepisode: 2073   score: 5.0   memory length: 481794   epsilon: 0.2440459000092351    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 5.87\nepisode: 2074   score: 4.0   memory length: 482055   epsilon: 0.24352912000923183    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 5.88\nepisode: 2075   score: 4.0   memory length: 482338   epsilon: 0.24296878000922828    steps: 283    lr: 6.400000000000001e-06     evaluation reward: 5.85\nepisode: 2076   score: 6.0   memory length: 482698   epsilon: 0.24225598000922377    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 5.83\nepisode: 2077   score: 4.0   memory length: 482940   epsilon: 0.24177682000922074    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.78\nepisode: 2078   score: 8.0   memory length: 483339   epsilon: 0.24098680000921574    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 5.83\nepisode: 2079   score: 3.0   memory length: 483550   epsilon: 0.2405690200092131    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2080   score: 7.0   memory length: 483976   epsilon: 0.23972554000920776    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 5.78\nepisode: 2081   score: 4.0   memory length: 484239   epsilon: 0.23920480000920447    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2082   score: 15.0   memory length: 484839   epsilon: 0.23801680000919695    steps: 600    lr: 6.400000000000001e-06     evaluation reward: 5.85\nepisode: 2083   score: 4.0   memory length: 485098   epsilon: 0.2375039800091937    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.84\nepisode: 2084   score: 6.0   memory length: 485471   epsilon: 0.23676544000918903    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 5.8\nepisode: 2085   score: 7.0   memory length: 485873   epsilon: 0.235969480009184    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 5.81\nepisode: 2086   score: 9.0   memory length: 486318   epsilon: 0.23508838000917842    steps: 445    lr: 6.400000000000001e-06     evaluation reward: 5.84\nepisode: 2087   score: 2.0   memory length: 486499   epsilon: 0.23473000000917615    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 5.81\nepisode: 2088   score: 4.0   memory length: 486758   epsilon: 0.2342171800091729    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.81\nepisode: 2089   score: 10.0   memory length: 487293   epsilon: 0.2331578800091662    steps: 535    lr: 6.400000000000001e-06     evaluation reward: 5.85\nepisode: 2090   score: 7.0   memory length: 487681   epsilon: 0.23238964000916135    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 5.88\nepisode: 2091   score: 5.0   memory length: 487969   epsilon: 0.23181940000915774    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 5.86\nepisode: 2092   score: 4.0   memory length: 488228   epsilon: 0.2313065800091545    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.85\nepisode: 2093   score: 11.0   memory length: 488776   epsilon: 0.23022154000914763    steps: 548    lr: 6.400000000000001e-06     evaluation reward: 5.9\nepisode: 2094   score: 7.0   memory length: 489162   epsilon: 0.2294572600091428    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 5.9\nepisode: 2095   score: 7.0   memory length: 489567   epsilon: 0.22865536000913772    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 5.9\nepisode: 2096   score: 5.0   memory length: 489840   epsilon: 0.2281148200091343    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 5.87\nepisode: 2097   score: 8.0   memory length: 490281   epsilon: 0.22724164000912878    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 5.92\nepisode: 2098   score: 6.0   memory length: 490637   epsilon: 0.22653676000912432    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 5.93\nepisode: 2099   score: 9.0   memory length: 491106   epsilon: 0.22560814000911844    steps: 469    lr: 6.400000000000001e-06     evaluation reward: 5.94\nepisode: 2100   score: 7.0   memory length: 491496   epsilon: 0.22483594000911356    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 5.94\nepisode: 2101   score: 3.0   memory length: 491709   epsilon: 0.2244142000091109    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.88\nepisode: 2102   score: 4.0   memory length: 491966   epsilon: 0.22390534000910767    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.85\nepisode: 2103   score: 9.0   memory length: 492435   epsilon: 0.2229767200091018    steps: 469    lr: 6.400000000000001e-06     evaluation reward: 5.89\nepisode: 2104   score: 2.0   memory length: 492617   epsilon: 0.2226163600090995    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 5.87\nepisode: 2105   score: 3.0   memory length: 492830   epsilon: 0.22219462000909684    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.85\nepisode: 2106   score: 5.0   memory length: 493118   epsilon: 0.22162438000909324    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 5.84\nepisode: 2107   score: 3.0   memory length: 493331   epsilon: 0.22120264000909057    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.81\nepisode: 2108   score: 5.0   memory length: 493602   epsilon: 0.22066606000908717    steps: 271    lr: 6.400000000000001e-06     evaluation reward: 5.81\nepisode: 2109   score: 9.0   memory length: 493946   epsilon: 0.21998494000908286    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 5.83\nepisode: 2110   score: 3.0   memory length: 494175   epsilon: 0.21953152000908    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2111   score: 4.0   memory length: 494438   epsilon: 0.2190107800090767    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.63\nepisode: 2112   score: 13.0   memory length: 495109   epsilon: 0.2176822000090683    steps: 671    lr: 6.400000000000001e-06     evaluation reward: 5.71\nepisode: 2113   score: 5.0   memory length: 495434   epsilon: 0.21703870000906422    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 2114   score: 13.0   memory length: 495934   epsilon: 0.21604870000905796    steps: 500    lr: 6.400000000000001e-06     evaluation reward: 5.82\nepisode: 2115   score: 3.0   memory length: 496147   epsilon: 0.2156269600090553    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2116   score: 3.0   memory length: 496360   epsilon: 0.21520522000905262    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.75\nepisode: 2117   score: 9.0   memory length: 496859   epsilon: 0.21421720000904637    steps: 499    lr: 6.400000000000001e-06     evaluation reward: 5.78\nepisode: 2118   score: 3.0   memory length: 497072   epsilon: 0.2137954600090437    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2119   score: 5.0   memory length: 497378   epsilon: 0.21318958000903987    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2120   score: 7.0   memory length: 497782   epsilon: 0.2123896600090348    steps: 404    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2121   score: 4.0   memory length: 498042   epsilon: 0.21187486000903155    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2122   score: 5.0   memory length: 498333   epsilon: 0.2112986800090279    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2123   score: 3.0   memory length: 498546   epsilon: 0.21087694000902524    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2124   score: 5.0   memory length: 498833   epsilon: 0.21030868000902164    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2125   score: 9.0   memory length: 499289   epsilon: 0.20940580000901593    steps: 456    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2126   score: 6.0   memory length: 499632   epsilon: 0.20872666000901163    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2127   score: 5.0   memory length: 499923   epsilon: 0.208150480009008    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2128   score: 4.0   memory length: 500184   epsilon: 0.20763370000900472    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 5.76\nepisode: 2129   score: 10.0   memory length: 500707   epsilon: 0.20659816000899817    steps: 523    lr: 2.560000000000001e-06     evaluation reward: 5.8\nepisode: 2130   score: 7.0   memory length: 501129   epsilon: 0.20576260000899288    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 5.8\nepisode: 2131   score: 7.0   memory length: 501495   epsilon: 0.2050379200089883    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 5.81\nepisode: 2132   score: 5.0   memory length: 501823   epsilon: 0.20438848000898419    steps: 328    lr: 2.560000000000001e-06     evaluation reward: 5.83\nepisode: 2133   score: 3.0   memory length: 502036   epsilon: 0.20396674000898152    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.8\nepisode: 2134   score: 3.0   memory length: 502247   epsilon: 0.20354896000897887    steps: 211    lr: 2.560000000000001e-06     evaluation reward: 5.76\nepisode: 2135   score: 9.0   memory length: 502733   epsilon: 0.20258668000897279    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 5.81\nepisode: 2136   score: 6.0   memory length: 503091   epsilon: 0.2018778400089683    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 5.83\nepisode: 2137   score: 9.0   memory length: 503533   epsilon: 0.20100268000896276    steps: 442    lr: 2.560000000000001e-06     evaluation reward: 5.84\nepisode: 2138   score: 4.0   memory length: 503773   epsilon: 0.20052748000895976    steps: 240    lr: 2.560000000000001e-06     evaluation reward: 5.81\nepisode: 2139   score: 7.0   memory length: 504198   epsilon: 0.19968598000895443    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 5.83\nepisode: 2140   score: 11.0   memory length: 504730   epsilon: 0.19863262000894777    steps: 532    lr: 2.560000000000001e-06     evaluation reward: 5.85\nepisode: 2141   score: 8.0   memory length: 505158   epsilon: 0.1977851800089424    steps: 428    lr: 2.560000000000001e-06     evaluation reward: 5.86\nepisode: 2142   score: 7.0   memory length: 505495   epsilon: 0.19711792000893819    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 5.9\nepisode: 2143   score: 3.0   memory length: 505708   epsilon: 0.19669618000893552    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.88\nepisode: 2144   score: 5.0   memory length: 505981   epsilon: 0.1961556400089321    steps: 273    lr: 2.560000000000001e-06     evaluation reward: 5.84\nepisode: 2145   score: 7.0   memory length: 506351   epsilon: 0.19542304000892746    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 5.82\nepisode: 2146   score: 12.0   memory length: 506907   epsilon: 0.1943221600089205    steps: 556    lr: 2.560000000000001e-06     evaluation reward: 5.86\nepisode: 2147   score: 9.0   memory length: 507374   epsilon: 0.19339750000891465    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 5.92\nepisode: 2148   score: 8.0   memory length: 507823   epsilon: 0.19250848000890902    steps: 449    lr: 2.560000000000001e-06     evaluation reward: 5.96\nepisode: 2149   score: 7.0   memory length: 508245   epsilon: 0.19167292000890374    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 5.99\nepisode: 2150   score: 3.0   memory length: 508458   epsilon: 0.19125118000890107    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.92\nepisode: 2151   score: 11.0   memory length: 508965   epsilon: 0.19024732000889472    steps: 507    lr: 2.560000000000001e-06     evaluation reward: 5.98\nepisode: 2152   score: 4.0   memory length: 509224   epsilon: 0.18973450000889147    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 5.98\nepisode: 2153   score: 3.0   memory length: 509436   epsilon: 0.18931474000888882    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 5.98\nepisode: 2154   score: 7.0   memory length: 509839   epsilon: 0.18851680000888377    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 5.97\nepisode: 2155   score: 5.0   memory length: 510148   epsilon: 0.1879049800088799    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 5.99\nepisode: 2156   score: 6.0   memory length: 510516   epsilon: 0.18717634000887529    steps: 368    lr: 2.560000000000001e-06     evaluation reward: 6.01\nepisode: 2157   score: 8.0   memory length: 510957   epsilon: 0.18630316000886976    steps: 441    lr: 2.560000000000001e-06     evaluation reward: 6.03\nepisode: 2158   score: 10.0   memory length: 511451   epsilon: 0.18532504000886357    steps: 494    lr: 2.560000000000001e-06     evaluation reward: 6.08\nepisode: 2159   score: 5.0   memory length: 511760   epsilon: 0.1847132200088597    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.09\nepisode: 2160   score: 9.0   memory length: 512242   epsilon: 0.18375886000885366    steps: 482    lr: 2.560000000000001e-06     evaluation reward: 6.13\nepisode: 2161   score: 7.0   memory length: 512668   epsilon: 0.18291538000884833    steps: 426    lr: 2.560000000000001e-06     evaluation reward: 6.12\nepisode: 2162   score: 3.0   memory length: 512881   epsilon: 0.18249364000884566    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.11\nepisode: 2163   score: 10.0   memory length: 513412   epsilon: 0.181442260008839    steps: 531    lr: 2.560000000000001e-06     evaluation reward: 6.17\nepisode: 2164   score: 9.0   memory length: 513849   epsilon: 0.18057700000883353    steps: 437    lr: 2.560000000000001e-06     evaluation reward: 6.23\nepisode: 2165   score: 5.0   memory length: 514120   epsilon: 0.18004042000883014    steps: 271    lr: 2.560000000000001e-06     evaluation reward: 6.24\nepisode: 2166   score: 5.0   memory length: 514426   epsilon: 0.1794345400088263    steps: 306    lr: 2.560000000000001e-06     evaluation reward: 6.23\nepisode: 2167   score: 3.0   memory length: 514639   epsilon: 0.17901280000882364    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.18\nepisode: 2168   score: 4.0   memory length: 514914   epsilon: 0.1784683000088202    steps: 275    lr: 2.560000000000001e-06     evaluation reward: 6.15\nepisode: 2169   score: 6.0   memory length: 515250   epsilon: 0.17780302000881598    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.16\nepisode: 2170   score: 6.0   memory length: 515572   epsilon: 0.17716546000881195    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 6.16\nepisode: 2171   score: 7.0   memory length: 515980   epsilon: 0.17635762000880684    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 6.18\nepisode: 2172   score: 6.0   memory length: 516354   epsilon: 0.17561710000880215    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 6.19\nepisode: 2173   score: 9.0   memory length: 516806   epsilon: 0.1747221400087965    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 6.23\nepisode: 2174   score: 15.0   memory length: 517422   epsilon: 0.17350246000878877    steps: 616    lr: 2.560000000000001e-06     evaluation reward: 6.34\nepisode: 2175   score: 9.0   memory length: 517875   epsilon: 0.1726055200087831    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 6.39\nepisode: 2176   score: 10.0   memory length: 518387   epsilon: 0.17159176000877668    steps: 512    lr: 2.560000000000001e-06     evaluation reward: 6.43\nepisode: 2177   score: 10.0   memory length: 518917   epsilon: 0.17054236000877004    steps: 530    lr: 2.560000000000001e-06     evaluation reward: 6.49\nepisode: 2178   score: 9.0   memory length: 519412   epsilon: 0.16956226000876384    steps: 495    lr: 2.560000000000001e-06     evaluation reward: 6.5\nepisode: 2179   score: 8.0   memory length: 519814   epsilon: 0.1687663000087588    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2180   score: 3.0   memory length: 520027   epsilon: 0.16834456000875614    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.51\nepisode: 2181   score: 5.0   memory length: 520354   epsilon: 0.16769710000875204    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 6.52\nepisode: 2182   score: 8.0   memory length: 520765   epsilon: 0.1668833200087469    steps: 411    lr: 2.560000000000001e-06     evaluation reward: 6.45\nepisode: 2183   score: 8.0   memory length: 521206   epsilon: 0.16601014000874137    steps: 441    lr: 2.560000000000001e-06     evaluation reward: 6.49\nepisode: 2184   score: 8.0   memory length: 521678   epsilon: 0.16507558000873546    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 6.51\nepisode: 2185   score: 14.0   memory length: 522233   epsilon: 0.1639766800087285    steps: 555    lr: 2.560000000000001e-06     evaluation reward: 6.58\nepisode: 2186   score: 3.0   memory length: 522446   epsilon: 0.16355494000872584    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.52\nepisode: 2187   score: 5.0   memory length: 522735   epsilon: 0.16298272000872221    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2188   score: 4.0   memory length: 522994   epsilon: 0.16246990000871897    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2189   score: 8.0   memory length: 523376   epsilon: 0.16171354000871418    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 6.53\nepisode: 2190   score: 8.0   memory length: 523793   epsilon: 0.16088788000870896    steps: 417    lr: 2.560000000000001e-06     evaluation reward: 6.54\nepisode: 2191   score: 6.0   memory length: 524147   epsilon: 0.16018696000870453    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2192   score: 3.0   memory length: 524360   epsilon: 0.15976522000870186    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.54\nepisode: 2193   score: 3.0   memory length: 524572   epsilon: 0.1593454600086992    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 6.46\nepisode: 2194   score: 5.0   memory length: 524897   epsilon: 0.15870196000869513    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 6.44\nepisode: 2195   score: 9.0   memory length: 525396   epsilon: 0.15771394000868888    steps: 499    lr: 2.560000000000001e-06     evaluation reward: 6.46\nepisode: 2196   score: 7.0   memory length: 525819   epsilon: 0.15687640000868358    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 6.48\nepisode: 2197   score: 4.0   memory length: 526079   epsilon: 0.15636160000868032    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.44\nepisode: 2198   score: 4.0   memory length: 526338   epsilon: 0.15584878000867708    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 6.42\nepisode: 2199   score: 9.0   memory length: 526786   epsilon: 0.15496174000867147    steps: 448    lr: 2.560000000000001e-06     evaluation reward: 6.42\nepisode: 2200   score: 3.0   memory length: 526999   epsilon: 0.1545400000086688    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.38\nepisode: 2201   score: 9.0   memory length: 527482   epsilon: 0.15358366000866275    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 6.44\nepisode: 2202   score: 3.0   memory length: 527693   epsilon: 0.1531658800086601    steps: 211    lr: 2.560000000000001e-06     evaluation reward: 6.43\nepisode: 2203   score: 4.0   memory length: 527935   epsilon: 0.15268672000865707    steps: 242    lr: 2.560000000000001e-06     evaluation reward: 6.38\nepisode: 2204   score: 6.0   memory length: 528310   epsilon: 0.15194422000865238    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.42\nepisode: 2205   score: 5.0   memory length: 528617   epsilon: 0.15133636000864853    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.44\nepisode: 2206   score: 7.0   memory length: 528863   epsilon: 0.15084928000864545    steps: 246    lr: 2.560000000000001e-06     evaluation reward: 6.46\nepisode: 2207   score: 8.0   memory length: 529313   epsilon: 0.1499582800086398    steps: 450    lr: 2.560000000000001e-06     evaluation reward: 6.51\nepisode: 2208   score: 5.0   memory length: 529622   epsilon: 0.14934646000863594    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.51\nepisode: 2209   score: 6.0   memory length: 529975   epsilon: 0.14864752000863152    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 6.48\nepisode: 2210   score: 8.0   memory length: 530397   epsilon: 0.14781196000862623    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 6.53\nepisode: 2211   score: 7.0   memory length: 530792   epsilon: 0.14702986000862128    steps: 395    lr: 2.560000000000001e-06     evaluation reward: 6.56\nepisode: 2212   score: 8.0   memory length: 531227   epsilon: 0.14616856000861583    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 6.51\nepisode: 2213   score: 12.0   memory length: 531686   epsilon: 0.14525974000861008    steps: 459    lr: 2.560000000000001e-06     evaluation reward: 6.58\nepisode: 2214   score: 7.0   memory length: 532073   epsilon: 0.14449348000860524    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 6.52\nepisode: 2215   score: 6.0   memory length: 532413   epsilon: 0.14382028000860098    steps: 340    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2216   score: 12.0   memory length: 532871   epsilon: 0.14291344000859524    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2217   score: 7.0   memory length: 533260   epsilon: 0.14214322000859037    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2218   score: 12.0   memory length: 533879   epsilon: 0.1409176000085826    steps: 619    lr: 2.560000000000001e-06     evaluation reward: 6.71\nepisode: 2227   score: 5.0   memory length: 536812   epsilon: 0.13511026000854587    steps: 275    lr: 2.560000000000001e-06     evaluation reward: 6.75\nepisode: 2228   score: 3.0   memory length: 537025   epsilon: 0.1346885200085432    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.74\nepisode: 2254   score: 12.0   memory length: 546718   epsilon: 0.11549638000848839    steps: 585    lr: 2.560000000000001e-06     evaluation reward: 6.79\nepisode: 2255   score: 4.0   memory length: 546981   epsilon: 0.11497564000848874    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.78\nepisode: 2256   score: 14.0   memory length: 547491   epsilon: 0.11396584000848943    steps: 510    lr: 2.560000000000001e-06     evaluation reward: 6.86\nepisode: 2257   score: 3.0   memory length: 547702   epsilon: 0.11354806000848972    steps: 211    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2258   score: 10.0   memory length: 548172   epsilon: 0.11261746000849035    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2259   score: 7.0   memory length: 548556   epsilon: 0.11185714000849087    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.83\nepisode: 2260   score: 7.0   memory length: 548978   epsilon: 0.11102158000849144    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2261   score: 3.0   memory length: 549191   epsilon: 0.11059984000849173    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2262   score: 7.0   memory length: 549439   epsilon: 0.11010880000849206    steps: 248    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2263   score: 8.0   memory length: 549879   epsilon: 0.10923760000849266    steps: 440    lr: 2.560000000000001e-06     evaluation reward: 6.79\nepisode: 2264   score: 9.0   memory length: 550352   epsilon: 0.1083010600084933    steps: 473    lr: 2.560000000000001e-06     evaluation reward: 6.79\nepisode: 2265   score: 6.0   memory length: 550723   epsilon: 0.1075664800084938    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 6.8\nepisode: 2266   score: 3.0   memory length: 550936   epsilon: 0.10714474000849408    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.78\nepisode: 2267   score: 9.0   memory length: 551410   epsilon: 0.10620622000849472    steps: 474    lr: 2.560000000000001e-06     evaluation reward: 6.84\nepisode: 2268   score: 9.0   memory length: 551885   epsilon: 0.10526572000849536    steps: 475    lr: 2.560000000000001e-06     evaluation reward: 6.89\nepisode: 2269   score: 3.0   memory length: 552098   epsilon: 0.10484398000849565    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.86\nepisode: 2270   score: 7.0   memory length: 552502   epsilon: 0.1040440600084962    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 6.87\nepisode: 2271   score: 7.0   memory length: 552852   epsilon: 0.10335106000849667    steps: 350    lr: 2.560000000000001e-06     evaluation reward: 6.87\nepisode: 2272   score: 8.0   memory length: 553300   epsilon: 0.10246402000849728    steps: 448    lr: 2.560000000000001e-06     evaluation reward: 6.89\nepisode: 2273   score: 6.0   memory length: 553654   epsilon: 0.10176310000849775    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 6.86\nepisode: 2274   score: 6.0   memory length: 553991   epsilon: 0.10109584000849821    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2275   score: 4.0   memory length: 554235   epsilon: 0.10061272000849854    steps: 244    lr: 2.560000000000001e-06     evaluation reward: 6.72\nepisode: 2276   score: 8.0   memory length: 554676   epsilon: 0.09973954000849913    steps: 441    lr: 2.560000000000001e-06     evaluation reward: 6.7\nepisode: 2277   score: 12.0   memory length: 555155   epsilon: 0.09879112000849978    steps: 479    lr: 2.560000000000001e-06     evaluation reward: 6.72\nepisode: 2281   score: 6.0   memory length: 556819   epsilon: 0.09549640000850203    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2282   score: 9.0   memory length: 557322   epsilon: 0.0945004600085027    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 6.78\nepisode: 2283   score: 3.0   memory length: 557535   epsilon: 0.094078720008503    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.73\nepisode: 2284   score: 6.0   memory length: 557878   epsilon: 0.09339958000850346    steps: 343    lr: 2.560000000000001e-06     evaluation reward: 6.71\nepisode: 2285   score: 7.0   memory length: 558284   epsilon: 0.092595700008504    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2286   score: 7.0   memory length: 558662   epsilon: 0.09184726000850452    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 6.68\nepisode: 2287   score: 9.0   memory length: 559132   epsilon: 0.09091666000850515    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 6.72\nepisode: 2288   score: 7.0   memory length: 559536   epsilon: 0.0901167400085057    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 6.75\nepisode: 2289   score: 6.0   memory length: 559874   epsilon: 0.08944750000850615    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.73\nepisode: 2290   score: 6.0   memory length: 560225   epsilon: 0.08875252000850663    steps: 351    lr: 2.560000000000001e-06     evaluation reward: 6.71\nepisode: 2291   score: 8.0   memory length: 560659   epsilon: 0.08789320000850721    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 6.73\nepisode: 2292   score: 7.0   memory length: 561028   epsilon: 0.08716258000850771    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2293   score: 3.0   memory length: 561240   epsilon: 0.086742820008508    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2294   score: 8.0   memory length: 561717   epsilon: 0.08579836000850864    steps: 477    lr: 2.560000000000001e-06     evaluation reward: 6.8\nepisode: 2295   score: 3.0   memory length: 561930   epsilon: 0.08537662000850893    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.74\nepisode: 2296   score: 10.0   memory length: 562450   epsilon: 0.08434702000850963    steps: 520    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2297   score: 8.0   memory length: 562862   epsilon: 0.08353126000851019    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2298   score: 3.0   memory length: 563075   epsilon: 0.08310952000851048    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.8\nepisode: 2299   score: 7.0   memory length: 563457   epsilon: 0.08235316000851099    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 6.78\nepisode: 2300   score: 9.0   memory length: 563819   epsilon: 0.08163640000851148    steps: 362    lr: 2.560000000000001e-06     evaluation reward: 6.84\nepisode: 2301   score: 3.0   memory length: 564032   epsilon: 0.08121466000851177    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.78\nepisode: 2302   score: 9.0   memory length: 564521   epsilon: 0.08024644000851243    steps: 489    lr: 2.560000000000001e-06     evaluation reward: 6.84\nepisode: 2303   score: 4.0   memory length: 564784   epsilon: 0.07972570000851278    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.84\nepisode: 2304   score: 7.0   memory length: 565155   epsilon: 0.07899112000851329    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 6.85\nepisode: 2305   score: 4.0   memory length: 565414   epsilon: 0.07847830000851364    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 6.84\nepisode: 2306   score: 3.0   memory length: 565627   epsilon: 0.07805656000851392    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.8\nepisode: 2307   score: 7.0   memory length: 566028   epsilon: 0.07726258000851446    steps: 401    lr: 2.560000000000001e-06     evaluation reward: 6.79\nepisode: 2308   score: 5.0   memory length: 566337   epsilon: 0.07665076000851488    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.79\nepisode: 2309   score: 8.0   memory length: 566746   epsilon: 0.07584094000851543    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2310   score: 4.0   memory length: 566990   epsilon: 0.07535782000851576    steps: 244    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2311   score: 7.0   memory length: 567358   epsilon: 0.07462918000851626    steps: 368    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2312   score: 7.0   memory length: 567794   epsilon: 0.07376590000851685    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 6.76\nepisode: 2313   score: 7.0   memory length: 568217   epsilon: 0.07292836000851742    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 6.71\nepisode: 2314   score: 10.0   memory length: 568764   epsilon: 0.07184530000851816    steps: 547    lr: 2.560000000000001e-06     evaluation reward: 6.74\nepisode: 2315   score: 10.0   memory length: 569219   epsilon: 0.07094440000851877    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 6.78\nepisode: 2316   score: 3.0   memory length: 569432   epsilon: 0.07052266000851906    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.69\nepisode: 2317   score: 8.0   memory length: 569854   epsilon: 0.06968710000851963    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 6.7\nepisode: 2318   score: 4.0   memory length: 570114   epsilon: 0.06917230000851998    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2319   score: 8.0   memory length: 570543   epsilon: 0.06832288000852056    steps: 429    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2320   score: 5.0   memory length: 570837   epsilon: 0.06774076000852096    steps: 294    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2360   score: 3.0   memory length: 585011   epsilon: 0.0396762400085401    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.59\nepisode: 2361   score: 3.0   memory length: 585224   epsilon: 0.03925450000854039    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.59\nepisode: 2362   score: 3.0   memory length: 585437   epsilon: 0.038832760008540676    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2363   score: 3.0   memory length: 585650   epsilon: 0.038411020008540964    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.5\nepisode: 2364   score: 3.0   memory length: 585863   epsilon: 0.03798928000854125    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 6.44\nepisode: 2413   score: 3.0   memory length: 599976   epsilon: 0.010045540008555422    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.69\nepisode: 2414   score: 4.0   memory length: 600220   epsilon: 0.009998020008555413    steps: 244    lr: 1.0240000000000005e-06     evaluation reward: 5.63\nepisode: 2415   score: 9.0   memory length: 600676   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 5.62\nepisode: 2416   score: 9.0   memory length: 601123   epsilon: 0.009998020008555413    steps: 447    lr: 1.0240000000000005e-06     evaluation reward: 5.68\nepisode: 2417   score: 4.0   memory length: 601367   epsilon: 0.009998020008555413    steps: 244    lr: 1.0240000000000005e-06     evaluation reward: 5.64\nepisode: 2418   score: 6.0   memory length: 601714   epsilon: 0.009998020008555413    steps: 347    lr: 1.0240000000000005e-06     evaluation reward: 5.66\nepisode: 2419   score: 3.0   memory length: 601926   epsilon: 0.009998020008555413    steps: 212    lr: 1.0240000000000005e-06     evaluation reward: 5.61\nepisode: 2465   score: 9.0   memory length: 614934   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 4.87\nepisode: 2466   score: 3.0   memory length: 615147   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 4.87\nepisode: 2467   score: 3.0   memory length: 615360   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 4.87\nepisode: 2468   score: 3.0   memory length: 615573   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 4.87\nepisode: 2469   score: 3.0   memory length: 615786   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 4.87\nepisode: 2470   score: 3.0   memory length: 615997   epsilon: 0.009998020008555413    steps: 211    lr: 1.0240000000000005e-06     evaluation reward: 4.81\nepisode: 2508   score: 7.0   memory length: 628503   epsilon: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     evaluation reward: 5.25\nepisode: 2509   score: 6.0   memory length: 628855   epsilon: 0.009998020008555413    steps: 352    lr: 1.0240000000000005e-06     evaluation reward: 5.25\nepisode: 2510   score: 3.0   memory length: 629068   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.1\nepisode: 2511   score: 6.0   memory length: 629421   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 5.13\nepisode: 2512   score: 9.0   memory length: 629883   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 5.19\nepisode: 2513   score: 3.0   memory length: 630096   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.19\nepisode: 2514   score: 8.0   memory length: 630518   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 5.23\nepisode: 2515   score: 4.0   memory length: 630778   epsilon: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     evaluation reward: 5.18\nepisode: 2516   score: 8.0   memory length: 631240   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 5.17\nepisode: 2517   score: 3.0   memory length: 631453   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.16\nepisode: 2559   score: 8.0   memory length: 644764   epsilon: 0.009998020008555413    steps: 414    lr: 1.0240000000000005e-06     evaluation reward: 5.65\nepisode: 2568   score: 11.0   memory length: 647768   epsilon: 0.009998020008555413    steps: 535    lr: 1.0240000000000005e-06     evaluation reward: 5.7\nepisode: 2569   score: 6.0   memory length: 648122   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 5.73\nepisode: 2570   score: 7.0   memory length: 648523   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 5.77\nepisode: 2571   score: 3.0   memory length: 648736   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.77\nepisode: 2616   score: 3.0   memory length: 662939   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.57\nepisode: 2617   score: 3.0   memory length: 663152   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.57\nepisode: 2618   score: 3.0   memory length: 663365   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.49\nepisode: 2619   score: 5.0   memory length: 663640   epsilon: 0.009998020008555413    steps: 275    lr: 1.0240000000000005e-06     evaluation reward: 5.51\nepisode: 2620   score: 4.0   memory length: 663884   epsilon: 0.009998020008555413    steps: 244    lr: 1.0240000000000005e-06     evaluation reward: 5.45\nepisode: 2621   score: 6.0   memory length: 664188   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 5.42\nepisode: 2662   score: 10.0   memory length: 677801   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 5.75\nepisode: 2663   score: 3.0   memory length: 678014   epsilon: 0.009998020008555413    steps: 213    lr: 1.0240000000000005e-06     evaluation reward: 5.75\nepisode: 2664   score: 10.0   memory length: 678531   epsilon: 0.009998020008555413    steps: 517    lr: 1.0240000000000005e-06     evaluation reward: 5.78\nepisode: 2665   score: 11.0   memory length: 678919   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 5.81\nepisode: 2709   score: 7.0   memory length: 694564   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.56\nepisode: 2710   score: 7.0   memory length: 694984   epsilon: 0.009998020008555413    steps: 420    lr: 1.0240000000000005e-06     evaluation reward: 6.52\nepisode: 2711   score: 10.0   memory length: 695486   epsilon: 0.009998020008555413    steps: 502    lr: 1.0240000000000005e-06     evaluation reward: 6.59\nepisode: 2712   score: 9.0   memory length: 695802   epsilon: 0.009998020008555413    steps: 316    lr: 1.0240000000000005e-06     evaluation reward: 6.62\nepisode: 2713   score: 5.0   memory length: 696075   epsilon: 0.009998020008555413    steps: 273    lr: 1.0240000000000005e-06     evaluation reward: 6.64\nepisode: 2714   score: 8.0   memory length: 696443   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 6.63\nepisode: 2715   score: 5.0   memory length: 696718   epsilon: 0.009998020008555413    steps: 275    lr: 1.0240000000000005e-06     evaluation reward: 6.58\nepisode: 2752   score: 5.0   memory length: 710456   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.51\nepisode: 2753   score: 6.0   memory length: 710760   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.52\nepisode: 2754   score: 9.0   memory length: 711076   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.55\nepisode: 2755   score: 10.0   memory length: 711421   epsilon: 0.009998020008555413    steps: 345    lr: 4.0960000000000023e-07     evaluation reward: 7.56\nepisode: 2756   score: 3.0   memory length: 711634   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.49\nepisode: 2757   score: 6.0   memory length: 711958   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 7.51\nepisode: 2758   score: 7.0   memory length: 712355   epsilon: 0.009998020008555413    steps: 397    lr: 4.0960000000000023e-07     evaluation reward: 7.49\nepisode: 2759   score: 7.0   memory length: 712759   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 7.49\nepisode: 2764   score: 13.0   memory length: 714466   epsilon: 0.009998020008555413    steps: 590    lr: 4.0960000000000023e-07     evaluation reward: 7.45\nepisode: 2765   score: 3.0   memory length: 714679   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.37\nepisode: 2766   score: 3.0   memory length: 714892   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.28\nepisode: 2767   score: 12.0   memory length: 715316   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 7.31\nepisode: 2768   score: 9.0   memory length: 715754   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 7.33\nepisode: 2769   score: 12.0   memory length: 716178   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 7.42\nepisode: 2770   score: 3.0   memory length: 716391   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.35\nepisode: 2779   score: 3.0   memory length: 719487   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.53\nepisode: 2780   score: 4.0   memory length: 719731   epsilon: 0.009998020008555413    steps: 244    lr: 4.0960000000000023e-07     evaluation reward: 7.54\nepisode: 2781   score: 3.0   memory length: 719944   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.43\nepisode: 2782   score: 3.0   memory length: 720157   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.36\nepisode: 2783   score: 12.0   memory length: 720691   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 7.44\nepisode: 2784   score: 9.0   memory length: 721176   epsilon: 0.009998020008555413    steps: 485    lr: 4.0960000000000023e-07     evaluation reward: 7.41\nepisode: 2785   score: 13.0   memory length: 721645   epsilon: 0.009998020008555413    steps: 469    lr: 4.0960000000000023e-07     evaluation reward: 7.51\nepisode: 2786   score: 9.0   memory length: 721961   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.54\nepisode: 2787   score: 9.0   memory length: 722413   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 7.57\nepisode: 2788   score: 9.0   memory length: 722729   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.55\nepisode: 2789   score: 10.0   memory length: 723074   epsilon: 0.009998020008555413    steps: 345    lr: 4.0960000000000023e-07     evaluation reward: 7.56\nepisode: 2790   score: 11.0   memory length: 723649   epsilon: 0.009998020008555413    steps: 575    lr: 4.0960000000000023e-07     evaluation reward: 7.56\nepisode: 2791   score: 9.0   memory length: 724088   epsilon: 0.009998020008555413    steps: 439    lr: 4.0960000000000023e-07     evaluation reward: 7.51\nepisode: 2792   score: 9.0   memory length: 724404   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.52\nepisode: 2793   score: 8.0   memory length: 724830   epsilon: 0.009998020008555413    steps: 426    lr: 4.0960000000000023e-07     evaluation reward: 7.51\nepisode: 2794   score: 5.0   memory length: 725105   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.53\nepisode: 2795   score: 8.0   memory length: 725543   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 7.58\nepisode: 2796   score: 9.0   memory length: 725859   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.64\nepisode: 2797   score: 6.0   memory length: 726163   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.55\nepisode: 2798   score: 3.0   memory length: 726376   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.55\nepisode: 2799   score: 18.0   memory length: 727088   epsilon: 0.009998020008555413    steps: 712    lr: 4.0960000000000023e-07     evaluation reward: 7.67\nepisode: 2800   score: 11.0   memory length: 727624   epsilon: 0.009998020008555413    steps: 536    lr: 4.0960000000000023e-07     evaluation reward: 7.73\nepisode: 2801   score: 7.0   memory length: 728013   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 7.67\nepisode: 2802   score: 9.0   memory length: 728465   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 7.71\nepisode: 2803   score: 9.0   memory length: 728781   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.77\nepisode: 2804   score: 9.0   memory length: 729097   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.76\nepisode: 2805   score: 5.0   memory length: 729370   epsilon: 0.009998020008555413    steps: 273    lr: 4.0960000000000023e-07     evaluation reward: 7.75\nepisode: 2806   score: 5.0   memory length: 729645   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.71\nepisode: 2807   score: 11.0   memory length: 730184   epsilon: 0.009998020008555413    steps: 539    lr: 4.0960000000000023e-07     evaluation reward: 7.69\nepisode: 2808   score: 9.0   memory length: 730500   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.71\nepisode: 2809   score: 5.0   memory length: 730775   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.69\nepisode: 2810   score: 10.0   memory length: 731138   epsilon: 0.009998020008555413    steps: 363    lr: 4.0960000000000023e-07     evaluation reward: 7.72\nepisode: 2811   score: 16.0   memory length: 731591   epsilon: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     evaluation reward: 7.78\nepisode: 2812   score: 14.0   memory length: 732079   epsilon: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     evaluation reward: 7.83\nepisode: 2813   score: 7.0   memory length: 732433   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2814   score: 5.0   memory length: 732708   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.82\nepisode: 2815   score: 5.0   memory length: 732983   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.82\nepisode: 2816   score: 7.0   memory length: 733337   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2817   score: 8.0   memory length: 733774   epsilon: 0.009998020008555413    steps: 437    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2818   score: 9.0   memory length: 734090   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 7.86\nepisode: 2819   score: 4.0   memory length: 734334   epsilon: 0.009998020008555413    steps: 244    lr: 4.0960000000000023e-07     evaluation reward: 7.83\nepisode: 2820   score: 7.0   memory length: 734743   epsilon: 0.009998020008555413    steps: 409    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2821   score: 13.0   memory length: 735370   epsilon: 0.009998020008555413    steps: 627    lr: 4.0960000000000023e-07     evaluation reward: 7.97\nepisode: 2822   score: 3.0   memory length: 735583   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.95\nepisode: 2823   score: 7.0   memory length: 735951   epsilon: 0.009998020008555413    steps: 368    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2824   score: 11.0   memory length: 736505   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2825   score: 5.0   memory length: 736780   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2826   score: 5.0   memory length: 737074   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2827   score: 15.0   memory length: 737618   epsilon: 0.009998020008555413    steps: 544    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2828   score: 9.0   memory length: 738074   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2829   score: 3.0   memory length: 738287   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.79\nepisode: 2830   score: 9.0   memory length: 738715   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2831   score: 9.0   memory length: 739213   epsilon: 0.009998020008555413    steps: 498    lr: 4.0960000000000023e-07     evaluation reward: 7.91\nepisode: 2832   score: 10.0   memory length: 739746   epsilon: 0.009998020008555413    steps: 533    lr: 4.0960000000000023e-07     evaluation reward: 7.91\nepisode: 2833   score: 18.0   memory length: 740458   epsilon: 0.009998020008555413    steps: 712    lr: 4.0960000000000023e-07     evaluation reward: 7.97\nepisode: 2834   score: 7.0   memory length: 740839   epsilon: 0.009998020008555413    steps: 381    lr: 4.0960000000000023e-07     evaluation reward: 7.99\nepisode: 2835   score: 8.0   memory length: 741277   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 7.96\nepisode: 2836   score: 3.0   memory length: 741490   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.89\nepisode: 2837   score: 3.0   memory length: 741703   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.8\nepisode: 2838   score: 7.0   memory length: 742109   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2839   score: 3.0   memory length: 742322   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.78\nepisode: 2840   score: 12.0   memory length: 742881   epsilon: 0.009998020008555413    steps: 559    lr: 4.0960000000000023e-07     evaluation reward: 7.81\nepisode: 2841   score: 20.0   memory length: 743460   epsilon: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     evaluation reward: 7.98\nepisode: 2842   score: 14.0   memory length: 744143   epsilon: 0.009998020008555413    steps: 683    lr: 4.0960000000000023e-07     evaluation reward: 7.99\nepisode: 2843   score: 14.0   memory length: 744531   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 8.06\nepisode: 2844   score: 12.0   memory length: 744963   epsilon: 0.009998020008555413    steps: 432    lr: 4.0960000000000023e-07     evaluation reward: 8.08\nepisode: 2845   score: 11.0   memory length: 745519   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 8.09\nepisode: 2846   score: 12.0   memory length: 746077   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 8.11\nepisode: 2847   score: 14.0   memory length: 746704   epsilon: 0.009998020008555413    steps: 627    lr: 4.0960000000000023e-07     evaluation reward: 8.22\nepisode: 2848   score: 9.0   memory length: 747170   epsilon: 0.009998020008555413    steps: 466    lr: 4.0960000000000023e-07     evaluation reward: 8.16\nepisode: 2849   score: 9.0   memory length: 747619   epsilon: 0.009998020008555413    steps: 449    lr: 4.0960000000000023e-07     evaluation reward: 8.22\nepisode: 2850   score: 3.0   memory length: 747832   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 8.15\nepisode: 2851   score: 3.0   memory length: 748045   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 8.1\nepisode: 2852   score: 11.0   memory length: 748599   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 8.16\nepisode: 2853   score: 12.0   memory length: 749159   epsilon: 0.009998020008555413    steps: 560    lr: 4.0960000000000023e-07     evaluation reward: 8.22\nepisode: 2854   score: 16.0   memory length: 749787   epsilon: 0.009998020008555413    steps: 628    lr: 4.0960000000000023e-07     evaluation reward: 8.29\nepisode: 2855   score: 6.0   memory length: 750111   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 8.25\nepisode: 2856   score: 13.0   memory length: 750682   epsilon: 0.009998020008555413    steps: 571    lr: 4.0960000000000023e-07     evaluation reward: 8.35\nepisode: 2857   score: 9.0   memory length: 751111   epsilon: 0.009998020008555413    steps: 429    lr: 4.0960000000000023e-07     evaluation reward: 8.38\nepisode: 2858   score: 9.0   memory length: 751585   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 8.4\nepisode: 2859   score: 9.0   memory length: 752022   epsilon: 0.009998020008555413    steps: 437    lr: 4.0960000000000023e-07     evaluation reward: 8.42\nepisode: 2860   score: 9.0   memory length: 752496   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 8.38\nepisode: 2861   score: 5.0   memory length: 752771   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 8.4\nepisode: 2862   score: 7.0   memory length: 753159   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 8.44\nepisode: 2863   score: 11.0   memory length: 753697   epsilon: 0.009998020008555413    steps: 538    lr: 4.0960000000000023e-07     evaluation reward: 8.52\nepisode: 2892   score: 12.0   memory length: 765263   epsilon: 0.009998020008555413    steps: 614    lr: 4.0960000000000023e-07     evaluation reward: 8.52\nepisode: 2893   score: 3.0   memory length: 765476   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 8.47\nepisode: 2894   score: 13.0   memory length: 766053   epsilon: 0.009998020008555413    steps: 577    lr: 4.0960000000000023e-07     evaluation reward: 8.55\nepisode: 2895   score: 10.0   memory length: 766543   epsilon: 0.009998020008555413    steps: 490    lr: 4.0960000000000023e-07     evaluation reward: 8.57\nepisode: 2896   score: 11.0   memory length: 767100   epsilon: 0.009998020008555413    steps: 557    lr: 4.0960000000000023e-07     evaluation reward: 8.59\nepisode: 2897   score: 11.0   memory length: 767635   epsilon: 0.009998020008555413    steps: 535    lr: 4.0960000000000023e-07     evaluation reward: 8.64\nepisode: 2898   score: 4.0   memory length: 767879   epsilon: 0.009998020008555413    steps: 244    lr: 4.0960000000000023e-07     evaluation reward: 8.65\nepisode: 2899   score: 7.0   memory length: 768299   epsilon: 0.009998020008555413    steps: 420    lr: 4.0960000000000023e-07     evaluation reward: 8.54\nepisode: 2900   score: 10.0   memory length: 768822   epsilon: 0.009998020008555413    steps: 523    lr: 4.0960000000000023e-07     evaluation reward: 8.53\nepisode: 2901   score: 10.0   memory length: 769282   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 8.56\nepisode: 2902   score: 6.0   memory length: 769634   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 8.53\nepisode: 2903   score: 8.0   memory length: 770049   epsilon: 0.009998020008555413    steps: 415    lr: 4.0960000000000023e-07     evaluation reward: 8.52\nepisode: 2904   score: 5.0   memory length: 770343   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 8.48\nepisode: 2905   score: 15.0   memory length: 771034   epsilon: 0.009998020008555413    steps: 691    lr: 4.0960000000000023e-07     evaluation reward: 8.58\nepisode: 2906   score: 11.0   memory length: 771552   epsilon: 0.009998020008555413    steps: 518    lr: 4.0960000000000023e-07     evaluation reward: 8.64\nepisode: 2907   score: 9.0   memory length: 771984   epsilon: 0.009998020008555413    steps: 432    lr: 4.0960000000000023e-07     evaluation reward: 8.62\nepisode: 2908   score: 7.0   memory length: 772401   epsilon: 0.009998020008555413    steps: 417    lr: 4.0960000000000023e-07     evaluation reward: 8.6\nepisode: 2909   score: 14.0   memory length: 772980   epsilon: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     evaluation reward: 8.69\nepisode: 2910   score: 8.0   memory length: 773385   epsilon: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     evaluation reward: 8.67\nepisode: 2911   score: 12.0   memory length: 773951   epsilon: 0.009998020008555413    steps: 566    lr: 4.0960000000000023e-07     evaluation reward: 8.63\nepisode: 2912   score: 9.0   memory length: 774380   epsilon: 0.009998020008555413    steps: 429    lr: 4.0960000000000023e-07     evaluation reward: 8.58\nepisode: 2913   score: 9.0   memory length: 774856   epsilon: 0.009998020008555413    steps: 476    lr: 4.0960000000000023e-07     evaluation reward: 8.6\nepisode: 2914   score: 11.0   memory length: 775364   epsilon: 0.009998020008555413    steps: 508    lr: 4.0960000000000023e-07     evaluation reward: 8.66\nepisode: 2915   score: 9.0   memory length: 775853   epsilon: 0.009998020008555413    steps: 489    lr: 4.0960000000000023e-07     evaluation reward: 8.7\nepisode: 2916   score: 8.0   memory length: 776291   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 8.71\nepisode: 2917   score: 9.0   memory length: 776788   epsilon: 0.009998020008555413    steps: 497    lr: 4.0960000000000023e-07     evaluation reward: 8.72\nepisode: 2918   score: 3.0   memory length: 777001   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 8.66\nepisode: 2919   score: 3.0   memory length: 777214   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 8.65\nepisode: 2920   score: 7.0   memory length: 777618   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 8.65\nepisode: 2921   score: 6.0   memory length: 777991   epsilon: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     evaluation reward: 8.58\nepisode: 2922   score: 13.0   memory length: 778515   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 8.68\nepisode: 2923   score: 10.0   memory length: 779036   epsilon: 0.009998020008555413    steps: 521    lr: 4.0960000000000023e-07     evaluation reward: 8.71\nepisode: 2924   score: 10.0   memory length: 779571   epsilon: 0.009998020008555413    steps: 535    lr: 4.0960000000000023e-07     evaluation reward: 8.7\nepisode: 2925   score: 10.0   memory length: 780033   epsilon: 0.009998020008555413    steps: 462    lr: 4.0960000000000023e-07     evaluation reward: 8.75\nepisode: 2926   score: 12.0   memory length: 780620   epsilon: 0.009998020008555413    steps: 587    lr: 4.0960000000000023e-07     evaluation reward: 8.82\nepisode: 2927   score: 10.0   memory length: 781135   epsilon: 0.009998020008555413    steps: 515    lr: 4.0960000000000023e-07     evaluation reward: 8.77\nepisode: 2928   score: 11.0   memory length: 781702   epsilon: 0.009998020008555413    steps: 567    lr: 4.0960000000000023e-07     evaluation reward: 8.79\nepisode: 2929   score: 9.0   memory length: 782176   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 8.85\nepisode: 2930   score: 5.0   memory length: 782470   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 8.81\nepisode: 2931   score: 5.0   memory length: 782764   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 8.77\nepisode: 2932   score: 12.0   memory length: 783283   epsilon: 0.009998020008555413    steps: 519    lr: 4.0960000000000023e-07     evaluation reward: 8.79\nepisode: 2933   score: 13.0   memory length: 783928   epsilon: 0.009998020008555413    steps: 645    lr: 4.0960000000000023e-07     evaluation reward: 8.74\nepisode: 2934   score: 11.0   memory length: 784445   epsilon: 0.009998020008555413    steps: 517    lr: 4.0960000000000023e-07     evaluation reward: 8.78\nepisode: 2935   score: 10.0   memory length: 784949   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 8.8\nepisode: 2936   score: 6.0   memory length: 785301   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 8.83\nepisode: 2937   score: 15.0   memory length: 785872   epsilon: 0.009998020008555413    steps: 571    lr: 4.0960000000000023e-07     evaluation reward: 8.95\nepisode: 2938   score: 11.0   memory length: 786389   epsilon: 0.009998020008555413    steps: 517    lr: 4.0960000000000023e-07     evaluation reward: 8.99\nepisode: 2939   score: 9.0   memory length: 786845   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 9.05\nepisode: 2940   score: 10.0   memory length: 787371   epsilon: 0.009998020008555413    steps: 526    lr: 4.0960000000000023e-07     evaluation reward: 9.03\nepisode: 2941   score: 11.0   memory length: 787925   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 8.94\nepisode: 2942   score: 11.0   memory length: 788442   epsilon: 0.009998020008555413    steps: 517    lr: 4.0960000000000023e-07     evaluation reward: 8.91\nepisode: 2943   score: 8.0   memory length: 788843   epsilon: 0.009998020008555413    steps: 401    lr: 4.0960000000000023e-07     evaluation reward: 8.85\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Start training after random sample generation\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(frame \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m train_frame): \u001b[38;5;66;03m# You can set train_frame to a lower value while testing your starts training earlier\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_policy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Update the target network only for Double DQN only\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m double_dqn \u001b[38;5;129;01mand\u001b[39;00m (frame \u001b[38;5;241m%\u001b[39m update_target_network_frequency)\u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/kaggle/working/cs444/assignment5/agent.py:62\u001b[0m, in \u001b[0;36mAgent.train_policy_net\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_min:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_decay\n\u001b[0;32m---> 62\u001b[0m mini_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m mini_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mini_batch, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m     65\u001b[0m history \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(mini_batch[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/kaggle/working/cs444/assignment5/memory.py:30\u001b[0m, in \u001b[0;36mReplayMemory.sample_mini_batch\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(HISTORY_SIZE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     28\u001b[0m         sample\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory[i \u001b[38;5;241m+\u001b[39m j])\n\u001b[0;32m---> 30\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     mini_batch\u001b[38;5;241m.\u001b[39mappend((np\u001b[38;5;241m.\u001b[39mstack(sample[:, \u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), sample[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m], sample[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m], sample[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m]))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mini_batch\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Visualize Agent Performance","metadata":{}},{"cell_type":"markdown","source":"BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n\nPlease save your model before running this portion of the code.","metadata":{}},{"cell_type":"code","source":"torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:26:41.373412Z","iopub.execute_input":"2024-05-01T17:26:41.373979Z","iopub.status.idle":"2024-05-01T17:26:41.406784Z","shell.execute_reply.started":"2024-05-01T17:26:41.373927Z","shell.execute_reply":"2024-05-01T17:26:41.404811Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# from gym.wrappers import Monitor # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\nfrom gym.wrappers import RecordVideo\nimport glob\nimport io\nimport base64\n\nfrom IPython.display import HTML\nfrom IPython import display as ipythondisplay\n\nfrom pyvirtualdisplay import Display\n\n# Displaying the game live\ndef show_state(env, step=0, info=\"\"):\n    plt.figure(3)\n    plt.clf()\n    plt.imshow(env.render(mode='rgb_array'))\n    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n    plt.axis('off')\n\n    ipythondisplay.clear_output(wait=True)\n    ipythondisplay.display(plt.gcf())\n    \n# Recording the game and replaying the game afterwards\ndef show_video():\n    mp4list = glob.glob('video/*.mp4')\n    if len(mp4list) > 0:\n        mp4 = mp4list[0]\n        video = io.open(mp4, 'r+b').read()\n        encoded = base64.b64encode(video)\n        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n             </video>'''.format(encoded.decode('ascii'))))\n    else: \n        print(\"Could not find video\")\n    \n\ndef wrap_env(env):\n    env = RecordVideo(env, './video', force=True)\n    return env","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:27:59.769913Z","iopub.execute_input":"2024-05-01T17:27:59.770804Z","iopub.status.idle":"2024-05-01T17:27:59.780549Z","shell.execute_reply.started":"2024-05-01T17:27:59.770767Z","shell.execute_reply":"2024-05-01T17:27:59.779614Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"display = Display(visible=0, size=(300, 200))\ndisplay.start()\n\n# Load agent\n# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\nagent.epsilon = 0.0 # Set agent to only exploit the best action\n\nenv = gym.make('BreakoutDeterministic-v4')\nenv = wrap_env(env)\n\ndone = False\nscore = 0\nstep = 0\nstate = env.reset()\nnext_state = state\nlife = number_lives\nhistory = np.zeros([5, 84, 84], dtype=np.uint8)\nget_init_state(history, state)\n\nwhile not done:\n    \n    # Render breakout\n    env.render()\n#     show_state(env,step) # uncommenting this provides another way to visualize the game\n\n    step += 1\n    frame += 1\n\n    # Perform a fire action if ball is no longer on screen\n    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n        action = 0\n    else:\n        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n    state = next_state\n    \n    next_state, reward, done, info = env.step(action + 1)\n        \n    frame_next_state = get_frame(next_state)\n    history[4, :, :] = frame_next_state\n    terminal_state = check_live(life, info['ale.lives'])\n        \n    life = info['ale.lives']\n    r = np.clip(reward, -1, 1) \n    r = reward\n\n    # Store the transition in memory \n    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n    # Start training after random sample generation\n    score += reward\n    \n    history[:4, :, :] = history[1:, :, :]\nenv.close()\nshow_video()\ndisplay.stop()","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:28:02.432877Z","iopub.execute_input":"2024-05-01T17:28:02.433746Z","iopub.status.idle":"2024-05-01T17:28:02.756856Z","shell.execute_reply.started":"2024-05-01T17:28:02.433709Z","shell.execute_reply":"2024-05-01T17:28:02.755657Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Exception ignored in: <function RecordVideo.__del__ at 0x78c51c1a0700>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/gym/core.py\", line 241, in __getattr__\n    return getattr(self.env, name)\n  File \"/opt/conda/lib/python3.10/site-packages/gym/core.py\", line 241, in __getattr__\n    return getattr(self.env, name)\n  File \"/opt/conda/lib/python3.10/site-packages/gym/core.py\", line 241, in __getattr__\n    return getattr(self.env, name)\n  [Previous line repeated 996 more times]\n  File \"/opt/conda/lib/python3.10/site-packages/gym/core.py\", line 239, in __getattr__\n    if name.startswith(\"_\"):\nRecursionError: maximum recursion depth exceeded while calling a Python object\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m agent\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;66;03m# Set agent to only exploit the best action\u001b[39;00m\n\u001b[1;32m      8\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakoutDeterministic-v4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","Cell \u001b[0;32mIn[14], line 39\u001b[0m, in \u001b[0;36mwrap_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_env\u001b[39m(env):\n\u001b[0;32m---> 39\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mRecordVideo\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./video\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\n","\u001b[0;31mTypeError\u001b[0m: RecordVideo.__init__() got an unexpected keyword argument 'force'"],"ename":"TypeError","evalue":"RecordVideo.__init__() got an unexpected keyword argument 'force'","output_type":"error"}]}]}