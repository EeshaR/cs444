{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Q-Learning ","metadata":{}},{"cell_type":"markdown","source":"Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down.","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/EeshaR/cs444.git","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:44:40.193055Z","iopub.execute_input":"2024-05-05T16:44:40.193407Z","iopub.status.idle":"2024-05-05T16:44:43.515468Z","shell.execute_reply.started":"2024-05-05T16:44:40.193379Z","shell.execute_reply":"2024-05-05T16:44:43.514310Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'cs444'...\nremote: Enumerating objects: 349, done.\u001b[K\nremote: Counting objects: 100% (206/206), done.\u001b[K\nremote: Compressing objects: 100% (206/206), done.\u001b[K\nremote: Total 349 (delta 96), reused 0 (delta 0), pack-reused 143\u001b[K\nReceiving objects: 100% (349/349), 21.29 MiB | 13.38 MiB/s, done.\nResolving deltas: 100% (143/143), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install gym pyvirtualdisplay\n!sudo apt-get install -y xvfb python-opengl ffmpeg","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:44:46.182827Z","iopub.execute_input":"2024-05-05T16:44:46.183597Z","iopub.status.idle":"2024-05-05T16:45:12.893583Z","shell.execute_reply.started":"2024-05-05T16:44:46.183548Z","shell.execute_reply":"2024-05-05T16:45:12.892631Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gym in /opt/conda/lib/python3.10/site-packages (0.26.2)\nCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym) (0.0.8)\nDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\nxvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.17).\nThe following additional packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python2 python2-minimal python2.7 python2.7-minimal\nSuggested packages:\n  python-tk python-numpy libgle3 python2-doc python2.7-doc binfmt-support\nThe following NEW packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python-opengl python2 python2-minimal python2.7\n  python2.7-minimal\n0 upgraded, 10 newly installed, 0 to remove and 65 not upgraded.\nNeed to get 4540 kB of archives.\nAfter this operation, 22.7 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-minimal amd64 2.7.18-1~20.04.4 [335 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7-minimal amd64 2.7.18-1~20.04.4 [1280 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-stdlib amd64 2.7.18-1~20.04.4 [1887 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7 amd64 2.7.18-1~20.04.4 [248 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7072 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libglu1-mesa amd64 9.0.1-1build1 [168 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\nFetched 4540 kB in 2s (2140 kB/s)     \nSelecting previously unselected package libpython2.7-minimal:amd64.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../0-libpython2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2.7-minimal.\nPreparing to unpack .../1-python2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking python2.7-minimal (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2-minimal.\nPreparing to unpack .../2-python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking python2-minimal (2.7.17-2ubuntu4) ...\nSelecting previously unselected package libpython2.7-stdlib:amd64.\nPreparing to unpack .../3-libpython2.7-stdlib_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2.7.\nPreparing to unpack .../4-python2.7_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking python2.7 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package libpython2-stdlib:amd64.\nPreparing to unpack .../5-libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\nSetting up libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\nSetting up python2.7-minimal (2.7.18-1~20.04.4) ...\nLinking and byte-compiling packages for runtime python2.7...\nSetting up python2-minimal (2.7.17-2ubuntu4) ...\nSelecting previously unselected package python2.\n(Reading database ... 114554 files and directories currently installed.)\nPreparing to unpack .../python2_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking python2 (2.7.17-2ubuntu4) ...\nSelecting previously unselected package freeglut3:amd64.\nPreparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\nUnpacking freeglut3:amd64 (2.8.1-3) ...\nSelecting previously unselected package libglu1-mesa:amd64.\nPreparing to unpack .../libglu1-mesa_9.0.1-1build1_amd64.deb ...\nUnpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\nSelecting previously unselected package python-opengl.\nPreparing to unpack .../python-opengl_3.1.0+dfsg-2build1_all.deb ...\nUnpacking python-opengl (3.1.0+dfsg-2build1) ...\nSetting up freeglut3:amd64 (2.8.1-3) ...\nSetting up libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\nSetting up libglu1-mesa:amd64 (9.0.1-1build1) ...\nSetting up python2.7 (2.7.18-1~20.04.4) ...\nSetting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\nSetting up python2 (2.7.17-2ubuntu4) ...\nSetting up python-opengl (3.1.0+dfsg-2build1) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install --upgrade setuptools --user\n!pip3 install ez_setup \n!pip3 install gym[atari] \n!pip3 install gym[accept-rom-license] ","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:45:16.591013Z","iopub.execute_input":"2024-05-05T16:45:16.591792Z","iopub.status.idle":"2024-05-05T16:46:24.576428Z","shell.execute_reply.started":"2024-05-05T16:45:16.591752Z","shell.execute_reply":"2024-05-05T16:46:24.575244Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (69.0.3)\nCollecting setuptools\n  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed setuptools-69.5.1\nCollecting ez_setup\n  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: ez_setup\n  Building wheel for ez_setup (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ez_setup: filename=ez_setup-0.9-py3-none-any.whl size=10995 sha256=fa2088dc61ce3c9e0539a18ccbb4a6f0d1c23d088cc4511d46ef4b81f467064c\n  Stored in directory: /root/.cache/pip/wheels/7a/d6/77/8f495e85fb7df23d41c328b9ea3cf0d9e83631b20bba479293\nSuccessfully built ez_setup\nInstalling collected packages: ez_setup\nSuccessfully installed ez_setup-0.9\nRequirement already satisfied: gym[atari] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (0.0.8)\nCollecting ale-py~=0.8.0 (from gym[atari])\n  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.0->gym[atari]) (6.1.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.0->gym[atari]) (4.9.0)\nDownloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py\nSuccessfully installed ale-py-0.8.1\nRequirement already satisfied: gym[accept-rom-license] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (0.0.8)\nCollecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (8.1.7)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (4.66.1)\nCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2024.2.2)\nDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: AutoROM.accept-rom-license\n  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=c2eef30a322fa3db57f62f23f2d2cbf974c35bff9cf4dcc26f943080cc3d3b3f\n  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\nSuccessfully built AutoROM.accept-rom-license\nInstalling collected packages: AutoROM.accept-rom-license, autorom\nSuccessfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__.","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport sys\n\n# Add the path to the directory containing the `gan` package to sys.path\nsys.path.append('/kaggle/working/cs444/assignment5')\n\nimport sys\nimport gym\nimport torch\nimport pylab\nimport random\nimport numpy as np\nfrom collections import deque\nfrom datetime import datetime\nfrom copy import deepcopy\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom utils import find_max_lives, check_live, get_frame, get_init_state\nfrom model import DQN, DQN_LSTM\nfrom config import *\n\nimport matplotlib.pyplot as plt\n# %load_ext autoreload\n# %autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:53:20.445018Z","iopub.execute_input":"2024-05-05T16:53:20.445418Z","iopub.status.idle":"2024-05-05T16:53:24.436326Z","shell.execute_reply.started":"2024-05-05T16:53:20.445384Z","shell.execute_reply":"2024-05-05T16:53:24.435308Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the environment","metadata":{}},{"cell_type":"markdown","source":"In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n\nIn breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right.","metadata":{}},{"cell_type":"code","source":"env = gym.make('BreakoutDeterministic-v4')\nstate = env.reset()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:53:24.438119Z","iopub.execute_input":"2024-05-05T16:53:24.438529Z","iopub.status.idle":"2024-05-05T16:53:24.779641Z","shell.execute_reply.started":"2024-05-05T16:53:24.438493Z","shell.execute_reply":"2024-05-05T16:53:24.778812Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n[Powered by Stella]\n","output_type":"stream"}]},{"cell_type":"code","source":"number_lives = find_max_lives(env)\nstate_size = env.observation_space.shape\naction_size = 3 #fire, left, and right","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:53:26.423817Z","iopub.execute_input":"2024-05-05T16:53:26.424190Z","iopub.status.idle":"2024-05-05T16:53:26.446453Z","shell.execute_reply.started":"2024-05-05T16:53:26.424160Z","shell.execute_reply":"2024-05-05T16:53:26.445354Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n  if not isinstance(terminated, (bool, np.bool8)):\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating a DQN Agent","metadata":{}},{"cell_type":"markdown","source":"Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n\n__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n\n__Frame__ : Number of frames processed in total.\n\n__Memory Size__ : The current size of the replay memory.","metadata":{}},{"cell_type":"code","source":"double_dqn = False # set to True if using double DQN agent\n\nif double_dqn:\n    from agent_double import Agent\nelse:\n    from agent import Agent\n\nagent = Agent(action_size)\nevaluation_reward = deque(maxlen=evaluation_reward_length)\nframe = 0\nmemory_size = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:53:28.515513Z","iopub.execute_input":"2024-05-05T16:53:28.516380Z","iopub.status.idle":"2024-05-05T16:53:30.929004Z","shell.execute_reply.started":"2024-05-05T16:53:28.516348Z","shell.execute_reply":"2024-05-05T16:53:30.928180Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Main Training Loop","metadata":{}},{"cell_type":"markdown","source":"In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\"","metadata":{}},{"cell_type":"code","source":"import os\n\n# Create the directory for saving graphs if it does not exist\nif not os.path.exists(\"./save_graph\"):\n    os.makedirs(\"./save_graph\")\n    \nif not os.path.exists(\"./save_model\"):\n    os.makedirs(\"./save_model\")\n\nrewards, episodes = [], []\nbest_eval_reward = 0\n\nfor e in range(EPISODES):\n    done = False\n    score = 0\n\n    history = np.zeros([5, 84, 84], dtype=np.uint8)\n    step = 0\n    state, _ = env.reset()\n    next_state = state\n    life = number_lives\n\n    get_init_state(history, state, HISTORY_SIZE)\n\n    while not done:\n        step += 1\n        frame += 1\n\n        # Perform a fire action if ball is no longer on screen to continue onto next life\n        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n            action = torch.tensor([[0]]).cuda()\n        else:\n            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n        state = next_state\n        \n        # next_state, reward, done, _, info = env.step(action + 1)\n        next_state, reward, terminated, truncated, info = env.step(action + 1)\n        done = terminated or truncated\n\n        frame_next_state = get_frame(next_state)\n        history[4, :, :] = frame_next_state\n        terminal_state = check_live(life, info['lives'])\n\n        life = info['lives']\n        r = reward\n\n        # Store the transition in memory \n        agent.memory.push(deepcopy(frame_next_state), action.cpu(), r, terminal_state)\n        # Start training after random sample generation\n        if(frame >= train_frame): # You can set train_frame to a lower value while testing your starts training earlier\n            agent.train_policy_net(frame)\n            # Update the target network only for Double DQN only\n            if double_dqn and (frame % update_target_network_frequency)== 0:\n                agent.update_target_net()\n        score += reward\n        history[:4, :, :] = history[1:, :, :]\n            \n        if done:\n            evaluation_reward.append(score)\n            rewards.append(np.mean(evaluation_reward))\n            episodes.append(e)\n            pylab.plot(episodes, rewards, 'b')\n            pylab.xlabel('Episodes')\n            pylab.ylabel('Rewards') \n            pylab.title('Episodes vs Reward')\n            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n            \n            # every episode, plot the play time\n            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n\n            # if the mean of scores of last 100 episode is bigger than 5 save model\n            ### Change this save condition to whatever you prefer ###\n            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n                best_eval_reward = np.mean(evaluation_reward)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-05T16:53:31.758228Z","iopub.execute_input":"2024-05-05T16:53:31.759168Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"episode: 0   score: 1.0   memory length: 150   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.0\nepisode: 1   score: 1.0   memory length: 319   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.0\nepisode: 2   score: 3.0   memory length: 565   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.6666666666666667\nepisode: 3   score: 7.0   memory length: 922   epsilon: 1.0    steps: 357    lr: 0.0001     evaluation reward: 3.0\nepisode: 4   score: 9.0   memory length: 1291   epsilon: 1.0    steps: 369    lr: 0.0001     evaluation reward: 4.2\nepisode: 5   score: 2.0   memory length: 1490   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 3.8333333333333335\nepisode: 6   score: 2.0   memory length: 1708   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 3.5714285714285716\nepisode: 7   score: 1.0   memory length: 1876   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 3.25\nepisode: 8   score: 2.0   memory length: 2094   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 3.111111111111111\nepisode: 9   score: 3.0   memory length: 2324   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 3.1\nepisode: 10   score: 0.0   memory length: 2447   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.8181818181818183\nepisode: 11   score: 0.0   memory length: 2570   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.5833333333333335\nepisode: 12   score: 1.0   memory length: 2740   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 2.4615384615384617\nepisode: 13   score: 2.0   memory length: 2937   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 2.4285714285714284\nepisode: 14   score: 0.0   memory length: 3060   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.2666666666666666\nepisode: 15   score: 0.0   memory length: 3183   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.125\nepisode: 16   score: 2.0   memory length: 3399   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 2.1176470588235294\nepisode: 17   score: 1.0   memory length: 3550   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 2.0555555555555554\nepisode: 18   score: 0.0   memory length: 3673   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9473684210526316\nepisode: 19   score: 3.0   memory length: 3939   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 2.0\nepisode: 20   score: 3.0   memory length: 4167   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 2.0476190476190474\nepisode: 21   score: 2.0   memory length: 4386   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 2.0454545454545454\nepisode: 22   score: 0.0   memory length: 4509   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9565217391304348\nepisode: 23   score: 2.0   memory length: 4706   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.9583333333333333\nepisode: 24   score: 1.0   memory length: 4875   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.92\nepisode: 25   score: 2.0   memory length: 5092   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.9230769230769231\nepisode: 26   score: 2.0   memory length: 5311   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.9259259259259258\nepisode: 27   score: 0.0   memory length: 5434   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8571428571428572\nepisode: 28   score: 3.0   memory length: 5680   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.896551724137931\nepisode: 29   score: 2.0   memory length: 5859   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.9\nepisode: 30   score: 5.0   memory length: 6221   epsilon: 1.0    steps: 362    lr: 0.0001     evaluation reward: 2.0\nepisode: 31   score: 1.0   memory length: 6390   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.96875\nepisode: 32   score: 0.0   memory length: 6513   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9090909090909092\nepisode: 33   score: 1.0   memory length: 6664   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.8823529411764706\nepisode: 34   score: 0.0   memory length: 6787   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8285714285714285\nepisode: 35   score: 0.0   memory length: 6910   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7777777777777777\nepisode: 36   score: 2.0   memory length: 7128   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.7837837837837838\nepisode: 37   score: 0.0   memory length: 7250   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.736842105263158\nepisode: 38   score: 5.0   memory length: 7560   epsilon: 1.0    steps: 310    lr: 0.0001     evaluation reward: 1.8205128205128205\nepisode: 39   score: 3.0   memory length: 7806   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.85\nepisode: 40   score: 1.0   memory length: 7975   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.829268292682927\nepisode: 41   score: 0.0   memory length: 8098   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7857142857142858\nepisode: 42   score: 9.0   memory length: 8457   epsilon: 1.0    steps: 359    lr: 0.0001     evaluation reward: 1.9534883720930232\nepisode: 43   score: 2.0   memory length: 8642   epsilon: 1.0    steps: 185    lr: 0.0001     evaluation reward: 1.9545454545454546\nepisode: 44   score: 1.0   memory length: 8813   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.9333333333333333\nepisode: 45   score: 3.0   memory length: 9061   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.9565217391304348\nepisode: 46   score: 3.0   memory length: 9306   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.9787234042553192\nepisode: 47   score: 4.0   memory length: 9601   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 2.0208333333333335\nepisode: 48   score: 2.0   memory length: 9798   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 2.020408163265306\nepisode: 49   score: 2.0   memory length: 10017   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 2.02\nepisode: 50   score: 4.0   memory length: 10294   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 2.0588235294117645\nepisode: 51   score: 1.0   memory length: 10465   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 2.0384615384615383\nepisode: 52   score: 0.0   memory length: 10588   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.0\nepisode: 53   score: 2.0   memory length: 10806   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 2.0\nepisode: 54   score: 0.0   memory length: 10929   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9636363636363636\nepisode: 55   score: 0.0   memory length: 11052   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9285714285714286\nepisode: 56   score: 3.0   memory length: 11284   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.9473684210526316\nepisode: 57   score: 0.0   memory length: 11406   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.9137931034482758\nepisode: 58   score: 3.0   memory length: 11672   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.9322033898305084\nepisode: 59   score: 0.0   memory length: 11794   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.9\nepisode: 60   score: 2.0   memory length: 11992   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.901639344262295\nepisode: 61   score: 2.0   memory length: 12210   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.903225806451613\nepisode: 62   score: 1.0   memory length: 12379   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.8888888888888888\nepisode: 63   score: 6.0   memory length: 12726   epsilon: 1.0    steps: 347    lr: 0.0001     evaluation reward: 1.953125\nepisode: 64   score: 2.0   memory length: 12924   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.9538461538461538\nepisode: 65   score: 0.0   memory length: 13046   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.9242424242424243\nepisode: 66   score: 5.0   memory length: 13350   epsilon: 1.0    steps: 304    lr: 0.0001     evaluation reward: 1.9701492537313432\nepisode: 67   score: 5.0   memory length: 13659   epsilon: 1.0    steps: 309    lr: 0.0001     evaluation reward: 2.014705882352941\nepisode: 68   score: 2.0   memory length: 13857   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.0144927536231885\nepisode: 69   score: 2.0   memory length: 14075   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 2.0142857142857142\nepisode: 70   score: 0.0   memory length: 14198   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9859154929577465\nepisode: 71   score: 7.0   memory length: 14619   epsilon: 1.0    steps: 421    lr: 0.0001     evaluation reward: 2.0555555555555554\nepisode: 72   score: 1.0   memory length: 14787   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 2.041095890410959\nepisode: 73   score: 1.0   memory length: 14956   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.027027027027027\nepisode: 74   score: 0.0   memory length: 15078   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 2.0\nepisode: 75   score: 0.0   memory length: 15201   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.9736842105263157\nepisode: 76   score: 1.0   memory length: 15371   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.9610389610389611\nepisode: 77   score: 1.0   memory length: 15522   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.9487179487179487\nepisode: 78   score: 2.0   memory length: 15719   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.9493670886075949\nepisode: 79   score: 2.0   memory length: 15917   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.95\nepisode: 80   score: 1.0   memory length: 16068   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.9382716049382716\nepisode: 81   score: 2.0   memory length: 16266   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.9390243902439024\nepisode: 82   score: 0.0   memory length: 16388   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.9156626506024097\nepisode: 83   score: 2.0   memory length: 16591   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.9166666666666667\nepisode: 84   score: 1.0   memory length: 16741   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.9058823529411764\nepisode: 85   score: 3.0   memory length: 16967   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.9186046511627908\nepisode: 86   score: 2.0   memory length: 17165   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.9195402298850575\nepisode: 87   score: 0.0   memory length: 17288   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8977272727272727\nepisode: 88   score: 1.0   memory length: 17457   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.8876404494382022\nepisode: 89   score: 0.0   memory length: 17580   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8666666666666667\nepisode: 90   score: 3.0   memory length: 17807   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.879120879120879\nepisode: 91   score: 2.0   memory length: 18009   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.8804347826086956\nepisode: 92   score: 2.0   memory length: 18210   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.881720430107527\nepisode: 93   score: 3.0   memory length: 18437   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.8936170212765957\nepisode: 94   score: 0.0   memory length: 18560   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8736842105263158\nepisode: 95   score: 2.0   memory length: 18758   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.875\nepisode: 96   score: 1.0   memory length: 18927   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.865979381443299\nepisode: 97   score: 0.0   memory length: 19050   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.846938775510204\nepisode: 98   score: 2.0   memory length: 19266   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.8484848484848484\nepisode: 99   score: 2.0   memory length: 19464   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.85\nepisode: 100   score: 1.0   memory length: 19633   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.85\nepisode: 101   score: 0.0   memory length: 19756   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.84\nepisode: 102   score: 0.0   memory length: 19879   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.81\nepisode: 103   score: 1.0   memory length: 20048   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.75\nepisode: 104   score: 1.0   memory length: 20200   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.67\nepisode: 105   score: 0.0   memory length: 20322   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.65\nepisode: 106   score: 0.0   memory length: 20445   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 107   score: 0.0   memory length: 20568   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 108   score: 1.0   memory length: 20736   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.61\nepisode: 109   score: 0.0   memory length: 20859   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 110   score: 0.0   memory length: 20982   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 111   score: 2.0   memory length: 21182   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6\nepisode: 112   score: 4.0   memory length: 21474   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.63\nepisode: 113   score: 1.0   memory length: 21643   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\nepisode: 114   score: 1.0   memory length: 21794   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.63\nepisode: 115   score: 1.0   memory length: 21944   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.64\nepisode: 116   score: 3.0   memory length: 22190   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.65\nepisode: 117   score: 0.0   memory length: 22313   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 118   score: 0.0   memory length: 22436   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 119   score: 2.0   memory length: 22656   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.63\nepisode: 120   score: 2.0   memory length: 22875   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.62\nepisode: 121   score: 0.0   memory length: 22997   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 122   score: 0.0   memory length: 23119   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 123   score: 1.0   memory length: 23269   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.59\nepisode: 124   score: 5.0   memory length: 23575   epsilon: 1.0    steps: 306    lr: 0.0001     evaluation reward: 1.63\nepisode: 125   score: 0.0   memory length: 23698   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 126   score: 1.0   memory length: 23866   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6\nepisode: 127   score: 0.0   memory length: 23989   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 128   score: 1.0   memory length: 24140   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 129   score: 1.0   memory length: 24308   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.57\nepisode: 130   score: 0.0   memory length: 24431   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 131   score: 1.0   memory length: 24600   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\nepisode: 132   score: 0.0   memory length: 24722   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 133   score: 0.0   memory length: 24844   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 134   score: 2.0   memory length: 25061   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.53\nepisode: 135   score: 1.0   memory length: 25233   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.54\nepisode: 136   score: 1.0   memory length: 25386   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.53\nepisode: 137   score: 0.0   memory length: 25509   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 138   score: 2.0   memory length: 25708   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.5\nepisode: 139   score: 2.0   memory length: 25923   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.49\nepisode: 140   score: 0.0   memory length: 26045   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 141   score: 2.0   memory length: 26264   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5\nepisode: 142   score: 3.0   memory length: 26511   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.44\nepisode: 143   score: 4.0   memory length: 26827   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.46\nepisode: 144   score: 1.0   memory length: 26996   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 145   score: 3.0   memory length: 27245   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.46\nepisode: 146   score: 5.0   memory length: 27571   epsilon: 1.0    steps: 326    lr: 0.0001     evaluation reward: 1.48\nepisode: 147   score: 3.0   memory length: 27815   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.47\nepisode: 148   score: 8.0   memory length: 28145   epsilon: 1.0    steps: 330    lr: 0.0001     evaluation reward: 1.53\nepisode: 149   score: 0.0   memory length: 28268   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 150   score: 2.0   memory length: 28466   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 151   score: 1.0   memory length: 28617   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 152   score: 1.0   memory length: 28786   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\nepisode: 153   score: 2.0   memory length: 28983   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\nepisode: 154   score: 4.0   memory length: 29256   epsilon: 1.0    steps: 273    lr: 0.0001     evaluation reward: 1.54\nepisode: 155   score: 6.0   memory length: 29612   epsilon: 1.0    steps: 356    lr: 0.0001     evaluation reward: 1.6\nepisode: 156   score: 2.0   memory length: 29812   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.59\nepisode: 157   score: 1.0   memory length: 29981   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6\nepisode: 158   score: 0.0   memory length: 30103   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\nepisode: 159   score: 1.0   memory length: 30255   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.58\nepisode: 160   score: 2.0   memory length: 30453   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\nepisode: 161   score: 1.0   memory length: 30603   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.57\nepisode: 162   score: 3.0   memory length: 30853   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.59\nepisode: 163   score: 0.0   memory length: 30976   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 164   score: 1.0   memory length: 31127   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.52\nepisode: 165   score: 2.0   memory length: 31325   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\nepisode: 166   score: 2.0   memory length: 31523   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\nepisode: 167   score: 2.0   memory length: 31742   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.48\nepisode: 168   score: 2.0   memory length: 31959   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.48\nepisode: 169   score: 0.0   memory length: 32081   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\nepisode: 170   score: 2.0   memory length: 32297   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.48\nepisode: 171   score: 0.0   memory length: 32420   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 172   score: 3.0   memory length: 32646   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.43\nepisode: 173   score: 0.0   memory length: 32769   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 174   score: 3.0   memory length: 33035   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.45\nepisode: 175   score: 0.0   memory length: 33158   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 176   score: 0.0   memory length: 33281   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 177   score: 2.0   memory length: 33480   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.45\nepisode: 178   score: 0.0   memory length: 33603   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 179   score: 1.0   memory length: 33754   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\nepisode: 180   score: 0.0   memory length: 33877   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 181   score: 0.0   memory length: 34000   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 182   score: 2.0   memory length: 34198   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\nepisode: 183   score: 0.0   memory length: 34321   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 184   score: 2.0   memory length: 34519   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\nepisode: 185   score: 3.0   memory length: 34786   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.4\nepisode: 186   score: 2.0   memory length: 35003   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\nepisode: 187   score: 2.0   memory length: 35183   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.42\nepisode: 188   score: 1.0   memory length: 35333   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.42\nepisode: 189   score: 1.0   memory length: 35502   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\nepisode: 190   score: 2.0   memory length: 35703   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.42\nepisode: 191   score: 1.0   memory length: 35872   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 192   score: 4.0   memory length: 36165   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.43\nepisode: 193   score: 0.0   memory length: 36287   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\nepisode: 194   score: 0.0   memory length: 36410   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 195   score: 1.0   memory length: 36579   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\nepisode: 196   score: 1.0   memory length: 36750   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.39\nepisode: 197   score: 2.0   memory length: 36948   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\nepisode: 198   score: 0.0   memory length: 37071   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 199   score: 2.0   memory length: 37268   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.39\nepisode: 200   score: 0.0   memory length: 37390   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\nepisode: 201   score: 2.0   memory length: 37608   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\nepisode: 202   score: 0.0   memory length: 37731   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 203   score: 1.0   memory length: 37899   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4\nepisode: 204   score: 3.0   memory length: 38148   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.42\nepisode: 205   score: 2.0   memory length: 38345   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.44\nepisode: 206   score: 0.0   memory length: 38468   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 207   score: 0.0   memory length: 38591   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 208   score: 0.0   memory length: 38713   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 209   score: 3.0   memory length: 38940   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.46\nepisode: 210   score: 3.0   memory length: 39188   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.49\nepisode: 211   score: 5.0   memory length: 39515   epsilon: 1.0    steps: 327    lr: 0.0001     evaluation reward: 1.52\nepisode: 212   score: 4.0   memory length: 39810   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.52\nepisode: 213   score: 1.0   memory length: 39961   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.52\nepisode: 214   score: 1.0   memory length: 40130   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\nepisode: 215   score: 3.0   memory length: 40376   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.54\nepisode: 216   score: 0.0   memory length: 40498   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 217   score: 2.0   memory length: 40697   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\nepisode: 218   score: 5.0   memory length: 41039   epsilon: 1.0    steps: 342    lr: 0.0001     evaluation reward: 1.58\nepisode: 219   score: 1.0   memory length: 41208   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\nepisode: 220   score: 3.0   memory length: 41434   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.58\nepisode: 221   score: 1.0   memory length: 41604   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.59\nepisode: 222   score: 2.0   memory length: 41819   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.61\nepisode: 223   score: 1.0   memory length: 41989   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\nepisode: 224   score: 2.0   memory length: 42187   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\nepisode: 225   score: 3.0   memory length: 42437   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.61\nepisode: 226   score: 0.0   memory length: 42560   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 227   score: 0.0   memory length: 42683   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 228   score: 0.0   memory length: 42806   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 229   score: 0.0   memory length: 42929   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 230   score: 2.0   memory length: 43145   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.6\nepisode: 231   score: 2.0   memory length: 43363   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.61\nepisode: 232   score: 1.0   memory length: 43535   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.62\nepisode: 233   score: 0.0   memory length: 43658   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 234   score: 2.0   memory length: 43855   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.62\nepisode: 235   score: 7.0   memory length: 44282   epsilon: 1.0    steps: 427    lr: 0.0001     evaluation reward: 1.68\nepisode: 236   score: 2.0   memory length: 44500   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.69\nepisode: 237   score: 0.0   memory length: 44623   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.69\nepisode: 238   score: 0.0   memory length: 44746   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 239   score: 1.0   memory length: 44897   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\nepisode: 240   score: 1.0   memory length: 45065   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.67\nepisode: 241   score: 1.0   memory length: 45216   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\nepisode: 242   score: 0.0   memory length: 45339   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 243   score: 2.0   memory length: 45557   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.61\nepisode: 244   score: 0.0   memory length: 45679   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 245   score: 0.0   memory length: 45802   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 246   score: 1.0   memory length: 45972   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.53\nepisode: 247   score: 2.0   memory length: 46169   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.52\nepisode: 248   score: 0.0   memory length: 46292   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 249   score: 3.0   memory length: 46518   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.47\nepisode: 250   score: 0.0   memory length: 46641   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 251   score: 1.0   memory length: 46810   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\nepisode: 252   score: 3.0   memory length: 47074   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.47\nepisode: 253   score: 0.0   memory length: 47196   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.45\nepisode: 254   score: 3.0   memory length: 47421   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.44\nepisode: 255   score: 2.0   memory length: 47638   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\nepisode: 256   score: 2.0   memory length: 47836   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\nepisode: 257   score: 0.0   memory length: 47959   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 258   score: 2.0   memory length: 48157   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\nepisode: 259   score: 2.0   memory length: 48358   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.42\nepisode: 260   score: 3.0   memory length: 48601   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.43\nepisode: 261   score: 1.0   memory length: 48770   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\nepisode: 262   score: 1.0   memory length: 48921   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\nepisode: 263   score: 2.0   memory length: 49140   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.43\nepisode: 264   score: 1.0   memory length: 49291   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\nepisode: 265   score: 2.0   memory length: 49489   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\nepisode: 266   score: 2.0   memory length: 49687   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\nepisode: 267   score: 2.0   memory length: 49885   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\nepisode: 268   score: 3.0   memory length: 50095   epsilon: 1.0    steps: 210    lr: 0.0001     evaluation reward: 1.44\nepisode: 269   score: 2.0   memory length: 50310   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.46\nepisode: 270   score: 2.0   memory length: 50508   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 271   score: 3.0   memory length: 50734   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.49\nepisode: 272   score: 2.0   memory length: 50952   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.48\nepisode: 273   score: 2.0   memory length: 51149   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\nepisode: 274   score: 2.0   memory length: 51347   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 275   score: 4.0   memory length: 51641   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.53\nepisode: 276   score: 1.0   memory length: 51810   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.54\nepisode: 277   score: 0.0   memory length: 51932   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 278   score: 0.0   memory length: 52055   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 279   score: 2.0   memory length: 52274   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.53\nepisode: 280   score: 1.0   memory length: 52425   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.54\nepisode: 281   score: 2.0   memory length: 52608   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.56\nepisode: 282   score: 2.0   memory length: 52806   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.56\nepisode: 283   score: 0.0   memory length: 52929   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 284   score: 0.0   memory length: 53051   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\nepisode: 285   score: 2.0   memory length: 53268   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.53\nepisode: 286   score: 2.0   memory length: 53486   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\nepisode: 287   score: 1.0   memory length: 53655   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\nepisode: 288   score: 3.0   memory length: 53902   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.54\nepisode: 289   score: 0.0   memory length: 54024   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 290   score: 3.0   memory length: 54272   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.54\nepisode: 291   score: 2.0   memory length: 54487   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.55\nepisode: 292   score: 3.0   memory length: 54734   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.54\nepisode: 293   score: 2.0   memory length: 54951   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.56\nepisode: 294   score: 1.0   memory length: 55119   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.57\nepisode: 295   score: 0.0   memory length: 55242   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 296   score: 3.0   memory length: 55468   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.58\nepisode: 297   score: 3.0   memory length: 55733   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.59\nepisode: 298   score: 0.0   memory length: 55855   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.59\nepisode: 299   score: 1.0   memory length: 56023   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.58\nepisode: 300   score: 0.0   memory length: 56146   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 301   score: 1.0   memory length: 56315   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\nepisode: 302   score: 1.0   memory length: 56466   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 303   score: 2.0   memory length: 56684   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.59\nepisode: 304   score: 3.0   memory length: 56928   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.59\nepisode: 305   score: 0.0   memory length: 57051   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 306   score: 1.0   memory length: 57220   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\nepisode: 307   score: 3.0   memory length: 57468   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.61\nepisode: 308   score: 0.0   memory length: 57591   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 309   score: 1.0   memory length: 57762   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.59\nepisode: 310   score: 3.0   memory length: 58031   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.59\nepisode: 311   score: 0.0   memory length: 58153   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\nepisode: 312   score: 2.0   memory length: 58351   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\nepisode: 313   score: 1.0   memory length: 58501   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.52\nepisode: 314   score: 0.0   memory length: 58623   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 315   score: 3.0   memory length: 58849   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.51\nepisode: 316   score: 1.0   memory length: 59001   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.52\nepisode: 317   score: 0.0   memory length: 59123   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\nepisode: 318   score: 1.0   memory length: 59292   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 319   score: 1.0   memory length: 59443   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\nepisode: 320   score: 0.0   memory length: 59566   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 321   score: 2.0   memory length: 59767   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.44\nepisode: 322   score: 2.0   memory length: 59964   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.44\nepisode: 323   score: 2.0   memory length: 60182   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.45\nepisode: 324   score: 1.0   memory length: 60334   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.44\nepisode: 325   score: 1.0   memory length: 60503   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 326   score: 2.0   memory length: 60701   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\nepisode: 327   score: 1.0   memory length: 60870   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\nepisode: 328   score: 3.0   memory length: 61113   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.48\nepisode: 329   score: 2.0   memory length: 61330   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.5\nepisode: 330   score: 2.0   memory length: 61527   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\nepisode: 331   score: 1.0   memory length: 61696   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 332   score: 1.0   memory length: 61865   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 333   score: 2.0   memory length: 62044   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.51\nepisode: 334   score: 2.0   memory length: 62224   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.51\nepisode: 335   score: 1.0   memory length: 62375   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 336   score: 3.0   memory length: 62621   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.46\nepisode: 337   score: 0.0   memory length: 62744   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 338   score: 1.0   memory length: 62895   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.47\nepisode: 339   score: 1.0   memory length: 63066   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.47\nepisode: 340   score: 2.0   memory length: 63264   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\nepisode: 341   score: 0.0   memory length: 63386   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\nepisode: 342   score: 1.0   memory length: 63557   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.48\nepisode: 343   score: 1.0   memory length: 63729   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.47\nepisode: 344   score: 1.0   memory length: 63880   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\nepisode: 345   score: 2.0   memory length: 64098   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\nepisode: 346   score: 2.0   memory length: 64314   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.51\nepisode: 347   score: 2.0   memory length: 64532   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.51\nepisode: 348   score: 2.0   memory length: 64729   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.53\nepisode: 349   score: 1.0   memory length: 64898   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\nepisode: 350   score: 0.0   memory length: 65021   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 351   score: 0.0   memory length: 65144   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 352   score: 0.0   memory length: 65267   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 353   score: 2.0   memory length: 65465   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 354   score: 5.0   memory length: 65790   epsilon: 1.0    steps: 325    lr: 0.0001     evaluation reward: 1.51\nepisode: 355   score: 0.0   memory length: 65912   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\nepisode: 356   score: 2.0   memory length: 66130   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.49\nepisode: 357   score: 2.0   memory length: 66328   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\nepisode: 358   score: 0.0   memory length: 66451   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 359   score: 0.0   memory length: 66573   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\nepisode: 360   score: 1.0   memory length: 66743   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\nepisode: 361   score: 2.0   memory length: 66961   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\nepisode: 362   score: 3.0   memory length: 67204   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.48\nepisode: 363   score: 2.0   memory length: 67402   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\nepisode: 364   score: 7.0   memory length: 67807   epsilon: 1.0    steps: 405    lr: 0.0001     evaluation reward: 1.54\nepisode: 365   score: 3.0   memory length: 68052   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.55\nepisode: 366   score: 2.0   memory length: 68270   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.55\nepisode: 367   score: 0.0   memory length: 68393   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 368   score: 1.0   memory length: 68544   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.51\nepisode: 369   score: 1.0   memory length: 68715   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\nepisode: 370   score: 0.0   memory length: 68838   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 371   score: 2.0   memory length: 69038   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.47\nepisode: 372   score: 2.0   memory length: 69255   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.47\nepisode: 373   score: 1.0   memory length: 69405   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.46\nepisode: 374   score: 1.0   memory length: 69576   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.45\nepisode: 375   score: 2.0   memory length: 69774   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\nepisode: 376   score: 0.0   memory length: 69896   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 377   score: 0.0   memory length: 70018   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 378   score: 0.0   memory length: 70141   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 379   score: 2.0   memory length: 70339   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\nepisode: 380   score: 1.0   memory length: 70507   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.42\nepisode: 381   score: 0.0   memory length: 70630   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 382   score: 3.0   memory length: 70879   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.41\nepisode: 383   score: 0.0   memory length: 71002   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 384   score: 3.0   memory length: 71268   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.44\nepisode: 385   score: 4.0   memory length: 71561   epsilon: 1.0    steps: 293    lr: 0.0001     evaluation reward: 1.46\nepisode: 386   score: 3.0   memory length: 71787   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.47\nepisode: 387   score: 0.0   memory length: 71910   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 388   score: 2.0   memory length: 72112   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.45\nepisode: 389   score: 2.0   memory length: 72309   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.47\nepisode: 390   score: 1.0   memory length: 72459   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.45\nepisode: 391   score: 2.0   memory length: 72656   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\nepisode: 392   score: 3.0   memory length: 72901   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.45\nepisode: 393   score: 2.0   memory length: 73099   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\nepisode: 394   score: 1.0   memory length: 73250   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 395   score: 2.0   memory length: 73449   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.47\nepisode: 396   score: 0.0   memory length: 73572   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 397   score: 0.0   memory length: 73695   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 398   score: 4.0   memory length: 73971   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.45\nepisode: 399   score: 2.0   memory length: 74169   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 400   score: 0.0   memory length: 74292   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 401   score: 0.0   memory length: 74415   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 402   score: 1.0   memory length: 74585   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\nepisode: 403   score: 1.0   memory length: 74736   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\nepisode: 404   score: 2.0   memory length: 74933   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.43\nepisode: 405   score: 0.0   memory length: 75056   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 406   score: 1.0   memory length: 75227   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.43\nepisode: 407   score: 1.0   memory length: 75396   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 408   score: 0.0   memory length: 75518   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\nepisode: 409   score: 1.0   memory length: 75688   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\nepisode: 410   score: 3.0   memory length: 75934   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.41\nepisode: 411   score: 0.0   memory length: 76057   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 412   score: 1.0   memory length: 76226   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\nepisode: 413   score: 0.0   memory length: 76348   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\nepisode: 414   score: 0.0   memory length: 76471   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 415   score: 1.0   memory length: 76622   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\nepisode: 416   score: 1.0   memory length: 76773   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\nepisode: 417   score: 3.0   memory length: 76999   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.4\nepisode: 418   score: 3.0   memory length: 77265   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.42\nepisode: 419   score: 3.0   memory length: 77478   epsilon: 1.0    steps: 213    lr: 0.0001     evaluation reward: 1.44\nepisode: 420   score: 1.0   memory length: 77647   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\nepisode: 421   score: 3.0   memory length: 77891   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.46\nepisode: 422   score: 2.0   memory length: 78089   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 423   score: 0.0   memory length: 78212   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 424   score: 2.0   memory length: 78392   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.45\nepisode: 425   score: 0.0   memory length: 78514   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 426   score: 0.0   memory length: 78637   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 427   score: 1.0   memory length: 78806   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 428   score: 0.0   memory length: 78929   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 429   score: 4.0   memory length: 79243   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.41\nepisode: 430   score: 0.0   memory length: 79366   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 431   score: 1.0   memory length: 79536   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\nepisode: 432   score: 1.0   memory length: 79705   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\nepisode: 433   score: 3.0   memory length: 79952   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.4\nepisode: 434   score: 1.0   memory length: 80123   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.39\nepisode: 435   score: 0.0   memory length: 80246   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 436   score: 0.0   memory length: 80369   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 437   score: 2.0   memory length: 80567   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\nepisode: 438   score: 1.0   memory length: 80736   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.37\nepisode: 439   score: 0.0   memory length: 80859   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\nepisode: 440   score: 3.0   memory length: 81088   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.37\nepisode: 441   score: 2.0   memory length: 81306   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.39\nepisode: 442   score: 0.0   memory length: 81429   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 443   score: 2.0   memory length: 81645   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.39\nepisode: 444   score: 2.0   memory length: 81863   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\nepisode: 445   score: 2.0   memory length: 82080   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\nepisode: 446   score: 4.0   memory length: 82358   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.42\nepisode: 447   score: 2.0   memory length: 82556   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\nepisode: 448   score: 2.0   memory length: 82775   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.42\nepisode: 449   score: 0.0   memory length: 82898   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 450   score: 2.0   memory length: 83116   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.43\nepisode: 451   score: 0.0   memory length: 83239   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 452   score: 1.0   memory length: 83407   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.44\nepisode: 453   score: 1.0   memory length: 83557   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\nepisode: 454   score: 1.0   memory length: 83728   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.39\nepisode: 455   score: 0.0   memory length: 83850   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.39\nepisode: 456   score: 1.0   memory length: 84018   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.38\nepisode: 457   score: 2.0   memory length: 84234   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.38\nepisode: 458   score: 0.0   memory length: 84357   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 459   score: 0.0   memory length: 84479   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\nepisode: 460   score: 0.0   memory length: 84601   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 461   score: 1.0   memory length: 84751   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.36\nepisode: 462   score: 0.0   memory length: 84874   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\nepisode: 463   score: 2.0   memory length: 85072   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.33\nepisode: 464   score: 1.0   memory length: 85223   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.27\nepisode: 465   score: 4.0   memory length: 85498   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.28\nepisode: 466   score: 1.0   memory length: 85648   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.27\nepisode: 467   score: 0.0   memory length: 85770   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.27\nepisode: 468   score: 2.0   memory length: 85968   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.28\nepisode: 469   score: 4.0   memory length: 86259   epsilon: 1.0    steps: 291    lr: 0.0001     evaluation reward: 1.31\nepisode: 470   score: 1.0   memory length: 86430   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.32\nepisode: 471   score: 2.0   memory length: 86647   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.32\nepisode: 472   score: 1.0   memory length: 86816   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.31\nepisode: 473   score: 2.0   memory length: 87014   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.32\nepisode: 474   score: 1.0   memory length: 87184   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.32\nepisode: 475   score: 1.0   memory length: 87353   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.31\nepisode: 476   score: 2.0   memory length: 87551   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.33\nepisode: 477   score: 2.0   memory length: 87749   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\nepisode: 478   score: 1.0   memory length: 87921   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.36\nepisode: 479   score: 1.0   memory length: 88090   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\nepisode: 480   score: 0.0   memory length: 88213   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\nepisode: 481   score: 1.0   memory length: 88383   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\nepisode: 482   score: 2.0   memory length: 88601   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.34\nepisode: 483   score: 1.0   memory length: 88752   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.35\nepisode: 484   score: 0.0   memory length: 88875   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\nepisode: 485   score: 0.0   memory length: 88998   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.28\nepisode: 486   score: 5.0   memory length: 89341   epsilon: 1.0    steps: 343    lr: 0.0001     evaluation reward: 1.3\nepisode: 487   score: 3.0   memory length: 89588   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.33\nepisode: 488   score: 3.0   memory length: 89833   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.34\nepisode: 489   score: 2.0   memory length: 90032   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.34\nepisode: 490   score: 3.0   memory length: 90279   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.36\nepisode: 491   score: 0.0   memory length: 90402   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\nepisode: 492   score: 3.0   memory length: 90664   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.34\nepisode: 493   score: 2.0   memory length: 90880   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.34\nepisode: 494   score: 0.0   memory length: 91003   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\nepisode: 495   score: 0.0   memory length: 91126   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\nepisode: 496   score: 3.0   memory length: 91356   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.34\nepisode: 497   score: 2.0   memory length: 91553   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.36\nepisode: 498   score: 3.0   memory length: 91797   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.35\nepisode: 499   score: 2.0   memory length: 92015   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.35\nepisode: 500   score: 0.0   memory length: 92138   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 501   score: 2.0   memory length: 92335   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.37\nepisode: 502   score: 0.0   memory length: 92457   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.36\nepisode: 503   score: 4.0   memory length: 92752   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.39\nepisode: 504   score: 0.0   memory length: 92875   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\nepisode: 505   score: 0.0   memory length: 92997   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 506   score: 2.0   memory length: 93177   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.38\nepisode: 507   score: 3.0   memory length: 93405   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.4\nepisode: 508   score: 1.0   memory length: 93575   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\nepisode: 509   score: 2.0   memory length: 93772   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.42\nepisode: 510   score: 3.0   memory length: 94000   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.42\nepisode: 511   score: 2.0   memory length: 94199   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.44\nepisode: 512   score: 2.0   memory length: 94419   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.45\nepisode: 513   score: 0.0   memory length: 94541   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.45\nepisode: 514   score: 2.0   memory length: 94742   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.47\nepisode: 515   score: 2.0   memory length: 94939   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.48\nepisode: 516   score: 3.0   memory length: 95206   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.5\nepisode: 517   score: 3.0   memory length: 95435   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.5\nepisode: 518   score: 4.0   memory length: 95730   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.51\nepisode: 519   score: 1.0   memory length: 95881   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 520   score: 1.0   memory length: 96050   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 521   score: 4.0   memory length: 96345   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.5\nepisode: 522   score: 1.0   memory length: 96495   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.49\nepisode: 523   score: 3.0   memory length: 96757   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.52\nepisode: 524   score: 1.0   memory length: 96908   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.51\nepisode: 525   score: 5.0   memory length: 97254   epsilon: 1.0    steps: 346    lr: 0.0001     evaluation reward: 1.56\nepisode: 526   score: 1.0   memory length: 97423   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\nepisode: 527   score: 2.0   memory length: 97621   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\nepisode: 528   score: 0.0   memory length: 97744   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 529   score: 0.0   memory length: 97866   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\nepisode: 530   score: 3.0   memory length: 98115   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.57\nepisode: 531   score: 0.0   memory length: 98238   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 532   score: 4.0   memory length: 98517   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.59\nepisode: 533   score: 1.0   memory length: 98667   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.57\nepisode: 534   score: 2.0   memory length: 98886   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.58\nepisode: 535   score: 2.0   memory length: 99084   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6\nepisode: 536   score: 0.0   memory length: 99207   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 537   score: 0.0   memory length: 99330   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 538   score: 7.0   memory length: 99734   epsilon: 1.0    steps: 404    lr: 0.0001     evaluation reward: 1.64\nepisode: 539   score: 4.0   memory length: 100046   epsilon: 0.999906940000002    steps: 312    lr: 0.0001     evaluation reward: 1.68\nepisode: 540   score: 3.0   memory length: 100293   epsilon: 0.9994178800000126    steps: 247    lr: 0.0001     evaluation reward: 1.68\nepisode: 541   score: 2.0   memory length: 100490   epsilon: 0.9990278200000211    steps: 197    lr: 0.0001     evaluation reward: 1.68\nepisode: 542   score: 1.0   memory length: 100641   epsilon: 0.9987288400000276    steps: 151    lr: 0.0001     evaluation reward: 1.69\nepisode: 543   score: 0.0   memory length: 100764   epsilon: 0.9984853000000329    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 544   score: 1.0   memory length: 100936   epsilon: 0.9981447400000403    steps: 172    lr: 0.0001     evaluation reward: 1.66\nepisode: 545   score: 3.0   memory length: 101201   epsilon: 0.9976200400000517    steps: 265    lr: 0.0001     evaluation reward: 1.67\nepisode: 546   score: 0.0   memory length: 101323   epsilon: 0.9973784800000569    steps: 122    lr: 0.0001     evaluation reward: 1.63\nepisode: 547   score: 1.0   memory length: 101474   epsilon: 0.9970795000000634    steps: 151    lr: 0.0001     evaluation reward: 1.62\nepisode: 548   score: 1.0   memory length: 101625   epsilon: 0.9967805200000699    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 549   score: 2.0   memory length: 101804   epsilon: 0.9964261000000776    steps: 179    lr: 0.0001     evaluation reward: 1.63\nepisode: 550   score: 0.0   memory length: 101926   epsilon: 0.9961845400000828    steps: 122    lr: 0.0001     evaluation reward: 1.61\nepisode: 551   score: 3.0   memory length: 102189   epsilon: 0.9956638000000941    steps: 263    lr: 0.0001     evaluation reward: 1.64\nepisode: 552   score: 1.0   memory length: 102358   epsilon: 0.9953291800001014    steps: 169    lr: 0.0001     evaluation reward: 1.64\nepisode: 553   score: 0.0   memory length: 102481   epsilon: 0.9950856400001067    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 554   score: 2.0   memory length: 102679   epsilon: 0.9946936000001152    steps: 198    lr: 0.0001     evaluation reward: 1.64\nepisode: 555   score: 2.0   memory length: 102876   epsilon: 0.9943035400001237    steps: 197    lr: 0.0001     evaluation reward: 1.66\nepisode: 556   score: 6.0   memory length: 103232   epsilon: 0.993598660000139    steps: 356    lr: 0.0001     evaluation reward: 1.71\nepisode: 557   score: 2.0   memory length: 103430   epsilon: 0.9932066200001475    steps: 198    lr: 0.0001     evaluation reward: 1.71\nepisode: 558   score: 2.0   memory length: 103646   epsilon: 0.9927789400001568    steps: 216    lr: 0.0001     evaluation reward: 1.73\nepisode: 559   score: 1.0   memory length: 103817   epsilon: 0.9924403600001641    steps: 171    lr: 0.0001     evaluation reward: 1.74\nepisode: 560   score: 0.0   memory length: 103939   epsilon: 0.9921988000001694    steps: 122    lr: 0.0001     evaluation reward: 1.74\nepisode: 561   score: 1.0   memory length: 104090   epsilon: 0.9918998200001758    steps: 151    lr: 0.0001     evaluation reward: 1.74\nepisode: 562   score: 2.0   memory length: 104288   epsilon: 0.9915077800001844    steps: 198    lr: 0.0001     evaluation reward: 1.76\nepisode: 563   score: 2.0   memory length: 104485   epsilon: 0.9911177200001928    steps: 197    lr: 0.0001     evaluation reward: 1.76\nepisode: 564   score: 0.0   memory length: 104608   epsilon: 0.9908741800001981    steps: 123    lr: 0.0001     evaluation reward: 1.75\nepisode: 565   score: 0.0   memory length: 104730   epsilon: 0.9906326200002034    steps: 122    lr: 0.0001     evaluation reward: 1.71\nepisode: 566   score: 1.0   memory length: 104880   epsilon: 0.9903356200002098    steps: 150    lr: 0.0001     evaluation reward: 1.71\nepisode: 567   score: 3.0   memory length: 105111   epsilon: 0.9898782400002197    steps: 231    lr: 0.0001     evaluation reward: 1.74\nepisode: 568   score: 2.0   memory length: 105329   epsilon: 0.9894466000002291    steps: 218    lr: 0.0001     evaluation reward: 1.74\nepisode: 569   score: 2.0   memory length: 105544   epsilon: 0.9890209000002383    steps: 215    lr: 0.0001     evaluation reward: 1.72\nepisode: 570   score: 1.0   memory length: 105715   epsilon: 0.9886823200002457    steps: 171    lr: 0.0001     evaluation reward: 1.72\nepisode: 571   score: 3.0   memory length: 105927   epsilon: 0.9882625600002548    steps: 212    lr: 0.0001     evaluation reward: 1.73\nepisode: 572   score: 0.0   memory length: 106049   epsilon: 0.98802100000026    steps: 122    lr: 0.0001     evaluation reward: 1.72\nepisode: 573   score: 2.0   memory length: 106248   epsilon: 0.9876269800002686    steps: 199    lr: 0.0001     evaluation reward: 1.72\nepisode: 574   score: 4.0   memory length: 106522   epsilon: 0.9870844600002804    steps: 274    lr: 0.0001     evaluation reward: 1.75\nepisode: 575   score: 3.0   memory length: 106768   epsilon: 0.986597380000291    steps: 246    lr: 0.0001     evaluation reward: 1.77\nepisode: 576   score: 0.0   memory length: 106891   epsilon: 0.9863538400002962    steps: 123    lr: 0.0001     evaluation reward: 1.75\nepisode: 577   score: 0.0   memory length: 107014   epsilon: 0.9861103000003015    steps: 123    lr: 0.0001     evaluation reward: 1.73\nepisode: 578   score: 2.0   memory length: 107233   epsilon: 0.985676680000311    steps: 219    lr: 0.0001     evaluation reward: 1.74\nepisode: 579   score: 1.0   memory length: 107383   epsilon: 0.9853796800003174    steps: 150    lr: 0.0001     evaluation reward: 1.74\nepisode: 580   score: 1.0   memory length: 107534   epsilon: 0.9850807000003239    steps: 151    lr: 0.0001     evaluation reward: 1.75\nepisode: 581   score: 1.0   memory length: 107685   epsilon: 0.9847817200003304    steps: 151    lr: 0.0001     evaluation reward: 1.75\nepisode: 582   score: 0.0   memory length: 107808   epsilon: 0.9845381800003357    steps: 123    lr: 0.0001     evaluation reward: 1.73\nepisode: 583   score: 2.0   memory length: 108006   epsilon: 0.9841461400003442    steps: 198    lr: 0.0001     evaluation reward: 1.74\nepisode: 584   score: 1.0   memory length: 108175   epsilon: 0.9838115200003514    steps: 169    lr: 0.0001     evaluation reward: 1.75\nepisode: 585   score: 0.0   memory length: 108297   epsilon: 0.9835699600003567    steps: 122    lr: 0.0001     evaluation reward: 1.75\nepisode: 586   score: 4.0   memory length: 108595   epsilon: 0.9829799200003695    steps: 298    lr: 0.0001     evaluation reward: 1.74\nepisode: 587   score: 2.0   memory length: 108795   epsilon: 0.9825839200003781    steps: 200    lr: 0.0001     evaluation reward: 1.73\nepisode: 588   score: 1.0   memory length: 108963   epsilon: 0.9822512800003853    steps: 168    lr: 0.0001     evaluation reward: 1.71\nepisode: 589   score: 1.0   memory length: 109114   epsilon: 0.9819523000003918    steps: 151    lr: 0.0001     evaluation reward: 1.7\nepisode: 590   score: 0.0   memory length: 109237   epsilon: 0.9817087600003971    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 591   score: 0.0   memory length: 109359   epsilon: 0.9814672000004023    steps: 122    lr: 0.0001     evaluation reward: 1.67\nepisode: 592   score: 2.0   memory length: 109577   epsilon: 0.9810355600004117    steps: 218    lr: 0.0001     evaluation reward: 1.66\nepisode: 593   score: 3.0   memory length: 109789   epsilon: 0.9806158000004208    steps: 212    lr: 0.0001     evaluation reward: 1.67\nepisode: 594   score: 0.0   memory length: 109912   epsilon: 0.9803722600004261    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 595   score: 0.0   memory length: 110035   epsilon: 0.9801287200004314    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 596   score: 1.0   memory length: 110207   epsilon: 0.9797881600004388    steps: 172    lr: 0.0001     evaluation reward: 1.65\nepisode: 597   score: 1.0   memory length: 110376   epsilon: 0.979453540000446    steps: 169    lr: 0.0001     evaluation reward: 1.64\nepisode: 598   score: 0.0   memory length: 110498   epsilon: 0.9792119800004513    steps: 122    lr: 0.0001     evaluation reward: 1.61\nepisode: 599   score: 0.0   memory length: 110621   epsilon: 0.9789684400004566    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 600   score: 2.0   memory length: 110818   epsilon: 0.978578380000465    steps: 197    lr: 0.0001     evaluation reward: 1.61\nepisode: 601   score: 3.0   memory length: 111087   epsilon: 0.9780457600004766    steps: 269    lr: 0.0001     evaluation reward: 1.62\nepisode: 602   score: 2.0   memory length: 111304   epsilon: 0.9776161000004859    steps: 217    lr: 0.0001     evaluation reward: 1.64\nepisode: 603   score: 2.0   memory length: 111501   epsilon: 0.9772260400004944    steps: 197    lr: 0.0001     evaluation reward: 1.62\nepisode: 604   score: 0.0   memory length: 111623   epsilon: 0.9769844800004996    steps: 122    lr: 0.0001     evaluation reward: 1.62\nepisode: 605   score: 2.0   memory length: 111802   epsilon: 0.9766300600005073    steps: 179    lr: 0.0001     evaluation reward: 1.64\nepisode: 606   score: 0.0   memory length: 111924   epsilon: 0.9763885000005126    steps: 122    lr: 0.0001     evaluation reward: 1.62\nepisode: 607   score: 1.0   memory length: 112093   epsilon: 0.9760538800005198    steps: 169    lr: 0.0001     evaluation reward: 1.6\nepisode: 608   score: 3.0   memory length: 112360   epsilon: 0.9755252200005313    steps: 267    lr: 0.0001     evaluation reward: 1.62\nepisode: 609   score: 0.0   memory length: 112483   epsilon: 0.9752816800005366    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 610   score: 1.0   memory length: 112634   epsilon: 0.9749827000005431    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 611   score: 3.0   memory length: 112881   epsilon: 0.9744936400005537    steps: 247    lr: 0.0001     evaluation reward: 1.59\nepisode: 612   score: 2.0   memory length: 113104   epsilon: 0.9740521000005633    steps: 223    lr: 0.0001     evaluation reward: 1.59\nepisode: 613   score: 4.0   memory length: 113401   epsilon: 0.9734640400005761    steps: 297    lr: 0.0001     evaluation reward: 1.63\nepisode: 614   score: 1.0   memory length: 113570   epsilon: 0.9731294200005833    steps: 169    lr: 0.0001     evaluation reward: 1.62\nepisode: 615   score: 0.0   memory length: 113692   epsilon: 0.9728878600005886    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 616   score: 2.0   memory length: 113910   epsilon: 0.972456220000598    steps: 218    lr: 0.0001     evaluation reward: 1.59\nepisode: 617   score: 1.0   memory length: 114078   epsilon: 0.9721235800006052    steps: 168    lr: 0.0001     evaluation reward: 1.57\nepisode: 618   score: 1.0   memory length: 114228   epsilon: 0.9718265800006116    steps: 150    lr: 0.0001     evaluation reward: 1.54\nepisode: 619   score: 0.0   memory length: 114351   epsilon: 0.9715830400006169    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 620   score: 1.0   memory length: 114521   epsilon: 0.9712464400006242    steps: 170    lr: 0.0001     evaluation reward: 1.53\nepisode: 621   score: 0.0   memory length: 114644   epsilon: 0.9710029000006295    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 622   score: 1.0   memory length: 114813   epsilon: 0.9706682800006368    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 623   score: 1.0   memory length: 114981   epsilon: 0.970335640000644    steps: 168    lr: 0.0001     evaluation reward: 1.47\nepisode: 624   score: 0.0   memory length: 115104   epsilon: 0.9700921000006493    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 625   score: 0.0   memory length: 115226   epsilon: 0.9698505400006545    steps: 122    lr: 0.0001     evaluation reward: 1.41\nepisode: 626   score: 2.0   memory length: 115447   epsilon: 0.969412960000664    steps: 221    lr: 0.0001     evaluation reward: 1.42\nepisode: 627   score: 0.0   memory length: 115570   epsilon: 0.9691694200006693    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 628   score: 3.0   memory length: 115795   epsilon: 0.968723920000679    steps: 225    lr: 0.0001     evaluation reward: 1.43\nepisode: 629   score: 1.0   memory length: 115963   epsilon: 0.9683912800006862    steps: 168    lr: 0.0001     evaluation reward: 1.44\nepisode: 630   score: 2.0   memory length: 116161   epsilon: 0.9679992400006947    steps: 198    lr: 0.0001     evaluation reward: 1.43\nepisode: 631   score: 5.0   memory length: 116466   epsilon: 0.9673953400007078    steps: 305    lr: 0.0001     evaluation reward: 1.48\nepisode: 632   score: 3.0   memory length: 116693   epsilon: 0.9669458800007176    steps: 227    lr: 0.0001     evaluation reward: 1.47\nepisode: 633   score: 0.0   memory length: 116816   epsilon: 0.9667023400007229    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 634   score: 1.0   memory length: 116988   epsilon: 0.9663617800007303    steps: 172    lr: 0.0001     evaluation reward: 1.45\nepisode: 635   score: 1.0   memory length: 117156   epsilon: 0.9660291400007375    steps: 168    lr: 0.0001     evaluation reward: 1.44\nepisode: 636   score: 2.0   memory length: 117374   epsilon: 0.9655975000007468    steps: 218    lr: 0.0001     evaluation reward: 1.46\nepisode: 637   score: 3.0   memory length: 117620   epsilon: 0.9651104200007574    steps: 246    lr: 0.0001     evaluation reward: 1.49\nepisode: 638   score: 0.0   memory length: 117743   epsilon: 0.9648668800007627    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 639   score: 1.0   memory length: 117913   epsilon: 0.96453028000077    steps: 170    lr: 0.0001     evaluation reward: 1.39\nepisode: 640   score: 1.0   memory length: 118063   epsilon: 0.9642332800007765    steps: 150    lr: 0.0001     evaluation reward: 1.37\nepisode: 641   score: 1.0   memory length: 118232   epsilon: 0.9638986600007837    steps: 169    lr: 0.0001     evaluation reward: 1.36\nepisode: 642   score: 0.0   memory length: 118355   epsilon: 0.963655120000789    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 643   score: 1.0   memory length: 118526   epsilon: 0.9633165400007964    steps: 171    lr: 0.0001     evaluation reward: 1.36\nepisode: 644   score: 0.0   memory length: 118648   epsilon: 0.9630749800008016    steps: 122    lr: 0.0001     evaluation reward: 1.35\nepisode: 645   score: 3.0   memory length: 118874   epsilon: 0.9626275000008113    steps: 226    lr: 0.0001     evaluation reward: 1.35\nepisode: 646   score: 0.0   memory length: 118997   epsilon: 0.9623839600008166    steps: 123    lr: 0.0001     evaluation reward: 1.35\nepisode: 647   score: 1.0   memory length: 119148   epsilon: 0.9620849800008231    steps: 151    lr: 0.0001     evaluation reward: 1.35\nepisode: 648   score: 0.0   memory length: 119270   epsilon: 0.9618434200008283    steps: 122    lr: 0.0001     evaluation reward: 1.34\nepisode: 649   score: 0.0   memory length: 119393   epsilon: 0.9615998800008336    steps: 123    lr: 0.0001     evaluation reward: 1.32\nepisode: 650   score: 2.0   memory length: 119590   epsilon: 0.9612098200008421    steps: 197    lr: 0.0001     evaluation reward: 1.34\nepisode: 651   score: 0.0   memory length: 119712   epsilon: 0.9609682600008473    steps: 122    lr: 0.0001     evaluation reward: 1.31\nepisode: 652   score: 0.0   memory length: 119834   epsilon: 0.9607267000008526    steps: 122    lr: 0.0001     evaluation reward: 1.3\nepisode: 653   score: 0.0   memory length: 119956   epsilon: 0.9604851400008578    steps: 122    lr: 0.0001     evaluation reward: 1.3\nepisode: 654   score: 2.0   memory length: 120153   epsilon: 0.9600950800008663    steps: 197    lr: 0.0001     evaluation reward: 1.3\nepisode: 655   score: 1.0   memory length: 120322   epsilon: 0.9597604600008736    steps: 169    lr: 0.0001     evaluation reward: 1.29\nepisode: 656   score: 0.0   memory length: 120445   epsilon: 0.9595169200008788    steps: 123    lr: 0.0001     evaluation reward: 1.23\nepisode: 657   score: 2.0   memory length: 120643   epsilon: 0.9591248800008874    steps: 198    lr: 0.0001     evaluation reward: 1.23\nepisode: 658   score: 0.0   memory length: 120765   epsilon: 0.9588833200008926    steps: 122    lr: 0.0001     evaluation reward: 1.21\nepisode: 659   score: 3.0   memory length: 121033   epsilon: 0.9583526800009041    steps: 268    lr: 0.0001     evaluation reward: 1.23\nepisode: 660   score: 0.0   memory length: 121155   epsilon: 0.9581111200009094    steps: 122    lr: 0.0001     evaluation reward: 1.23\nepisode: 661   score: 0.0   memory length: 121277   epsilon: 0.9578695600009146    steps: 122    lr: 0.0001     evaluation reward: 1.22\nepisode: 662   score: 1.0   memory length: 121446   epsilon: 0.9575349400009219    steps: 169    lr: 0.0001     evaluation reward: 1.21\nepisode: 663   score: 2.0   memory length: 121643   epsilon: 0.9571448800009303    steps: 197    lr: 0.0001     evaluation reward: 1.21\nepisode: 664   score: 1.0   memory length: 121793   epsilon: 0.9568478800009368    steps: 150    lr: 0.0001     evaluation reward: 1.22\nepisode: 665   score: 2.0   memory length: 121991   epsilon: 0.9564558400009453    steps: 198    lr: 0.0001     evaluation reward: 1.24\nepisode: 666   score: 2.0   memory length: 122189   epsilon: 0.9560638000009538    steps: 198    lr: 0.0001     evaluation reward: 1.25\nepisode: 667   score: 1.0   memory length: 122360   epsilon: 0.9557252200009612    steps: 171    lr: 0.0001     evaluation reward: 1.23\nepisode: 668   score: 4.0   memory length: 122656   epsilon: 0.9551391400009739    steps: 296    lr: 0.0001     evaluation reward: 1.25\nepisode: 669   score: 0.0   memory length: 122778   epsilon: 0.9548975800009791    steps: 122    lr: 0.0001     evaluation reward: 1.23\nepisode: 670   score: 3.0   memory length: 123026   epsilon: 0.9544065400009898    steps: 248    lr: 0.0001     evaluation reward: 1.25\nepisode: 671   score: 4.0   memory length: 123324   epsilon: 0.9538165000010026    steps: 298    lr: 0.0001     evaluation reward: 1.26\nepisode: 672   score: 0.0   memory length: 123447   epsilon: 0.9535729600010079    steps: 123    lr: 0.0001     evaluation reward: 1.26\nepisode: 673   score: 3.0   memory length: 123690   epsilon: 0.9530918200010183    steps: 243    lr: 0.0001     evaluation reward: 1.27\nepisode: 674   score: 2.0   memory length: 123908   epsilon: 0.9526601800010277    steps: 218    lr: 0.0001     evaluation reward: 1.25\nepisode: 675   score: 0.0   memory length: 124030   epsilon: 0.952418620001033    steps: 122    lr: 0.0001     evaluation reward: 1.22\nepisode: 676   score: 2.0   memory length: 124228   epsilon: 0.9520265800010415    steps: 198    lr: 0.0001     evaluation reward: 1.24\nepisode: 677   score: 0.0   memory length: 124351   epsilon: 0.9517830400010467    steps: 123    lr: 0.0001     evaluation reward: 1.24\nepisode: 678   score: 4.0   memory length: 124648   epsilon: 0.9511949800010595    steps: 297    lr: 0.0001     evaluation reward: 1.26\nepisode: 679   score: 3.0   memory length: 124894   epsilon: 0.9507079000010701    steps: 246    lr: 0.0001     evaluation reward: 1.28\nepisode: 680   score: 2.0   memory length: 125092   epsilon: 0.9503158600010786    steps: 198    lr: 0.0001     evaluation reward: 1.29\nepisode: 681   score: 2.0   memory length: 125289   epsilon: 0.9499258000010871    steps: 197    lr: 0.0001     evaluation reward: 1.3\nepisode: 682   score: 0.0   memory length: 125411   epsilon: 0.9496842400010923    steps: 122    lr: 0.0001     evaluation reward: 1.3\nepisode: 683   score: 3.0   memory length: 125637   epsilon: 0.949236760001102    steps: 226    lr: 0.0001     evaluation reward: 1.31\nepisode: 684   score: 2.0   memory length: 125834   epsilon: 0.9488467000011105    steps: 197    lr: 0.0001     evaluation reward: 1.32\nepisode: 685   score: 1.0   memory length: 126003   epsilon: 0.9485120800011178    steps: 169    lr: 0.0001     evaluation reward: 1.33\nepisode: 686   score: 3.0   memory length: 126250   epsilon: 0.9480230200011284    steps: 247    lr: 0.0001     evaluation reward: 1.32\nepisode: 687   score: 2.0   memory length: 126448   epsilon: 0.9476309800011369    steps: 198    lr: 0.0001     evaluation reward: 1.32\nepisode: 688   score: 2.0   memory length: 126663   epsilon: 0.9472052800011461    steps: 215    lr: 0.0001     evaluation reward: 1.33\nepisode: 689   score: 4.0   memory length: 126941   epsilon: 0.9466548400011581    steps: 278    lr: 0.0001     evaluation reward: 1.36\nepisode: 690   score: 1.0   memory length: 127110   epsilon: 0.9463202200011653    steps: 169    lr: 0.0001     evaluation reward: 1.37\nepisode: 691   score: 0.0   memory length: 127232   epsilon: 0.9460786600011706    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 692   score: 1.0   memory length: 127383   epsilon: 0.9457796800011771    steps: 151    lr: 0.0001     evaluation reward: 1.36\nepisode: 693   score: 1.0   memory length: 127533   epsilon: 0.9454826800011835    steps: 150    lr: 0.0001     evaluation reward: 1.34\nepisode: 694   score: 2.0   memory length: 127733   epsilon: 0.9450866800011921    steps: 200    lr: 0.0001     evaluation reward: 1.36\nepisode: 695   score: 4.0   memory length: 128011   epsilon: 0.9445362400012041    steps: 278    lr: 0.0001     evaluation reward: 1.4\nepisode: 696   score: 5.0   memory length: 128351   epsilon: 0.9438630400012187    steps: 340    lr: 0.0001     evaluation reward: 1.44\nepisode: 697   score: 0.0   memory length: 128474   epsilon: 0.943619500001224    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 698   score: 0.0   memory length: 128597   epsilon: 0.9433759600012293    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 699   score: 3.0   memory length: 128861   epsilon: 0.9428532400012406    steps: 264    lr: 0.0001     evaluation reward: 1.46\nepisode: 700   score: 5.0   memory length: 129170   epsilon: 0.9422414200012539    steps: 309    lr: 0.0001     evaluation reward: 1.49\nepisode: 701   score: 0.0   memory length: 129293   epsilon: 0.9419978800012592    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 702   score: 1.0   memory length: 129444   epsilon: 0.9416989000012657    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 703   score: 2.0   memory length: 129662   epsilon: 0.941267260001275    steps: 218    lr: 0.0001     evaluation reward: 1.45\nepisode: 704   score: 2.0   memory length: 129859   epsilon: 0.9408772000012835    steps: 197    lr: 0.0001     evaluation reward: 1.47\nepisode: 705   score: 0.0   memory length: 129982   epsilon: 0.9406336600012888    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 706   score: 1.0   memory length: 130151   epsilon: 0.940299040001296    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 707   score: 0.0   memory length: 130274   epsilon: 0.9400555000013013    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 708   score: 2.0   memory length: 130472   epsilon: 0.9396634600013098    steps: 198    lr: 0.0001     evaluation reward: 1.44\nepisode: 709   score: 1.0   memory length: 130641   epsilon: 0.9393288400013171    steps: 169    lr: 0.0001     evaluation reward: 1.45\nepisode: 710   score: 2.0   memory length: 130839   epsilon: 0.9389368000013256    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 711   score: 3.0   memory length: 131087   epsilon: 0.9384457600013363    steps: 248    lr: 0.0001     evaluation reward: 1.46\nepisode: 712   score: 2.0   memory length: 131305   epsilon: 0.9380141200013457    steps: 218    lr: 0.0001     evaluation reward: 1.46\nepisode: 713   score: 0.0   memory length: 131427   epsilon: 0.9377725600013509    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 714   score: 4.0   memory length: 131704   epsilon: 0.9372241000013628    steps: 277    lr: 0.0001     evaluation reward: 1.45\nepisode: 715   score: 0.0   memory length: 131827   epsilon: 0.9369805600013681    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 716   score: 3.0   memory length: 132074   epsilon: 0.9364915000013787    steps: 247    lr: 0.0001     evaluation reward: 1.46\nepisode: 717   score: 0.0   memory length: 132196   epsilon: 0.936249940001384    steps: 122    lr: 0.0001     evaluation reward: 1.45\nepisode: 718   score: 1.0   memory length: 132347   epsilon: 0.9359509600013904    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 719   score: 2.0   memory length: 132566   epsilon: 0.9355173400013999    steps: 219    lr: 0.0001     evaluation reward: 1.47\nepisode: 720   score: 3.0   memory length: 132793   epsilon: 0.9350678800014096    steps: 227    lr: 0.0001     evaluation reward: 1.49\nepisode: 721   score: 3.0   memory length: 133021   epsilon: 0.9346164400014194    steps: 228    lr: 0.0001     evaluation reward: 1.52\nepisode: 722   score: 0.0   memory length: 133143   epsilon: 0.9343748800014247    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 723   score: 4.0   memory length: 133434   epsilon: 0.9337987000014372    steps: 291    lr: 0.0001     evaluation reward: 1.54\nepisode: 724   score: 2.0   memory length: 133634   epsilon: 0.9334027000014458    steps: 200    lr: 0.0001     evaluation reward: 1.56\nepisode: 725   score: 0.0   memory length: 133756   epsilon: 0.933161140001451    steps: 122    lr: 0.0001     evaluation reward: 1.56\nepisode: 726   score: 2.0   memory length: 133976   epsilon: 0.9327255400014605    steps: 220    lr: 0.0001     evaluation reward: 1.56\nepisode: 727   score: 0.0   memory length: 134099   epsilon: 0.9324820000014657    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 728   score: 0.0   memory length: 134221   epsilon: 0.932240440001471    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 729   score: 1.0   memory length: 134389   epsilon: 0.9319078000014782    steps: 168    lr: 0.0001     evaluation reward: 1.53\nepisode: 730   score: 2.0   memory length: 134605   epsilon: 0.9314801200014875    steps: 216    lr: 0.0001     evaluation reward: 1.53\nepisode: 731   score: 2.0   memory length: 134821   epsilon: 0.9310524400014968    steps: 216    lr: 0.0001     evaluation reward: 1.5\nepisode: 732   score: 3.0   memory length: 135088   epsilon: 0.9305237800015083    steps: 267    lr: 0.0001     evaluation reward: 1.5\nepisode: 733   score: 0.0   memory length: 135211   epsilon: 0.9302802400015135    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 734   score: 1.0   memory length: 135361   epsilon: 0.92998324000152    steps: 150    lr: 0.0001     evaluation reward: 1.5\nepisode: 735   score: 0.0   memory length: 135484   epsilon: 0.9297397000015253    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 736   score: 2.0   memory length: 135683   epsilon: 0.9293456800015338    steps: 199    lr: 0.0001     evaluation reward: 1.49\nepisode: 737   score: 1.0   memory length: 135834   epsilon: 0.9290467000015403    steps: 151    lr: 0.0001     evaluation reward: 1.47\nepisode: 738   score: 0.0   memory length: 135957   epsilon: 0.9288031600015456    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 739   score: 0.0   memory length: 136080   epsilon: 0.9285596200015509    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 740   score: 0.0   memory length: 136203   epsilon: 0.9283160800015562    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 741   score: 2.0   memory length: 136401   epsilon: 0.9279240400015647    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 742   score: 1.0   memory length: 136570   epsilon: 0.927589420001572    steps: 169    lr: 0.0001     evaluation reward: 1.47\nepisode: 743   score: 2.0   memory length: 136767   epsilon: 0.9271993600015804    steps: 197    lr: 0.0001     evaluation reward: 1.48\nepisode: 744   score: 3.0   memory length: 137018   epsilon: 0.9267023800015912    steps: 251    lr: 0.0001     evaluation reward: 1.51\nepisode: 745   score: 2.0   memory length: 137216   epsilon: 0.9263103400015997    steps: 198    lr: 0.0001     evaluation reward: 1.5\nepisode: 746   score: 1.0   memory length: 137385   epsilon: 0.925975720001607    steps: 169    lr: 0.0001     evaluation reward: 1.51\nepisode: 747   score: 2.0   memory length: 137582   epsilon: 0.9255856600016155    steps: 197    lr: 0.0001     evaluation reward: 1.52\nepisode: 748   score: 0.0   memory length: 137704   epsilon: 0.9253441000016207    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 749   score: 0.0   memory length: 137826   epsilon: 0.925102540001626    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 750   score: 1.0   memory length: 137977   epsilon: 0.9248035600016324    steps: 151    lr: 0.0001     evaluation reward: 1.51\nepisode: 751   score: 3.0   memory length: 138207   epsilon: 0.9243481600016423    steps: 230    lr: 0.0001     evaluation reward: 1.54\nepisode: 752   score: 2.0   memory length: 138405   epsilon: 0.9239561200016508    steps: 198    lr: 0.0001     evaluation reward: 1.56\nepisode: 753   score: 1.0   memory length: 138556   epsilon: 0.9236571400016573    steps: 151    lr: 0.0001     evaluation reward: 1.57\nepisode: 754   score: 3.0   memory length: 138802   epsilon: 0.9231700600016679    steps: 246    lr: 0.0001     evaluation reward: 1.58\nepisode: 755   score: 0.0   memory length: 138924   epsilon: 0.9229285000016731    steps: 122    lr: 0.0001     evaluation reward: 1.57\nepisode: 756   score: 1.0   memory length: 139095   epsilon: 0.9225899200016805    steps: 171    lr: 0.0001     evaluation reward: 1.58\nepisode: 757   score: 3.0   memory length: 139343   epsilon: 0.9220988800016912    steps: 248    lr: 0.0001     evaluation reward: 1.59\nepisode: 758   score: 4.0   memory length: 139642   epsilon: 0.921506860001704    steps: 299    lr: 0.0001     evaluation reward: 1.63\nepisode: 759   score: 0.0   memory length: 139764   epsilon: 0.9212653000017093    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 760   score: 0.0   memory length: 139886   epsilon: 0.9210237400017145    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 761   score: 5.0   memory length: 140249   epsilon: 0.9203050000017301    steps: 363    lr: 0.0001     evaluation reward: 1.65\nepisode: 762   score: 1.0   memory length: 140400   epsilon: 0.9200060200017366    steps: 151    lr: 0.0001     evaluation reward: 1.65\nepisode: 763   score: 2.0   memory length: 140618   epsilon: 0.919574380001746    steps: 218    lr: 0.0001     evaluation reward: 1.65\nepisode: 764   score: 2.0   memory length: 140839   epsilon: 0.9191368000017555    steps: 221    lr: 0.0001     evaluation reward: 1.66\nepisode: 765   score: 5.0   memory length: 141174   epsilon: 0.9184735000017699    steps: 335    lr: 0.0001     evaluation reward: 1.69\nepisode: 766   score: 3.0   memory length: 141401   epsilon: 0.9180240400017796    steps: 227    lr: 0.0001     evaluation reward: 1.7\nepisode: 767   score: 3.0   memory length: 141667   epsilon: 0.917497360001791    steps: 266    lr: 0.0001     evaluation reward: 1.72\nepisode: 768   score: 4.0   memory length: 141946   epsilon: 0.916944940001803    steps: 279    lr: 0.0001     evaluation reward: 1.72\nepisode: 769   score: 1.0   memory length: 142099   epsilon: 0.9166420000018096    steps: 153    lr: 0.0001     evaluation reward: 1.73\nepisode: 770   score: 0.0   memory length: 142222   epsilon: 0.9163984600018149    steps: 123    lr: 0.0001     evaluation reward: 1.7\nepisode: 771   score: 2.0   memory length: 142440   epsilon: 0.9159668200018243    steps: 218    lr: 0.0001     evaluation reward: 1.68\nepisode: 772   score: 2.0   memory length: 142638   epsilon: 0.9155747800018328    steps: 198    lr: 0.0001     evaluation reward: 1.7\nepisode: 773   score: 1.0   memory length: 142808   epsilon: 0.9152381800018401    steps: 170    lr: 0.0001     evaluation reward: 1.68\nepisode: 774   score: 1.0   memory length: 142977   epsilon: 0.9149035600018474    steps: 169    lr: 0.0001     evaluation reward: 1.67\nepisode: 775   score: 1.0   memory length: 143147   epsilon: 0.9145669600018547    steps: 170    lr: 0.0001     evaluation reward: 1.68\nepisode: 776   score: 3.0   memory length: 143358   epsilon: 0.9141491800018637    steps: 211    lr: 0.0001     evaluation reward: 1.69\nepisode: 777   score: 2.0   memory length: 143556   epsilon: 0.9137571400018722    steps: 198    lr: 0.0001     evaluation reward: 1.71\nepisode: 778   score: 4.0   memory length: 143852   epsilon: 0.913171060001885    steps: 296    lr: 0.0001     evaluation reward: 1.71\nepisode: 779   score: 1.0   memory length: 144002   epsilon: 0.9128740600018914    steps: 150    lr: 0.0001     evaluation reward: 1.69\nepisode: 780   score: 0.0   memory length: 144125   epsilon: 0.9126305200018967    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 781   score: 0.0   memory length: 144248   epsilon: 0.912386980001902    steps: 123    lr: 0.0001     evaluation reward: 1.65\nepisode: 782   score: 0.0   memory length: 144370   epsilon: 0.9121454200019072    steps: 122    lr: 0.0001     evaluation reward: 1.65\nepisode: 783   score: 2.0   memory length: 144568   epsilon: 0.9117533800019157    steps: 198    lr: 0.0001     evaluation reward: 1.64\nepisode: 784   score: 4.0   memory length: 144861   epsilon: 0.9111732400019283    steps: 293    lr: 0.0001     evaluation reward: 1.66\nepisode: 785   score: 1.0   memory length: 145030   epsilon: 0.9108386200019356    steps: 169    lr: 0.0001     evaluation reward: 1.66\nepisode: 786   score: 1.0   memory length: 145199   epsilon: 0.9105040000019429    steps: 169    lr: 0.0001     evaluation reward: 1.64\nepisode: 787   score: 3.0   memory length: 145427   epsilon: 0.9100525600019527    steps: 228    lr: 0.0001     evaluation reward: 1.65\nepisode: 788   score: 0.0   memory length: 145550   epsilon: 0.909809020001958    steps: 123    lr: 0.0001     evaluation reward: 1.63\nepisode: 789   score: 0.0   memory length: 145673   epsilon: 0.9095654800019632    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 790   score: 5.0   memory length: 146040   epsilon: 0.908838820001979    steps: 367    lr: 0.0001     evaluation reward: 1.63\nepisode: 791   score: 0.0   memory length: 146162   epsilon: 0.9085972600019843    steps: 122    lr: 0.0001     evaluation reward: 1.63\nepisode: 792   score: 2.0   memory length: 146379   epsilon: 0.9081676000019936    steps: 217    lr: 0.0001     evaluation reward: 1.64\nepisode: 793   score: 9.0   memory length: 146746   epsilon: 0.9074409400020094    steps: 367    lr: 0.0001     evaluation reward: 1.72\nepisode: 794   score: 0.0   memory length: 146869   epsilon: 0.9071974000020147    steps: 123    lr: 0.0001     evaluation reward: 1.7\nepisode: 795   score: 0.0   memory length: 146992   epsilon: 0.9069538600020199    steps: 123    lr: 0.0001     evaluation reward: 1.66\nepisode: 796   score: 3.0   memory length: 147240   epsilon: 0.9064628200020306    steps: 248    lr: 0.0001     evaluation reward: 1.64\nepisode: 797   score: 3.0   memory length: 147508   epsilon: 0.9059321800020421    steps: 268    lr: 0.0001     evaluation reward: 1.67\nepisode: 798   score: 1.0   memory length: 147677   epsilon: 0.9055975600020494    steps: 169    lr: 0.0001     evaluation reward: 1.68\nepisode: 799   score: 0.0   memory length: 147799   epsilon: 0.9053560000020546    steps: 122    lr: 0.0001     evaluation reward: 1.65\nepisode: 800   score: 1.0   memory length: 147950   epsilon: 0.9050570200020611    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 801   score: 2.0   memory length: 148148   epsilon: 0.9046649800020696    steps: 198    lr: 0.0001     evaluation reward: 1.63\nepisode: 802   score: 0.0   memory length: 148271   epsilon: 0.9044214400020749    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 803   score: 2.0   memory length: 148469   epsilon: 0.9040294000020834    steps: 198    lr: 0.0001     evaluation reward: 1.62\nepisode: 804   score: 0.0   memory length: 148592   epsilon: 0.9037858600020887    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 805   score: 1.0   memory length: 148761   epsilon: 0.903451240002096    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 806   score: 0.0   memory length: 148883   epsilon: 0.9032096800021012    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 807   score: 0.0   memory length: 149006   epsilon: 0.9029661400021065    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 808   score: 0.0   memory length: 149128   epsilon: 0.9027245800021118    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 809   score: 1.0   memory length: 149279   epsilon: 0.9024256000021182    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 810   score: 1.0   memory length: 149451   epsilon: 0.9020850400021256    steps: 172    lr: 0.0001     evaluation reward: 1.57\nepisode: 811   score: 2.0   memory length: 149649   epsilon: 0.9016930000021341    steps: 198    lr: 0.0001     evaluation reward: 1.56\nepisode: 812   score: 3.0   memory length: 149874   epsilon: 0.9012475000021438    steps: 225    lr: 0.0001     evaluation reward: 1.57\nepisode: 813   score: 1.0   memory length: 150025   epsilon: 0.9009485200021503    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 814   score: 1.0   memory length: 150176   epsilon: 0.9006495400021568    steps: 151    lr: 0.0001     evaluation reward: 1.55\nepisode: 815   score: 1.0   memory length: 150326   epsilon: 0.9003525400021632    steps: 150    lr: 0.0001     evaluation reward: 1.56\nepisode: 816   score: 0.0   memory length: 150448   epsilon: 0.9001109800021685    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 817   score: 5.0   memory length: 150787   epsilon: 0.8994397600021831    steps: 339    lr: 0.0001     evaluation reward: 1.58\nepisode: 818   score: 2.0   memory length: 150985   epsilon: 0.8990477200021916    steps: 198    lr: 0.0001     evaluation reward: 1.59\nepisode: 819   score: 0.0   memory length: 151107   epsilon: 0.8988061600021968    steps: 122    lr: 0.0001     evaluation reward: 1.57\nepisode: 820   score: 0.0   memory length: 151230   epsilon: 0.8985626200022021    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 821   score: 2.0   memory length: 151447   epsilon: 0.8981329600022114    steps: 217    lr: 0.0001     evaluation reward: 1.53\nepisode: 822   score: 2.0   memory length: 151665   epsilon: 0.8977013200022208    steps: 218    lr: 0.0001     evaluation reward: 1.55\nepisode: 823   score: 0.0   memory length: 151788   epsilon: 0.8974577800022261    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 824   score: 2.0   memory length: 151989   epsilon: 0.8970598000022347    steps: 201    lr: 0.0001     evaluation reward: 1.51\nepisode: 825   score: 2.0   memory length: 152169   epsilon: 0.8967034000022425    steps: 180    lr: 0.0001     evaluation reward: 1.53\nepisode: 826   score: 2.0   memory length: 152367   epsilon: 0.896311360002251    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 827   score: 1.0   memory length: 152536   epsilon: 0.8959767400022582    steps: 169    lr: 0.0001     evaluation reward: 1.54\nepisode: 828   score: 1.0   memory length: 152705   epsilon: 0.8956421200022655    steps: 169    lr: 0.0001     evaluation reward: 1.55\nepisode: 829   score: 2.0   memory length: 152904   epsilon: 0.8952481000022741    steps: 199    lr: 0.0001     evaluation reward: 1.56\nepisode: 830   score: 2.0   memory length: 153120   epsilon: 0.8948204200022833    steps: 216    lr: 0.0001     evaluation reward: 1.56\nepisode: 831   score: 3.0   memory length: 153366   epsilon: 0.8943333400022939    steps: 246    lr: 0.0001     evaluation reward: 1.57\nepisode: 832   score: 3.0   memory length: 153594   epsilon: 0.8938819000023037    steps: 228    lr: 0.0001     evaluation reward: 1.57\nepisode: 833   score: 0.0   memory length: 153716   epsilon: 0.893640340002309    steps: 122    lr: 0.0001     evaluation reward: 1.57\nepisode: 834   score: 0.0   memory length: 153838   epsilon: 0.8933987800023142    steps: 122    lr: 0.0001     evaluation reward: 1.56\nepisode: 835   score: 3.0   memory length: 154084   epsilon: 0.8929117000023248    steps: 246    lr: 0.0001     evaluation reward: 1.59\nepisode: 836   score: 2.0   memory length: 154282   epsilon: 0.8925196600023333    steps: 198    lr: 0.0001     evaluation reward: 1.59\nepisode: 837   score: 0.0   memory length: 154404   epsilon: 0.8922781000023385    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 838   score: 0.0   memory length: 154527   epsilon: 0.8920345600023438    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 839   score: 0.0   memory length: 154650   epsilon: 0.8917910200023491    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 840   score: 2.0   memory length: 154848   epsilon: 0.8913989800023576    steps: 198    lr: 0.0001     evaluation reward: 1.6\nepisode: 841   score: 0.0   memory length: 154970   epsilon: 0.8911574200023629    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 842   score: 1.0   memory length: 155121   epsilon: 0.8908584400023694    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 843   score: 2.0   memory length: 155300   epsilon: 0.890504020002377    steps: 179    lr: 0.0001     evaluation reward: 1.58\nepisode: 844   score: 0.0   memory length: 155423   epsilon: 0.8902604800023823    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 845   score: 2.0   memory length: 155641   epsilon: 0.8898288400023917    steps: 218    lr: 0.0001     evaluation reward: 1.55\nepisode: 846   score: 3.0   memory length: 155870   epsilon: 0.8893754200024016    steps: 229    lr: 0.0001     evaluation reward: 1.57\nepisode: 847   score: 1.0   memory length: 156041   epsilon: 0.8890368400024089    steps: 171    lr: 0.0001     evaluation reward: 1.56\nepisode: 848   score: 1.0   memory length: 156211   epsilon: 0.8887002400024162    steps: 170    lr: 0.0001     evaluation reward: 1.57\nepisode: 849   score: 1.0   memory length: 156361   epsilon: 0.8884032400024227    steps: 150    lr: 0.0001     evaluation reward: 1.58\nepisode: 850   score: 3.0   memory length: 156608   epsilon: 0.8879141800024333    steps: 247    lr: 0.0001     evaluation reward: 1.6\nepisode: 851   score: 1.0   memory length: 156758   epsilon: 0.8876171800024397    steps: 150    lr: 0.0001     evaluation reward: 1.58\nepisode: 852   score: 1.0   memory length: 156926   epsilon: 0.8872845400024469    steps: 168    lr: 0.0001     evaluation reward: 1.57\nepisode: 853   score: 6.0   memory length: 157296   epsilon: 0.8865519400024628    steps: 370    lr: 0.0001     evaluation reward: 1.62\nepisode: 854   score: 0.0   memory length: 157419   epsilon: 0.8863084000024681    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 855   score: 3.0   memory length: 157665   epsilon: 0.8858213200024787    steps: 246    lr: 0.0001     evaluation reward: 1.62\nepisode: 856   score: 2.0   memory length: 157862   epsilon: 0.8854312600024872    steps: 197    lr: 0.0001     evaluation reward: 1.63\nepisode: 857   score: 1.0   memory length: 158013   epsilon: 0.8851322800024937    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 858   score: 1.0   memory length: 158181   epsilon: 0.8847996400025009    steps: 168    lr: 0.0001     evaluation reward: 1.58\nepisode: 859   score: 3.0   memory length: 158406   epsilon: 0.8843541400025106    steps: 225    lr: 0.0001     evaluation reward: 1.61\nepisode: 860   score: 1.0   memory length: 158578   epsilon: 0.884013580002518    steps: 172    lr: 0.0001     evaluation reward: 1.62\nepisode: 861   score: 2.0   memory length: 158795   epsilon: 0.8835839200025273    steps: 217    lr: 0.0001     evaluation reward: 1.59\nepisode: 862   score: 2.0   memory length: 158992   epsilon: 0.8831938600025357    steps: 197    lr: 0.0001     evaluation reward: 1.6\nepisode: 863   score: 1.0   memory length: 159161   epsilon: 0.882859240002543    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 864   score: 2.0   memory length: 159379   epsilon: 0.8824276000025524    steps: 218    lr: 0.0001     evaluation reward: 1.59\nepisode: 865   score: 6.0   memory length: 159632   epsilon: 0.8819266600025633    steps: 253    lr: 0.0001     evaluation reward: 1.6\nepisode: 866   score: 1.0   memory length: 159782   epsilon: 0.8816296600025697    steps: 150    lr: 0.0001     evaluation reward: 1.58\nepisode: 867   score: 2.0   memory length: 160003   epsilon: 0.8811920800025792    steps: 221    lr: 0.0001     evaluation reward: 1.57\nepisode: 868   score: 0.0   memory length: 160126   epsilon: 0.8809485400025845    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 869   score: 1.0   memory length: 160298   epsilon: 0.8806079800025919    steps: 172    lr: 0.0001     evaluation reward: 1.53\nepisode: 870   score: 2.0   memory length: 160516   epsilon: 0.8801763400026013    steps: 218    lr: 0.0001     evaluation reward: 1.55\nepisode: 871   score: 3.0   memory length: 160763   epsilon: 0.8796872800026119    steps: 247    lr: 0.0001     evaluation reward: 1.56\nepisode: 872   score: 4.0   memory length: 161028   epsilon: 0.8791625800026233    steps: 265    lr: 0.0001     evaluation reward: 1.58\nepisode: 873   score: 0.0   memory length: 161150   epsilon: 0.8789210200026285    steps: 122    lr: 0.0001     evaluation reward: 1.57\nepisode: 874   score: 0.0   memory length: 161272   epsilon: 0.8786794600026337    steps: 122    lr: 0.0001     evaluation reward: 1.56\nepisode: 875   score: 0.0   memory length: 161395   epsilon: 0.878435920002639    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 876   score: 1.0   memory length: 161564   epsilon: 0.8781013000026463    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 877   score: 0.0   memory length: 161687   epsilon: 0.8778577600026516    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 878   score: 2.0   memory length: 161904   epsilon: 0.8774281000026609    steps: 217    lr: 0.0001     evaluation reward: 1.49\nepisode: 879   score: 3.0   memory length: 162152   epsilon: 0.8769370600026716    steps: 248    lr: 0.0001     evaluation reward: 1.51\nepisode: 880   score: 2.0   memory length: 162350   epsilon: 0.8765450200026801    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 881   score: 2.0   memory length: 162570   epsilon: 0.8761094200026895    steps: 220    lr: 0.0001     evaluation reward: 1.55\nepisode: 882   score: 0.0   memory length: 162693   epsilon: 0.8758658800026948    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 883   score: 1.0   memory length: 162863   epsilon: 0.8755292800027021    steps: 170    lr: 0.0001     evaluation reward: 1.54\nepisode: 884   score: 2.0   memory length: 163061   epsilon: 0.8751372400027106    steps: 198    lr: 0.0001     evaluation reward: 1.52\nepisode: 885   score: 3.0   memory length: 163289   epsilon: 0.8746858000027204    steps: 228    lr: 0.0001     evaluation reward: 1.54\nepisode: 886   score: 0.0   memory length: 163412   epsilon: 0.8744422600027257    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 887   score: 2.0   memory length: 163591   epsilon: 0.8740878400027334    steps: 179    lr: 0.0001     evaluation reward: 1.52\nepisode: 888   score: 3.0   memory length: 163857   epsilon: 0.8735611600027449    steps: 266    lr: 0.0001     evaluation reward: 1.55\nepisode: 889   score: 0.0   memory length: 163980   epsilon: 0.8733176200027502    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 890   score: 3.0   memory length: 164225   epsilon: 0.8728325200027607    steps: 245    lr: 0.0001     evaluation reward: 1.53\nepisode: 891   score: 1.0   memory length: 164396   epsilon: 0.872493940002768    steps: 171    lr: 0.0001     evaluation reward: 1.54\nepisode: 892   score: 2.0   memory length: 164593   epsilon: 0.8721038800027765    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 893   score: 2.0   memory length: 164811   epsilon: 0.8716722400027859    steps: 218    lr: 0.0001     evaluation reward: 1.47\nepisode: 894   score: 6.0   memory length: 165202   epsilon: 0.8708980600028027    steps: 391    lr: 0.0001     evaluation reward: 1.53\nepisode: 895   score: 1.0   memory length: 165371   epsilon: 0.8705634400028099    steps: 169    lr: 0.0001     evaluation reward: 1.54\nepisode: 896   score: 1.0   memory length: 165541   epsilon: 0.8702268400028172    steps: 170    lr: 0.0001     evaluation reward: 1.52\nepisode: 897   score: 2.0   memory length: 165739   epsilon: 0.8698348000028258    steps: 198    lr: 0.0001     evaluation reward: 1.51\nepisode: 898   score: 6.0   memory length: 166132   epsilon: 0.8690566600028427    steps: 393    lr: 0.0001     evaluation reward: 1.56\nepisode: 899   score: 0.0   memory length: 166255   epsilon: 0.8688131200028479    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 900   score: 1.0   memory length: 166406   epsilon: 0.8685141400028544    steps: 151    lr: 0.0001     evaluation reward: 1.56\nepisode: 901   score: 0.0   memory length: 166529   epsilon: 0.8682706000028597    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 902   score: 2.0   memory length: 166728   epsilon: 0.8678765800028683    steps: 199    lr: 0.0001     evaluation reward: 1.56\nepisode: 903   score: 2.0   memory length: 166949   epsilon: 0.8674390000028778    steps: 221    lr: 0.0001     evaluation reward: 1.56\nepisode: 904   score: 2.0   memory length: 167147   epsilon: 0.8670469600028863    steps: 198    lr: 0.0001     evaluation reward: 1.58\nepisode: 905   score: 3.0   memory length: 167393   epsilon: 0.8665598800028969    steps: 246    lr: 0.0001     evaluation reward: 1.6\nepisode: 906   score: 2.0   memory length: 167591   epsilon: 0.8661678400029054    steps: 198    lr: 0.0001     evaluation reward: 1.62\nepisode: 907   score: 3.0   memory length: 167817   epsilon: 0.8657203600029151    steps: 226    lr: 0.0001     evaluation reward: 1.65\nepisode: 908   score: 2.0   memory length: 168015   epsilon: 0.8653283200029236    steps: 198    lr: 0.0001     evaluation reward: 1.67\nepisode: 909   score: 0.0   memory length: 168138   epsilon: 0.8650847800029289    steps: 123    lr: 0.0001     evaluation reward: 1.66\nepisode: 910   score: 2.0   memory length: 168320   epsilon: 0.8647244200029367    steps: 182    lr: 0.0001     evaluation reward: 1.67\nepisode: 911   score: 2.0   memory length: 168538   epsilon: 0.8642927800029461    steps: 218    lr: 0.0001     evaluation reward: 1.67\nepisode: 912   score: 2.0   memory length: 168736   epsilon: 0.8639007400029546    steps: 198    lr: 0.0001     evaluation reward: 1.66\nepisode: 913   score: 4.0   memory length: 169011   epsilon: 0.8633562400029664    steps: 275    lr: 0.0001     evaluation reward: 1.69\nepisode: 914   score: 2.0   memory length: 169209   epsilon: 0.8629642000029749    steps: 198    lr: 0.0001     evaluation reward: 1.7\nepisode: 915   score: 4.0   memory length: 169509   epsilon: 0.8623702000029878    steps: 300    lr: 0.0001     evaluation reward: 1.73\nepisode: 916   score: 3.0   memory length: 169756   epsilon: 0.8618811400029984    steps: 247    lr: 0.0001     evaluation reward: 1.76\nepisode: 917   score: 0.0   memory length: 169879   epsilon: 0.8616376000030037    steps: 123    lr: 0.0001     evaluation reward: 1.71\nepisode: 918   score: 1.0   memory length: 170047   epsilon: 0.8613049600030109    steps: 168    lr: 0.0001     evaluation reward: 1.7\nepisode: 919   score: 1.0   memory length: 170217   epsilon: 0.8609683600030182    steps: 170    lr: 0.0001     evaluation reward: 1.71\nepisode: 920   score: 2.0   memory length: 170415   epsilon: 0.8605763200030268    steps: 198    lr: 0.0001     evaluation reward: 1.73\nepisode: 921   score: 1.0   memory length: 170566   epsilon: 0.8602773400030332    steps: 151    lr: 0.0001     evaluation reward: 1.72\nepisode: 922   score: 0.0   memory length: 170689   epsilon: 0.8600338000030385    steps: 123    lr: 0.0001     evaluation reward: 1.7\nepisode: 923   score: 1.0   memory length: 170859   epsilon: 0.8596972000030458    steps: 170    lr: 0.0001     evaluation reward: 1.71\nepisode: 924   score: 2.0   memory length: 171056   epsilon: 0.8593071400030543    steps: 197    lr: 0.0001     evaluation reward: 1.71\nepisode: 925   score: 2.0   memory length: 171254   epsilon: 0.8589151000030628    steps: 198    lr: 0.0001     evaluation reward: 1.71\nepisode: 926   score: 2.0   memory length: 171451   epsilon: 0.8585250400030713    steps: 197    lr: 0.0001     evaluation reward: 1.71\nepisode: 927   score: 1.0   memory length: 171620   epsilon: 0.8581904200030785    steps: 169    lr: 0.0001     evaluation reward: 1.71\nepisode: 928   score: 2.0   memory length: 171818   epsilon: 0.8577983800030871    steps: 198    lr: 0.0001     evaluation reward: 1.72\nepisode: 929   score: 2.0   memory length: 172000   epsilon: 0.8574380200030949    steps: 182    lr: 0.0001     evaluation reward: 1.72\nepisode: 930   score: 3.0   memory length: 172248   epsilon: 0.8569469800031055    steps: 248    lr: 0.0001     evaluation reward: 1.73\nepisode: 931   score: 0.0   memory length: 172371   epsilon: 0.8567034400031108    steps: 123    lr: 0.0001     evaluation reward: 1.7\nepisode: 932   score: 0.0   memory length: 172493   epsilon: 0.8564618800031161    steps: 122    lr: 0.0001     evaluation reward: 1.67\nepisode: 933   score: 1.0   memory length: 172663   epsilon: 0.8561252800031234    steps: 170    lr: 0.0001     evaluation reward: 1.68\nepisode: 934   score: 3.0   memory length: 172909   epsilon: 0.855638200003134    steps: 246    lr: 0.0001     evaluation reward: 1.71\nepisode: 935   score: 4.0   memory length: 173183   epsilon: 0.8550956800031457    steps: 274    lr: 0.0001     evaluation reward: 1.72\nepisode: 936   score: 3.0   memory length: 173409   epsilon: 0.8546482000031554    steps: 226    lr: 0.0001     evaluation reward: 1.73\nepisode: 937   score: 1.0   memory length: 173560   epsilon: 0.8543492200031619    steps: 151    lr: 0.0001     evaluation reward: 1.74\nepisode: 938   score: 1.0   memory length: 173711   epsilon: 0.8540502400031684    steps: 151    lr: 0.0001     evaluation reward: 1.75\nepisode: 939   score: 4.0   memory length: 173986   epsilon: 0.8535057400031802    steps: 275    lr: 0.0001     evaluation reward: 1.79\nepisode: 940   score: 2.0   memory length: 174183   epsilon: 0.8531156800031887    steps: 197    lr: 0.0001     evaluation reward: 1.79\nepisode: 941   score: 2.0   memory length: 174399   epsilon: 0.852688000003198    steps: 216    lr: 0.0001     evaluation reward: 1.81\nepisode: 942   score: 0.0   memory length: 174522   epsilon: 0.8524444600032033    steps: 123    lr: 0.0001     evaluation reward: 1.8\nepisode: 943   score: 3.0   memory length: 174769   epsilon: 0.8519554000032139    steps: 247    lr: 0.0001     evaluation reward: 1.81\nepisode: 944   score: 2.0   memory length: 174967   epsilon: 0.8515633600032224    steps: 198    lr: 0.0001     evaluation reward: 1.83\nepisode: 945   score: 2.0   memory length: 175165   epsilon: 0.8511713200032309    steps: 198    lr: 0.0001     evaluation reward: 1.83\nepisode: 946   score: 3.0   memory length: 175430   epsilon: 0.8506466200032423    steps: 265    lr: 0.0001     evaluation reward: 1.83\nepisode: 947   score: 3.0   memory length: 175656   epsilon: 0.850199140003252    steps: 226    lr: 0.0001     evaluation reward: 1.85\nepisode: 948   score: 1.0   memory length: 175825   epsilon: 0.8498645200032593    steps: 169    lr: 0.0001     evaluation reward: 1.85\nepisode: 949   score: 2.0   memory length: 176005   epsilon: 0.849508120003267    steps: 180    lr: 0.0001     evaluation reward: 1.86\nepisode: 950   score: 0.0   memory length: 176128   epsilon: 0.8492645800032723    steps: 123    lr: 0.0001     evaluation reward: 1.83\nepisode: 951   score: 2.0   memory length: 176326   epsilon: 0.8488725400032808    steps: 198    lr: 0.0001     evaluation reward: 1.84\nepisode: 952   score: 2.0   memory length: 176524   epsilon: 0.8484805000032893    steps: 198    lr: 0.0001     evaluation reward: 1.85\nepisode: 953   score: 2.0   memory length: 176725   epsilon: 0.848082520003298    steps: 201    lr: 0.0001     evaluation reward: 1.81\nepisode: 954   score: 0.0   memory length: 176848   epsilon: 0.8478389800033033    steps: 123    lr: 0.0001     evaluation reward: 1.81\nepisode: 955   score: 2.0   memory length: 177048   epsilon: 0.8474429800033119    steps: 200    lr: 0.0001     evaluation reward: 1.8\nepisode: 956   score: 1.0   memory length: 177219   epsilon: 0.8471044000033192    steps: 171    lr: 0.0001     evaluation reward: 1.79\nepisode: 957   score: 5.0   memory length: 177564   epsilon: 0.846421300003334    steps: 345    lr: 0.0001     evaluation reward: 1.83\nepisode: 958   score: 2.0   memory length: 177746   epsilon: 0.8460609400033419    steps: 182    lr: 0.0001     evaluation reward: 1.84\nepisode: 959   score: 4.0   memory length: 178042   epsilon: 0.8454748600033546    steps: 296    lr: 0.0001     evaluation reward: 1.85\nepisode: 960   score: 2.0   memory length: 178242   epsilon: 0.8450788600033632    steps: 200    lr: 0.0001     evaluation reward: 1.86\nepisode: 961   score: 2.0   memory length: 178442   epsilon: 0.8446828600033718    steps: 200    lr: 0.0001     evaluation reward: 1.86\nepisode: 962   score: 2.0   memory length: 178624   epsilon: 0.8443225000033796    steps: 182    lr: 0.0001     evaluation reward: 1.86\nepisode: 963   score: 3.0   memory length: 178849   epsilon: 0.8438770000033893    steps: 225    lr: 0.0001     evaluation reward: 1.88\nepisode: 964   score: 2.0   memory length: 179031   epsilon: 0.8435166400033971    steps: 182    lr: 0.0001     evaluation reward: 1.88\nepisode: 965   score: 2.0   memory length: 179231   epsilon: 0.8431206400034057    steps: 200    lr: 0.0001     evaluation reward: 1.84\nepisode: 966   score: 3.0   memory length: 179477   epsilon: 0.8426335600034163    steps: 246    lr: 0.0001     evaluation reward: 1.86\nepisode: 967   score: 2.0   memory length: 179697   epsilon: 0.8421979600034257    steps: 220    lr: 0.0001     evaluation reward: 1.86\nepisode: 968   score: 3.0   memory length: 179944   epsilon: 0.8417089000034363    steps: 247    lr: 0.0001     evaluation reward: 1.89\nepisode: 969   score: 1.0   memory length: 180095   epsilon: 0.8414099200034428    steps: 151    lr: 0.0001     evaluation reward: 1.89\nepisode: 970   score: 3.0   memory length: 180342   epsilon: 0.8409208600034535    steps: 247    lr: 0.0001     evaluation reward: 1.9\nepisode: 971   score: 2.0   memory length: 180561   epsilon: 0.8404872400034629    steps: 219    lr: 0.0001     evaluation reward: 1.89\nepisode: 972   score: 3.0   memory length: 180789   epsilon: 0.8400358000034727    steps: 228    lr: 0.0001     evaluation reward: 1.88\nepisode: 973   score: 3.0   memory length: 181017   epsilon: 0.8395843600034825    steps: 228    lr: 0.0001     evaluation reward: 1.91\nepisode: 974   score: 3.0   memory length: 181281   epsilon: 0.8390616400034938    steps: 264    lr: 0.0001     evaluation reward: 1.94\nepisode: 975   score: 4.0   memory length: 181577   epsilon: 0.8384755600035065    steps: 296    lr: 0.0001     evaluation reward: 1.98\nepisode: 976   score: 3.0   memory length: 181823   epsilon: 0.8379884800035171    steps: 246    lr: 0.0001     evaluation reward: 2.0\nepisode: 977   score: 1.0   memory length: 181973   epsilon: 0.8376914800035236    steps: 150    lr: 0.0001     evaluation reward: 2.01\nepisode: 978   score: 1.0   memory length: 182144   epsilon: 0.8373529000035309    steps: 171    lr: 0.0001     evaluation reward: 2.0\nepisode: 979   score: 2.0   memory length: 182325   epsilon: 0.8369945200035387    steps: 181    lr: 0.0001     evaluation reward: 1.99\nepisode: 980   score: 1.0   memory length: 182496   epsilon: 0.836655940003546    steps: 171    lr: 0.0001     evaluation reward: 1.98\nepisode: 981   score: 3.0   memory length: 182723   epsilon: 0.8362064800035558    steps: 227    lr: 0.0001     evaluation reward: 1.99\nepisode: 982   score: 1.0   memory length: 182893   epsilon: 0.8358698800035631    steps: 170    lr: 0.0001     evaluation reward: 2.0\nepisode: 983   score: 3.0   memory length: 183158   epsilon: 0.8353451800035745    steps: 265    lr: 0.0001     evaluation reward: 2.02\nepisode: 984   score: 1.0   memory length: 183309   epsilon: 0.835046200003581    steps: 151    lr: 0.0001     evaluation reward: 2.01\nepisode: 985   score: 3.0   memory length: 183537   epsilon: 0.8345947600035908    steps: 228    lr: 0.0001     evaluation reward: 2.01\nepisode: 986   score: 0.0   memory length: 183660   epsilon: 0.8343512200035961    steps: 123    lr: 0.0001     evaluation reward: 2.01\nepisode: 987   score: 2.0   memory length: 183844   epsilon: 0.833986900003604    steps: 184    lr: 0.0001     evaluation reward: 2.01\nepisode: 988   score: 2.0   memory length: 184044   epsilon: 0.8335909000036126    steps: 200    lr: 0.0001     evaluation reward: 2.0\nepisode: 989   score: 5.0   memory length: 184367   epsilon: 0.8329513600036265    steps: 323    lr: 0.0001     evaluation reward: 2.05\nepisode: 990   score: 3.0   memory length: 184595   epsilon: 0.8324999200036363    steps: 228    lr: 0.0001     evaluation reward: 2.05\nepisode: 991   score: 1.0   memory length: 184747   epsilon: 0.8321989600036428    steps: 152    lr: 0.0001     evaluation reward: 2.05\nepisode: 992   score: 2.0   memory length: 184945   epsilon: 0.8318069200036513    steps: 198    lr: 0.0001     evaluation reward: 2.05\nepisode: 993   score: 1.0   memory length: 185096   epsilon: 0.8315079400036578    steps: 151    lr: 0.0001     evaluation reward: 2.04\nepisode: 994   score: 0.0   memory length: 185219   epsilon: 0.8312644000036631    steps: 123    lr: 0.0001     evaluation reward: 1.98\nepisode: 995   score: 3.0   memory length: 185466   epsilon: 0.8307753400036737    steps: 247    lr: 0.0001     evaluation reward: 2.0\nepisode: 996   score: 1.0   memory length: 185617   epsilon: 0.8304763600036802    steps: 151    lr: 0.0001     evaluation reward: 2.0\nepisode: 997   score: 6.0   memory length: 185991   epsilon: 0.8297358400036963    steps: 374    lr: 0.0001     evaluation reward: 2.04\nepisode: 998   score: 1.0   memory length: 186163   epsilon: 0.8293952800037037    steps: 172    lr: 0.0001     evaluation reward: 1.99\nepisode: 999   score: 3.0   memory length: 186389   epsilon: 0.8289478000037134    steps: 226    lr: 0.0001     evaluation reward: 2.02\nepisode: 1000   score: 1.0   memory length: 186540   epsilon: 0.8286488200037199    steps: 151    lr: 0.0001     evaluation reward: 2.02\nepisode: 1001   score: 3.0   memory length: 186749   epsilon: 0.8282350000037288    steps: 209    lr: 0.0001     evaluation reward: 2.05\nepisode: 1002   score: 1.0   memory length: 186900   epsilon: 0.8279360200037353    steps: 151    lr: 0.0001     evaluation reward: 2.04\nepisode: 1003   score: 2.0   memory length: 187097   epsilon: 0.8275459600037438    steps: 197    lr: 0.0001     evaluation reward: 2.04\nepisode: 1004   score: 2.0   memory length: 187316   epsilon: 0.8271123400037532    steps: 219    lr: 0.0001     evaluation reward: 2.04\nepisode: 1005   score: 4.0   memory length: 187614   epsilon: 0.826522300003766    steps: 298    lr: 0.0001     evaluation reward: 2.05\nepisode: 1006   score: 2.0   memory length: 187836   epsilon: 0.8260827400037756    steps: 222    lr: 0.0001     evaluation reward: 2.05\nepisode: 1007   score: 2.0   memory length: 188052   epsilon: 0.8256550600037849    steps: 216    lr: 0.0001     evaluation reward: 2.04\nepisode: 1008   score: 2.0   memory length: 188250   epsilon: 0.8252630200037934    steps: 198    lr: 0.0001     evaluation reward: 2.04\nepisode: 1009   score: 2.0   memory length: 188447   epsilon: 0.8248729600038018    steps: 197    lr: 0.0001     evaluation reward: 2.06\nepisode: 1010   score: 2.0   memory length: 188662   epsilon: 0.8244472600038111    steps: 215    lr: 0.0001     evaluation reward: 2.06\nepisode: 1011   score: 3.0   memory length: 188888   epsilon: 0.8239997800038208    steps: 226    lr: 0.0001     evaluation reward: 2.07\nepisode: 1012   score: 3.0   memory length: 189155   epsilon: 0.8234711200038323    steps: 267    lr: 0.0001     evaluation reward: 2.08\nepisode: 1013   score: 0.0   memory length: 189278   epsilon: 0.8232275800038376    steps: 123    lr: 0.0001     evaluation reward: 2.04\nepisode: 1014   score: 1.0   memory length: 189429   epsilon: 0.822928600003844    steps: 151    lr: 0.0001     evaluation reward: 2.03\nepisode: 1015   score: 1.0   memory length: 189598   epsilon: 0.8225939800038513    steps: 169    lr: 0.0001     evaluation reward: 2.0\nepisode: 1016   score: 2.0   memory length: 189798   epsilon: 0.8221979800038599    steps: 200    lr: 0.0001     evaluation reward: 1.99\nepisode: 1017   score: 2.0   memory length: 190018   epsilon: 0.8217623800038694    steps: 220    lr: 0.0001     evaluation reward: 2.01\nepisode: 1018   score: 2.0   memory length: 190216   epsilon: 0.8213703400038779    steps: 198    lr: 0.0001     evaluation reward: 2.02\nepisode: 1019   score: 1.0   memory length: 190367   epsilon: 0.8210713600038844    steps: 151    lr: 0.0001     evaluation reward: 2.02\nepisode: 1020   score: 2.0   memory length: 190546   epsilon: 0.8207169400038921    steps: 179    lr: 0.0001     evaluation reward: 2.02\nepisode: 1021   score: 2.0   memory length: 190744   epsilon: 0.8203249000039006    steps: 198    lr: 0.0001     evaluation reward: 2.03\nepisode: 1022   score: 1.0   memory length: 190913   epsilon: 0.8199902800039078    steps: 169    lr: 0.0001     evaluation reward: 2.04\nepisode: 1023   score: 2.0   memory length: 191113   epsilon: 0.8195942800039164    steps: 200    lr: 0.0001     evaluation reward: 2.05\nepisode: 1024   score: 2.0   memory length: 191311   epsilon: 0.8192022400039249    steps: 198    lr: 0.0001     evaluation reward: 2.05\nepisode: 1025   score: 1.0   memory length: 191480   epsilon: 0.8188676200039322    steps: 169    lr: 0.0001     evaluation reward: 2.04\nepisode: 1026   score: 4.0   memory length: 191776   epsilon: 0.8182815400039449    steps: 296    lr: 0.0001     evaluation reward: 2.06\nepisode: 1027   score: 2.0   memory length: 191973   epsilon: 0.8178914800039534    steps: 197    lr: 0.0001     evaluation reward: 2.07\nepisode: 1028   score: 2.0   memory length: 192195   epsilon: 0.8174519200039629    steps: 222    lr: 0.0001     evaluation reward: 2.07\nepisode: 1029   score: 8.0   memory length: 192516   epsilon: 0.8168163400039767    steps: 321    lr: 0.0001     evaluation reward: 2.13\nepisode: 1030   score: 2.0   memory length: 192717   epsilon: 0.8164183600039854    steps: 201    lr: 0.0001     evaluation reward: 2.12\nepisode: 1031   score: 1.0   memory length: 192868   epsilon: 0.8161193800039919    steps: 151    lr: 0.0001     evaluation reward: 2.13\nepisode: 1032   score: 3.0   memory length: 193135   epsilon: 0.8155907200040033    steps: 267    lr: 0.0001     evaluation reward: 2.16\nepisode: 1033   score: 5.0   memory length: 193438   epsilon: 0.8149907800040164    steps: 303    lr: 0.0001     evaluation reward: 2.2\nepisode: 1034   score: 3.0   memory length: 193687   epsilon: 0.8144977600040271    steps: 249    lr: 0.0001     evaluation reward: 2.2\nepisode: 1035   score: 7.0   memory length: 193986   epsilon: 0.8139057400040399    steps: 299    lr: 0.0001     evaluation reward: 2.23\nepisode: 1036   score: 1.0   memory length: 194137   epsilon: 0.8136067600040464    steps: 151    lr: 0.0001     evaluation reward: 2.21\nepisode: 1037   score: 5.0   memory length: 194460   epsilon: 0.8129672200040603    steps: 323    lr: 0.0001     evaluation reward: 2.25\nepisode: 1038   score: 0.0   memory length: 194583   epsilon: 0.8127236800040656    steps: 123    lr: 0.0001     evaluation reward: 2.24\nepisode: 1039   score: 3.0   memory length: 194809   epsilon: 0.8122762000040753    steps: 226    lr: 0.0001     evaluation reward: 2.23\nepisode: 1040   score: 1.0   memory length: 194977   epsilon: 0.8119435600040825    steps: 168    lr: 0.0001     evaluation reward: 2.22\nepisode: 1041   score: 2.0   memory length: 195177   epsilon: 0.8115475600040911    steps: 200    lr: 0.0001     evaluation reward: 2.22\nepisode: 1042   score: 1.0   memory length: 195347   epsilon: 0.8112109600040984    steps: 170    lr: 0.0001     evaluation reward: 2.23\nepisode: 1043   score: 3.0   memory length: 195594   epsilon: 0.810721900004109    steps: 247    lr: 0.0001     evaluation reward: 2.23\nepisode: 1044   score: 1.0   memory length: 195763   epsilon: 0.8103872800041163    steps: 169    lr: 0.0001     evaluation reward: 2.22\nepisode: 1045   score: 3.0   memory length: 195991   epsilon: 0.8099358400041261    steps: 228    lr: 0.0001     evaluation reward: 2.23\nepisode: 1046   score: 0.0   memory length: 196114   epsilon: 0.8096923000041314    steps: 123    lr: 0.0001     evaluation reward: 2.2\nepisode: 1047   score: 2.0   memory length: 196312   epsilon: 0.8093002600041399    steps: 198    lr: 0.0001     evaluation reward: 2.19\nepisode: 1048   score: 4.0   memory length: 196627   epsilon: 0.8086765600041534    steps: 315    lr: 0.0001     evaluation reward: 2.22\nepisode: 1049   score: 2.0   memory length: 196830   epsilon: 0.8082746200041622    steps: 203    lr: 0.0001     evaluation reward: 2.22\nepisode: 1050   score: 1.0   memory length: 196981   epsilon: 0.8079756400041687    steps: 151    lr: 0.0001     evaluation reward: 2.23\nepisode: 1051   score: 4.0   memory length: 197257   epsilon: 0.8074291600041805    steps: 276    lr: 0.0001     evaluation reward: 2.25\nepisode: 1052   score: 8.0   memory length: 197714   epsilon: 0.8065243000042002    steps: 457    lr: 0.0001     evaluation reward: 2.31\nepisode: 1053   score: 2.0   memory length: 197912   epsilon: 0.8061322600042087    steps: 198    lr: 0.0001     evaluation reward: 2.31\nepisode: 1054   score: 3.0   memory length: 198138   epsilon: 0.8056847800042184    steps: 226    lr: 0.0001     evaluation reward: 2.34\nepisode: 1055   score: 2.0   memory length: 198356   epsilon: 0.8052531400042278    steps: 218    lr: 0.0001     evaluation reward: 2.34\nepisode: 1056   score: 1.0   memory length: 198525   epsilon: 0.804918520004235    steps: 169    lr: 0.0001     evaluation reward: 2.34\nepisode: 1057   score: 1.0   memory length: 198694   epsilon: 0.8045839000042423    steps: 169    lr: 0.0001     evaluation reward: 2.3\nepisode: 1058   score: 2.0   memory length: 198892   epsilon: 0.8041918600042508    steps: 198    lr: 0.0001     evaluation reward: 2.3\nepisode: 1059   score: 0.0   memory length: 199015   epsilon: 0.8039483200042561    steps: 123    lr: 0.0001     evaluation reward: 2.26\nepisode: 1060   score: 1.0   memory length: 199166   epsilon: 0.8036493400042626    steps: 151    lr: 0.0001     evaluation reward: 2.25\nepisode: 1061   score: 0.0   memory length: 199289   epsilon: 0.8034058000042679    steps: 123    lr: 0.0001     evaluation reward: 2.23\nepisode: 1062   score: 1.0   memory length: 199439   epsilon: 0.8031088000042743    steps: 150    lr: 0.0001     evaluation reward: 2.22\nepisode: 1063   score: 3.0   memory length: 199664   epsilon: 0.802663300004284    steps: 225    lr: 0.0001     evaluation reward: 2.22\nepisode: 1064   score: 2.0   memory length: 199862   epsilon: 0.8022712600042925    steps: 198    lr: 0.0001     evaluation reward: 2.22\nepisode: 1065   score: 2.0   memory length: 200041   epsilon: 0.8019168400043002    steps: 179    lr: 4e-05     evaluation reward: 2.22\nepisode: 1066   score: 1.0   memory length: 200192   epsilon: 0.8016178600043067    steps: 151    lr: 4e-05     evaluation reward: 2.2\nepisode: 1067   score: 1.0   memory length: 200342   epsilon: 0.8013208600043131    steps: 150    lr: 4e-05     evaluation reward: 2.19\nepisode: 1068   score: 2.0   memory length: 200542   epsilon: 0.8009248600043217    steps: 200    lr: 4e-05     evaluation reward: 2.18\nepisode: 1069   score: 1.0   memory length: 200693   epsilon: 0.8006258800043282    steps: 151    lr: 4e-05     evaluation reward: 2.18\nepisode: 1070   score: 2.0   memory length: 200891   epsilon: 0.8002338400043367    steps: 198    lr: 4e-05     evaluation reward: 2.17\nepisode: 1071   score: 2.0   memory length: 201091   epsilon: 0.7998378400043453    steps: 200    lr: 4e-05     evaluation reward: 2.17\nepisode: 1072   score: 3.0   memory length: 201317   epsilon: 0.799390360004355    steps: 226    lr: 4e-05     evaluation reward: 2.17\nepisode: 1073   score: 4.0   memory length: 201572   epsilon: 0.798885460004366    steps: 255    lr: 4e-05     evaluation reward: 2.18\nepisode: 1074   score: 5.0   memory length: 201861   epsilon: 0.7983132400043784    steps: 289    lr: 4e-05     evaluation reward: 2.2\nepisode: 1075   score: 3.0   memory length: 202109   epsilon: 0.7978222000043891    steps: 248    lr: 4e-05     evaluation reward: 2.19\nepisode: 1076   score: 2.0   memory length: 202311   epsilon: 0.7974222400043978    steps: 202    lr: 4e-05     evaluation reward: 2.18\nepisode: 1077   score: 1.0   memory length: 202483   epsilon: 0.7970816800044052    steps: 172    lr: 4e-05     evaluation reward: 2.18\nepisode: 1078   score: 2.0   memory length: 202703   epsilon: 0.7966460800044146    steps: 220    lr: 4e-05     evaluation reward: 2.19\nepisode: 1079   score: 6.0   memory length: 203096   epsilon: 0.7958679400044315    steps: 393    lr: 4e-05     evaluation reward: 2.23\nepisode: 1080   score: 0.0   memory length: 203219   epsilon: 0.7956244000044368    steps: 123    lr: 4e-05     evaluation reward: 2.22\nepisode: 1081   score: 5.0   memory length: 203525   epsilon: 0.79501852000445    steps: 306    lr: 4e-05     evaluation reward: 2.24\nepisode: 1082   score: 2.0   memory length: 203742   epsilon: 0.7945888600044593    steps: 217    lr: 4e-05     evaluation reward: 2.25\nepisode: 1083   score: 2.0   memory length: 203923   epsilon: 0.794230480004467    steps: 181    lr: 4e-05     evaluation reward: 2.24\nepisode: 1084   score: 1.0   memory length: 204093   epsilon: 0.7938938800044744    steps: 170    lr: 4e-05     evaluation reward: 2.24\nepisode: 1085   score: 3.0   memory length: 204323   epsilon: 0.7934384800044842    steps: 230    lr: 4e-05     evaluation reward: 2.24\nepisode: 1086   score: 2.0   memory length: 204539   epsilon: 0.7930108000044935    steps: 216    lr: 4e-05     evaluation reward: 2.26\nepisode: 1087   score: 3.0   memory length: 204804   epsilon: 0.7924861000045049    steps: 265    lr: 4e-05     evaluation reward: 2.27\nepisode: 1088   score: 5.0   memory length: 205090   epsilon: 0.7919198200045172    steps: 286    lr: 4e-05     evaluation reward: 2.3\nepisode: 1089   score: 3.0   memory length: 205339   epsilon: 0.7914268000045279    steps: 249    lr: 4e-05     evaluation reward: 2.28\nepisode: 1090   score: 2.0   memory length: 205558   epsilon: 0.7909931800045373    steps: 219    lr: 4e-05     evaluation reward: 2.27\nepisode: 1091   score: 4.0   memory length: 205817   epsilon: 0.7904803600045485    steps: 259    lr: 4e-05     evaluation reward: 2.3\nepisode: 1092   score: 2.0   memory length: 206019   epsilon: 0.7900804000045571    steps: 202    lr: 4e-05     evaluation reward: 2.3\nepisode: 1093   score: 3.0   memory length: 206267   epsilon: 0.7895893600045678    steps: 248    lr: 4e-05     evaluation reward: 2.32\nepisode: 1094   score: 4.0   memory length: 206542   epsilon: 0.7890448600045796    steps: 275    lr: 4e-05     evaluation reward: 2.36\nepisode: 1095   score: 5.0   memory length: 206845   epsilon: 0.7884449200045927    steps: 303    lr: 4e-05     evaluation reward: 2.38\nepisode: 1096   score: 2.0   memory length: 207066   epsilon: 0.7880073400046022    steps: 221    lr: 4e-05     evaluation reward: 2.39\nepisode: 1097   score: 2.0   memory length: 207248   epsilon: 0.78764698000461    steps: 182    lr: 4e-05     evaluation reward: 2.35\nepisode: 1098   score: 1.0   memory length: 207420   epsilon: 0.7873064200046174    steps: 172    lr: 4e-05     evaluation reward: 2.35\nepisode: 1099   score: 3.0   memory length: 207668   epsilon: 0.786815380004628    steps: 248    lr: 4e-05     evaluation reward: 2.35\nepisode: 1100   score: 3.0   memory length: 207912   epsilon: 0.7863322600046385    steps: 244    lr: 4e-05     evaluation reward: 2.37\nepisode: 1101   score: 3.0   memory length: 208163   epsilon: 0.7858352800046493    steps: 251    lr: 4e-05     evaluation reward: 2.37\nepisode: 1102   score: 1.0   memory length: 208313   epsilon: 0.7855382800046558    steps: 150    lr: 4e-05     evaluation reward: 2.37\nepisode: 1103   score: 4.0   memory length: 208553   epsilon: 0.7850630800046661    steps: 240    lr: 4e-05     evaluation reward: 2.39\nepisode: 1104   score: 1.0   memory length: 208704   epsilon: 0.7847641000046726    steps: 151    lr: 4e-05     evaluation reward: 2.38\nepisode: 1105   score: 3.0   memory length: 208953   epsilon: 0.7842710800046833    steps: 249    lr: 4e-05     evaluation reward: 2.37\nepisode: 1106   score: 3.0   memory length: 209181   epsilon: 0.7838196400046931    steps: 228    lr: 4e-05     evaluation reward: 2.38\nepisode: 1107   score: 2.0   memory length: 209379   epsilon: 0.7834276000047016    steps: 198    lr: 4e-05     evaluation reward: 2.38\nepisode: 1108   score: 5.0   memory length: 209722   epsilon: 0.7827484600047163    steps: 343    lr: 4e-05     evaluation reward: 2.41\nepisode: 1109   score: 0.0   memory length: 209845   epsilon: 0.7825049200047216    steps: 123    lr: 4e-05     evaluation reward: 2.39\nepisode: 1110   score: 2.0   memory length: 210030   epsilon: 0.7821386200047296    steps: 185    lr: 4e-05     evaluation reward: 2.39\nepisode: 1111   score: 3.0   memory length: 210297   epsilon: 0.781609960004741    steps: 267    lr: 4e-05     evaluation reward: 2.39\nepisode: 1112   score: 2.0   memory length: 210517   epsilon: 0.7811743600047505    steps: 220    lr: 4e-05     evaluation reward: 2.38\nepisode: 1113   score: 1.0   memory length: 210667   epsilon: 0.7808773600047569    steps: 150    lr: 4e-05     evaluation reward: 2.39\nepisode: 1114   score: 5.0   memory length: 210988   epsilon: 0.7802417800047707    steps: 321    lr: 4e-05     evaluation reward: 2.43\nepisode: 1115   score: 1.0   memory length: 211140   epsilon: 0.7799408200047773    steps: 152    lr: 4e-05     evaluation reward: 2.43\nepisode: 1116   score: 5.0   memory length: 211468   epsilon: 0.7792913800047914    steps: 328    lr: 4e-05     evaluation reward: 2.46\nepisode: 1117   score: 3.0   memory length: 211735   epsilon: 0.7787627200048028    steps: 267    lr: 4e-05     evaluation reward: 2.47\nepisode: 1118   score: 3.0   memory length: 211961   epsilon: 0.7783152400048126    steps: 226    lr: 4e-05     evaluation reward: 2.48\nepisode: 1119   score: 1.0   memory length: 212131   epsilon: 0.7779786400048199    steps: 170    lr: 4e-05     evaluation reward: 2.48\nepisode: 1120   score: 0.0   memory length: 212253   epsilon: 0.7777370800048251    steps: 122    lr: 4e-05     evaluation reward: 2.46\nepisode: 1121   score: 3.0   memory length: 212479   epsilon: 0.7772896000048348    steps: 226    lr: 4e-05     evaluation reward: 2.47\nepisode: 1122   score: 5.0   memory length: 212827   epsilon: 0.7766005600048498    steps: 348    lr: 4e-05     evaluation reward: 2.51\nepisode: 1123   score: 4.0   memory length: 213102   epsilon: 0.7760560600048616    steps: 275    lr: 4e-05     evaluation reward: 2.53\nepisode: 1124   score: 1.0   memory length: 213272   epsilon: 0.7757194600048689    steps: 170    lr: 4e-05     evaluation reward: 2.52\nepisode: 1125   score: 3.0   memory length: 213519   epsilon: 0.7752304000048795    steps: 247    lr: 4e-05     evaluation reward: 2.54\nepisode: 1126   score: 7.0   memory length: 213921   epsilon: 0.7744344400048968    steps: 402    lr: 4e-05     evaluation reward: 2.57\nepisode: 1127   score: 7.0   memory length: 214365   epsilon: 0.7735553200049159    steps: 444    lr: 4e-05     evaluation reward: 2.62\nepisode: 1128   score: 3.0   memory length: 214612   epsilon: 0.7730662600049265    steps: 247    lr: 4e-05     evaluation reward: 2.63\nepisode: 1129   score: 4.0   memory length: 214908   epsilon: 0.7724801800049392    steps: 296    lr: 4e-05     evaluation reward: 2.59\nepisode: 1130   score: 2.0   memory length: 215090   epsilon: 0.772119820004947    steps: 182    lr: 4e-05     evaluation reward: 2.59\nepisode: 1131   score: 0.0   memory length: 215212   epsilon: 0.7718782600049523    steps: 122    lr: 4e-05     evaluation reward: 2.58\nepisode: 1132   score: 1.0   memory length: 215383   epsilon: 0.7715396800049596    steps: 171    lr: 4e-05     evaluation reward: 2.56\nepisode: 1133   score: 3.0   memory length: 215627   epsilon: 0.7710565600049701    steps: 244    lr: 4e-05     evaluation reward: 2.54\nepisode: 1134   score: 2.0   memory length: 215807   epsilon: 0.7707001600049779    steps: 180    lr: 4e-05     evaluation reward: 2.53\nepisode: 1135   score: 3.0   memory length: 216053   epsilon: 0.7702130800049884    steps: 246    lr: 4e-05     evaluation reward: 2.49\nepisode: 1136   score: 5.0   memory length: 216366   epsilon: 0.7695933400050019    steps: 313    lr: 4e-05     evaluation reward: 2.53\nepisode: 1137   score: 4.0   memory length: 216658   epsilon: 0.7690151800050145    steps: 292    lr: 4e-05     evaluation reward: 2.52\nepisode: 1138   score: 3.0   memory length: 216889   epsilon: 0.7685578000050244    steps: 231    lr: 4e-05     evaluation reward: 2.55\nepisode: 1139   score: 3.0   memory length: 217137   epsilon: 0.768066760005035    steps: 248    lr: 4e-05     evaluation reward: 2.55\nepisode: 1140   score: 3.0   memory length: 217382   epsilon: 0.7675816600050456    steps: 245    lr: 4e-05     evaluation reward: 2.57\nepisode: 1141   score: 0.0   memory length: 217504   epsilon: 0.7673401000050508    steps: 122    lr: 4e-05     evaluation reward: 2.55\nepisode: 1142   score: 3.0   memory length: 217730   epsilon: 0.7668926200050605    steps: 226    lr: 4e-05     evaluation reward: 2.57\nepisode: 1143   score: 2.0   memory length: 217928   epsilon: 0.766500580005069    steps: 198    lr: 4e-05     evaluation reward: 2.56\nepisode: 1144   score: 5.0   memory length: 218252   epsilon: 0.765859060005083    steps: 324    lr: 4e-05     evaluation reward: 2.6\nepisode: 1145   score: 2.0   memory length: 218450   epsilon: 0.7654670200050915    steps: 198    lr: 4e-05     evaluation reward: 2.59\nepisode: 1146   score: 0.0   memory length: 218573   epsilon: 0.7652234800050968    steps: 123    lr: 4e-05     evaluation reward: 2.59\nepisode: 1147   score: 2.0   memory length: 218771   epsilon: 0.7648314400051053    steps: 198    lr: 4e-05     evaluation reward: 2.59\nepisode: 1148   score: 2.0   memory length: 218969   epsilon: 0.7644394000051138    steps: 198    lr: 4e-05     evaluation reward: 2.57\nepisode: 1149   score: 4.0   memory length: 219244   epsilon: 0.7638949000051256    steps: 275    lr: 4e-05     evaluation reward: 2.59\nepisode: 1150   score: 1.0   memory length: 219395   epsilon: 0.7635959200051321    steps: 151    lr: 4e-05     evaluation reward: 2.59\nepisode: 1151   score: 3.0   memory length: 219638   epsilon: 0.7631147800051425    steps: 243    lr: 4e-05     evaluation reward: 2.58\nepisode: 1152   score: 2.0   memory length: 219820   epsilon: 0.7627544200051504    steps: 182    lr: 4e-05     evaluation reward: 2.52\nepisode: 1153   score: 2.0   memory length: 220018   epsilon: 0.7623623800051589    steps: 198    lr: 4e-05     evaluation reward: 2.52\nepisode: 1154   score: 4.0   memory length: 220273   epsilon: 0.7618574800051698    steps: 255    lr: 4e-05     evaluation reward: 2.53\nepisode: 1155   score: 1.0   memory length: 220424   epsilon: 0.7615585000051763    steps: 151    lr: 4e-05     evaluation reward: 2.52\nepisode: 1156   score: 3.0   memory length: 220670   epsilon: 0.7610714200051869    steps: 246    lr: 4e-05     evaluation reward: 2.54\nepisode: 1157   score: 3.0   memory length: 220880   epsilon: 0.7606556200051959    steps: 210    lr: 4e-05     evaluation reward: 2.56\nepisode: 1158   score: 3.0   memory length: 221109   epsilon: 0.7602022000052058    steps: 229    lr: 4e-05     evaluation reward: 2.57\nepisode: 1159   score: 3.0   memory length: 221335   epsilon: 0.7597547200052155    steps: 226    lr: 4e-05     evaluation reward: 2.6\nepisode: 1160   score: 4.0   memory length: 221631   epsilon: 0.7591686400052282    steps: 296    lr: 4e-05     evaluation reward: 2.63\nepisode: 1161   score: 2.0   memory length: 221813   epsilon: 0.758808280005236    steps: 182    lr: 4e-05     evaluation reward: 2.65\nepisode: 1162   score: 10.0   memory length: 222187   epsilon: 0.7580677600052521    steps: 374    lr: 4e-05     evaluation reward: 2.74\nepisode: 1163   score: 3.0   memory length: 222432   epsilon: 0.7575826600052626    steps: 245    lr: 4e-05     evaluation reward: 2.74\nepisode: 1164   score: 1.0   memory length: 222600   epsilon: 0.7572500200052699    steps: 168    lr: 4e-05     evaluation reward: 2.73\nepisode: 1165   score: 2.0   memory length: 222797   epsilon: 0.7568599600052783    steps: 197    lr: 4e-05     evaluation reward: 2.73\nepisode: 1166   score: 1.0   memory length: 222948   epsilon: 0.7565609800052848    steps: 151    lr: 4e-05     evaluation reward: 2.73\nepisode: 1167   score: 1.0   memory length: 223098   epsilon: 0.7562639800052913    steps: 150    lr: 4e-05     evaluation reward: 2.73\nepisode: 1168   score: 4.0   memory length: 223377   epsilon: 0.7557115600053033    steps: 279    lr: 4e-05     evaluation reward: 2.75\nepisode: 1169   score: 4.0   memory length: 223695   epsilon: 0.7550819200053169    steps: 318    lr: 4e-05     evaluation reward: 2.78\nepisode: 1170   score: 0.0   memory length: 223818   epsilon: 0.7548383800053222    steps: 123    lr: 4e-05     evaluation reward: 2.76\nepisode: 1171   score: 4.0   memory length: 224093   epsilon: 0.754293880005334    steps: 275    lr: 4e-05     evaluation reward: 2.78\nepisode: 1172   score: 3.0   memory length: 224357   epsilon: 0.7537711600053454    steps: 264    lr: 4e-05     evaluation reward: 2.78\nepisode: 1173   score: 6.0   memory length: 224719   epsilon: 0.753054400005361    steps: 362    lr: 4e-05     evaluation reward: 2.8\nepisode: 1174   score: 4.0   memory length: 224994   epsilon: 0.7525099000053728    steps: 275    lr: 4e-05     evaluation reward: 2.79\nepisode: 1175   score: 3.0   memory length: 225220   epsilon: 0.7520624200053825    steps: 226    lr: 4e-05     evaluation reward: 2.79\nepisode: 1176   score: 4.0   memory length: 225479   epsilon: 0.7515496000053936    steps: 259    lr: 4e-05     evaluation reward: 2.81\nepisode: 1177   score: 4.0   memory length: 225755   epsilon: 0.7510031200054055    steps: 276    lr: 4e-05     evaluation reward: 2.84\nepisode: 1178   score: 4.0   memory length: 226015   epsilon: 0.7504883200054167    steps: 260    lr: 4e-05     evaluation reward: 2.86\nepisode: 1179   score: 5.0   memory length: 226306   epsilon: 0.7499121400054292    steps: 291    lr: 4e-05     evaluation reward: 2.85\nepisode: 1180   score: 3.0   memory length: 226551   epsilon: 0.7494270400054397    steps: 245    lr: 4e-05     evaluation reward: 2.88\nepisode: 1181   score: 2.0   memory length: 226733   epsilon: 0.7490666800054475    steps: 182    lr: 4e-05     evaluation reward: 2.85\nepisode: 1182   score: 5.0   memory length: 227042   epsilon: 0.7484548600054608    steps: 309    lr: 4e-05     evaluation reward: 2.88\nepisode: 1183   score: 4.0   memory length: 227318   epsilon: 0.7479083800054727    steps: 276    lr: 4e-05     evaluation reward: 2.9\nepisode: 1184   score: 6.0   memory length: 227653   epsilon: 0.7472450800054871    steps: 335    lr: 4e-05     evaluation reward: 2.95\nepisode: 1185   score: 2.0   memory length: 227850   epsilon: 0.7468550200054955    steps: 197    lr: 4e-05     evaluation reward: 2.94\nepisode: 1186   score: 4.0   memory length: 228107   epsilon: 0.7463461600055066    steps: 257    lr: 4e-05     evaluation reward: 2.96\nepisode: 1187   score: 3.0   memory length: 228352   epsilon: 0.7458610600055171    steps: 245    lr: 4e-05     evaluation reward: 2.96\nepisode: 1188   score: 2.0   memory length: 228549   epsilon: 0.7454710000055256    steps: 197    lr: 4e-05     evaluation reward: 2.93\nepisode: 1189   score: 4.0   memory length: 228806   epsilon: 0.7449621400055366    steps: 257    lr: 4e-05     evaluation reward: 2.94\nepisode: 1190   score: 7.0   memory length: 229217   epsilon: 0.7441483600055543    steps: 411    lr: 4e-05     evaluation reward: 2.99\nepisode: 1191   score: 3.0   memory length: 229443   epsilon: 0.743700880005564    steps: 226    lr: 4e-05     evaluation reward: 2.98\nepisode: 1192   score: 0.0   memory length: 229565   epsilon: 0.7434593200055692    steps: 122    lr: 4e-05     evaluation reward: 2.96\nepisode: 1193   score: 4.0   memory length: 229843   epsilon: 0.7429088800055812    steps: 278    lr: 4e-05     evaluation reward: 2.97\nepisode: 1194   score: 3.0   memory length: 230091   epsilon: 0.7424178400055919    steps: 248    lr: 4e-05     evaluation reward: 2.96\nepisode: 1195   score: 2.0   memory length: 230291   epsilon: 0.7420218400056005    steps: 200    lr: 4e-05     evaluation reward: 2.93\nepisode: 1196   score: 5.0   memory length: 230640   epsilon: 0.7413308200056155    steps: 349    lr: 4e-05     evaluation reward: 2.96\nepisode: 1197   score: 3.0   memory length: 230888   epsilon: 0.7408397800056261    steps: 248    lr: 4e-05     evaluation reward: 2.97\nepisode: 1198   score: 4.0   memory length: 231161   epsilon: 0.7402992400056378    steps: 273    lr: 4e-05     evaluation reward: 3.0\nepisode: 1199   score: 7.0   memory length: 231563   epsilon: 0.7395032800056551    steps: 402    lr: 4e-05     evaluation reward: 3.04\nepisode: 1200   score: 2.0   memory length: 231743   epsilon: 0.7391468800056629    steps: 180    lr: 4e-05     evaluation reward: 3.03\nepisode: 1201   score: 5.0   memory length: 232053   epsilon: 0.7385330800056762    steps: 310    lr: 4e-05     evaluation reward: 3.05\nepisode: 1202   score: 4.0   memory length: 232311   epsilon: 0.7380222400056873    steps: 258    lr: 4e-05     evaluation reward: 3.08\nepisode: 1203   score: 2.0   memory length: 232511   epsilon: 0.7376262400056959    steps: 200    lr: 4e-05     evaluation reward: 3.06\nepisode: 1204   score: 1.0   memory length: 232681   epsilon: 0.7372896400057032    steps: 170    lr: 4e-05     evaluation reward: 3.06\nepisode: 1205   score: 5.0   memory length: 233007   epsilon: 0.7366441600057172    steps: 326    lr: 4e-05     evaluation reward: 3.08\nepisode: 1206   score: 4.0   memory length: 233248   epsilon: 0.7361669800057276    steps: 241    lr: 4e-05     evaluation reward: 3.09\nepisode: 1207   score: 3.0   memory length: 233461   epsilon: 0.7357452400057367    steps: 213    lr: 4e-05     evaluation reward: 3.1\nepisode: 1208   score: 3.0   memory length: 233707   epsilon: 0.7352581600057473    steps: 246    lr: 4e-05     evaluation reward: 3.08\nepisode: 1209   score: 4.0   memory length: 234000   epsilon: 0.7346780200057599    steps: 293    lr: 4e-05     evaluation reward: 3.12\nepisode: 1210   score: 5.0   memory length: 234342   epsilon: 0.7340008600057746    steps: 342    lr: 4e-05     evaluation reward: 3.15\nepisode: 1211   score: 0.0   memory length: 234465   epsilon: 0.7337573200057799    steps: 123    lr: 4e-05     evaluation reward: 3.12\nepisode: 1212   score: 0.0   memory length: 234588   epsilon: 0.7335137800057852    steps: 123    lr: 4e-05     evaluation reward: 3.1\nepisode: 1213   score: 7.0   memory length: 234955   epsilon: 0.7327871200058009    steps: 367    lr: 4e-05     evaluation reward: 3.16\nepisode: 1214   score: 3.0   memory length: 235168   epsilon: 0.7323653800058101    steps: 213    lr: 4e-05     evaluation reward: 3.14\nepisode: 1215   score: 3.0   memory length: 235394   epsilon: 0.7319179000058198    steps: 226    lr: 4e-05     evaluation reward: 3.16\nepisode: 1216   score: 1.0   memory length: 235566   epsilon: 0.7315773400058272    steps: 172    lr: 4e-05     evaluation reward: 3.12\nepisode: 1217   score: 1.0   memory length: 235716   epsilon: 0.7312803400058336    steps: 150    lr: 4e-05     evaluation reward: 3.1\nepisode: 1218   score: 2.0   memory length: 235896   epsilon: 0.7309239400058414    steps: 180    lr: 4e-05     evaluation reward: 3.09\nepisode: 1219   score: 3.0   memory length: 236121   epsilon: 0.730478440005851    steps: 225    lr: 4e-05     evaluation reward: 3.11\nepisode: 1220   score: 6.0   memory length: 236500   epsilon: 0.7297280200058673    steps: 379    lr: 4e-05     evaluation reward: 3.17\nepisode: 1221   score: 5.0   memory length: 236830   epsilon: 0.7290746200058815    steps: 330    lr: 4e-05     evaluation reward: 3.19\nepisode: 1222   score: 4.0   memory length: 237125   epsilon: 0.7284905200058942    steps: 295    lr: 4e-05     evaluation reward: 3.18\nepisode: 1223   score: 1.0   memory length: 237295   epsilon: 0.7281539200059015    steps: 170    lr: 4e-05     evaluation reward: 3.15\nepisode: 1224   score: 2.0   memory length: 237474   epsilon: 0.7277995000059092    steps: 179    lr: 4e-05     evaluation reward: 3.16\nepisode: 1225   score: 3.0   memory length: 237720   epsilon: 0.7273124200059198    steps: 246    lr: 4e-05     evaluation reward: 3.16\nepisode: 1226   score: 1.0   memory length: 237871   epsilon: 0.7270134400059263    steps: 151    lr: 4e-05     evaluation reward: 3.1\nepisode: 1227   score: 4.0   memory length: 238166   epsilon: 0.726429340005939    steps: 295    lr: 4e-05     evaluation reward: 3.07\nepisode: 1228   score: 2.0   memory length: 238366   epsilon: 0.7260333400059475    steps: 200    lr: 4e-05     evaluation reward: 3.06\nepisode: 1229   score: 4.0   memory length: 238607   epsilon: 0.7255561600059579    steps: 241    lr: 4e-05     evaluation reward: 3.06\nepisode: 1230   score: 3.0   memory length: 238817   epsilon: 0.7251403600059669    steps: 210    lr: 4e-05     evaluation reward: 3.07\nepisode: 1231   score: 3.0   memory length: 239043   epsilon: 0.7246928800059766    steps: 226    lr: 4e-05     evaluation reward: 3.1\nepisode: 1232   score: 3.0   memory length: 239310   epsilon: 0.7241642200059881    steps: 267    lr: 4e-05     evaluation reward: 3.12\nepisode: 1233   score: 4.0   memory length: 239588   epsilon: 0.7236137800060001    steps: 278    lr: 4e-05     evaluation reward: 3.13\nepisode: 1234   score: 4.0   memory length: 239887   epsilon: 0.7230217600060129    steps: 299    lr: 4e-05     evaluation reward: 3.15\nepisode: 1235   score: 1.0   memory length: 240038   epsilon: 0.7227227800060194    steps: 151    lr: 4e-05     evaluation reward: 3.13\nepisode: 1236   score: 2.0   memory length: 240236   epsilon: 0.7223307400060279    steps: 198    lr: 4e-05     evaluation reward: 3.1\nepisode: 1237   score: 3.0   memory length: 240487   epsilon: 0.7218337600060387    steps: 251    lr: 4e-05     evaluation reward: 3.09\nepisode: 1238   score: 6.0   memory length: 240882   epsilon: 0.7210516600060557    steps: 395    lr: 4e-05     evaluation reward: 3.12\nepisode: 1239   score: 5.0   memory length: 241207   epsilon: 0.7204081600060697    steps: 325    lr: 4e-05     evaluation reward: 3.14\nepisode: 1240   score: 4.0   memory length: 241481   epsilon: 0.7198656400060814    steps: 274    lr: 4e-05     evaluation reward: 3.15\nepisode: 1241   score: 3.0   memory length: 241731   epsilon: 0.7193706400060922    steps: 250    lr: 4e-05     evaluation reward: 3.18\nepisode: 1242   score: 1.0   memory length: 241900   epsilon: 0.7190360200060995    steps: 169    lr: 4e-05     evaluation reward: 3.16\nepisode: 1243   score: 4.0   memory length: 242157   epsilon: 0.7185271600061105    steps: 257    lr: 4e-05     evaluation reward: 3.18\nepisode: 1244   score: 6.0   memory length: 242501   epsilon: 0.7178460400061253    steps: 344    lr: 4e-05     evaluation reward: 3.19\nepisode: 1245   score: 2.0   memory length: 242681   epsilon: 0.717489640006133    steps: 180    lr: 4e-05     evaluation reward: 3.19\nepisode: 1246   score: 2.0   memory length: 242897   epsilon: 0.7170619600061423    steps: 216    lr: 4e-05     evaluation reward: 3.21\nepisode: 1247   score: 6.0   memory length: 243220   epsilon: 0.7164224200061562    steps: 323    lr: 4e-05     evaluation reward: 3.25\nepisode: 1248   score: 2.0   memory length: 243435   epsilon: 0.7159967200061654    steps: 215    lr: 4e-05     evaluation reward: 3.25\nepisode: 1249   score: 2.0   memory length: 243653   epsilon: 0.7155650800061748    steps: 218    lr: 4e-05     evaluation reward: 3.23\nepisode: 1250   score: 1.0   memory length: 243804   epsilon: 0.7152661000061813    steps: 151    lr: 4e-05     evaluation reward: 3.23\nepisode: 1251   score: 3.0   memory length: 244029   epsilon: 0.714820600006191    steps: 225    lr: 4e-05     evaluation reward: 3.23\nepisode: 1252   score: 2.0   memory length: 244227   epsilon: 0.7144285600061995    steps: 198    lr: 4e-05     evaluation reward: 3.23\nepisode: 1253   score: 1.0   memory length: 244378   epsilon: 0.714129580006206    steps: 151    lr: 4e-05     evaluation reward: 3.22\nepisode: 1254   score: 0.0   memory length: 244501   epsilon: 0.7138860400062113    steps: 123    lr: 4e-05     evaluation reward: 3.18\nepisode: 1255   score: 4.0   memory length: 244783   epsilon: 0.7133276800062234    steps: 282    lr: 4e-05     evaluation reward: 3.21\nepisode: 1256   score: 3.0   memory length: 245031   epsilon: 0.712836640006234    steps: 248    lr: 4e-05     evaluation reward: 3.21\nepisode: 1257   score: 4.0   memory length: 245329   epsilon: 0.7122466000062468    steps: 298    lr: 4e-05     evaluation reward: 3.22\nepisode: 1258   score: 2.0   memory length: 245527   epsilon: 0.7118545600062554    steps: 198    lr: 4e-05     evaluation reward: 3.21\nepisode: 1259   score: 7.0   memory length: 245964   epsilon: 0.7109893000062741    steps: 437    lr: 4e-05     evaluation reward: 3.25\nepisode: 1260   score: 4.0   memory length: 246261   epsilon: 0.7104012400062869    steps: 297    lr: 4e-05     evaluation reward: 3.25\nepisode: 1261   score: 4.0   memory length: 246539   epsilon: 0.7098508000062989    steps: 278    lr: 4e-05     evaluation reward: 3.27\nepisode: 1262   score: 4.0   memory length: 246813   epsilon: 0.7093082800063106    steps: 274    lr: 4e-05     evaluation reward: 3.21\nepisode: 1263   score: 4.0   memory length: 247069   epsilon: 0.7088014000063216    steps: 256    lr: 4e-05     evaluation reward: 3.22\nepisode: 1264   score: 0.0   memory length: 247192   epsilon: 0.7085578600063269    steps: 123    lr: 4e-05     evaluation reward: 3.21\nepisode: 1265   score: 1.0   memory length: 247342   epsilon: 0.7082608600063334    steps: 150    lr: 4e-05     evaluation reward: 3.2\nepisode: 1266   score: 2.0   memory length: 247542   epsilon: 0.707864860006342    steps: 200    lr: 4e-05     evaluation reward: 3.21\nepisode: 1267   score: 2.0   memory length: 247742   epsilon: 0.7074688600063506    steps: 200    lr: 4e-05     evaluation reward: 3.22\nepisode: 1268   score: 3.0   memory length: 247968   epsilon: 0.7070213800063603    steps: 226    lr: 4e-05     evaluation reward: 3.21\nepisode: 1269   score: 6.0   memory length: 248343   epsilon: 0.7062788800063764    steps: 375    lr: 4e-05     evaluation reward: 3.23\nepisode: 1270   score: 4.0   memory length: 248621   epsilon: 0.7057284400063883    steps: 278    lr: 4e-05     evaluation reward: 3.27\nepisode: 1271   score: 1.0   memory length: 248772   epsilon: 0.7054294600063948    steps: 151    lr: 4e-05     evaluation reward: 3.24\nepisode: 1272   score: 2.0   memory length: 248970   epsilon: 0.7050374200064033    steps: 198    lr: 4e-05     evaluation reward: 3.23\nepisode: 1273   score: 3.0   memory length: 249198   epsilon: 0.7045859800064131    steps: 228    lr: 4e-05     evaluation reward: 3.2\nepisode: 1274   score: 3.0   memory length: 249423   epsilon: 0.7041404800064228    steps: 225    lr: 4e-05     evaluation reward: 3.19\nepisode: 1275   score: 2.0   memory length: 249641   epsilon: 0.7037088400064322    steps: 218    lr: 4e-05     evaluation reward: 3.18\nepisode: 1276   score: 4.0   memory length: 249913   epsilon: 0.7031702800064439    steps: 272    lr: 4e-05     evaluation reward: 3.18\nepisode: 1277   score: 5.0   memory length: 250258   epsilon: 0.7024871800064587    steps: 345    lr: 4e-05     evaluation reward: 3.19\nepisode: 1278   score: 3.0   memory length: 250504   epsilon: 0.7020001000064693    steps: 246    lr: 4e-05     evaluation reward: 3.18\nepisode: 1279   score: 3.0   memory length: 250716   epsilon: 0.7015803400064784    steps: 212    lr: 4e-05     evaluation reward: 3.16\nepisode: 1280   score: 3.0   memory length: 250983   epsilon: 0.7010516800064899    steps: 267    lr: 4e-05     evaluation reward: 3.16\nepisode: 1281   score: 5.0   memory length: 251281   epsilon: 0.7004616400065027    steps: 298    lr: 4e-05     evaluation reward: 3.19\nepisode: 1282   score: 3.0   memory length: 251529   epsilon: 0.6999706000065133    steps: 248    lr: 4e-05     evaluation reward: 3.17\nepisode: 1283   score: 1.0   memory length: 251699   epsilon: 0.6996340000065207    steps: 170    lr: 4e-05     evaluation reward: 3.14\nepisode: 1284   score: 2.0   memory length: 251879   epsilon: 0.6992776000065284    steps: 180    lr: 4e-05     evaluation reward: 3.1\nepisode: 1285   score: 5.0   memory length: 252225   epsilon: 0.6985925200065433    steps: 346    lr: 4e-05     evaluation reward: 3.13\nepisode: 1286   score: 2.0   memory length: 252423   epsilon: 0.6982004800065518    steps: 198    lr: 4e-05     evaluation reward: 3.11\nepisode: 1287   score: 4.0   memory length: 252739   epsilon: 0.6975748000065654    steps: 316    lr: 4e-05     evaluation reward: 3.12\nepisode: 1288   score: 1.0   memory length: 252908   epsilon: 0.6972401800065726    steps: 169    lr: 4e-05     evaluation reward: 3.11\nepisode: 1289   score: 1.0   memory length: 253078   epsilon: 0.6969035800065799    steps: 170    lr: 4e-05     evaluation reward: 3.08\nepisode: 1290   score: 3.0   memory length: 253303   epsilon: 0.6964580800065896    steps: 225    lr: 4e-05     evaluation reward: 3.04\nepisode: 1291   score: 3.0   memory length: 253548   epsilon: 0.6959729800066001    steps: 245    lr: 4e-05     evaluation reward: 3.04\nepisode: 1292   score: 0.0   memory length: 253671   epsilon: 0.6957294400066054    steps: 123    lr: 4e-05     evaluation reward: 3.04\nepisode: 1293   score: 5.0   memory length: 253944   epsilon: 0.6951889000066171    steps: 273    lr: 4e-05     evaluation reward: 3.05\nepisode: 1294   score: 2.0   memory length: 254125   epsilon: 0.6948305200066249    steps: 181    lr: 4e-05     evaluation reward: 3.04\nepisode: 1295   score: 3.0   memory length: 254351   epsilon: 0.6943830400066346    steps: 226    lr: 4e-05     evaluation reward: 3.05\nepisode: 1296   score: 4.0   memory length: 254626   epsilon: 0.6938385400066465    steps: 275    lr: 4e-05     evaluation reward: 3.04\nepisode: 1297   score: 2.0   memory length: 254826   epsilon: 0.6934425400066551    steps: 200    lr: 4e-05     evaluation reward: 3.03\nepisode: 1298   score: 5.0   memory length: 255114   epsilon: 0.6928723000066674    steps: 288    lr: 4e-05     evaluation reward: 3.04\nepisode: 1299   score: 5.0   memory length: 255417   epsilon: 0.6922723600066805    steps: 303    lr: 4e-05     evaluation reward: 3.02\nepisode: 1300   score: 4.0   memory length: 255694   epsilon: 0.6917239000066924    steps: 277    lr: 4e-05     evaluation reward: 3.04\nepisode: 1301   score: 6.0   memory length: 256067   epsilon: 0.6909853600067084    steps: 373    lr: 4e-05     evaluation reward: 3.05\nepisode: 1302   score: 6.0   memory length: 256483   epsilon: 0.6901616800067263    steps: 416    lr: 4e-05     evaluation reward: 3.07\nepisode: 1303   score: 1.0   memory length: 256634   epsilon: 0.6898627000067328    steps: 151    lr: 4e-05     evaluation reward: 3.06\nepisode: 1304   score: 0.0   memory length: 256756   epsilon: 0.689621140006738    steps: 122    lr: 4e-05     evaluation reward: 3.05\nepisode: 1305   score: 5.0   memory length: 257082   epsilon: 0.688975660006752    steps: 326    lr: 4e-05     evaluation reward: 3.05\nepisode: 1306   score: 3.0   memory length: 257307   epsilon: 0.6885301600067617    steps: 225    lr: 4e-05     evaluation reward: 3.04\nepisode: 1307   score: 4.0   memory length: 257602   epsilon: 0.6879460600067744    steps: 295    lr: 4e-05     evaluation reward: 3.05\nepisode: 1308   score: 4.0   memory length: 257861   epsilon: 0.6874332400067855    steps: 259    lr: 4e-05     evaluation reward: 3.06\nepisode: 1309   score: 4.0   memory length: 258121   epsilon: 0.6869184400067967    steps: 260    lr: 4e-05     evaluation reward: 3.06\nepisode: 1310   score: 10.0   memory length: 258547   epsilon: 0.686074960006815    steps: 426    lr: 4e-05     evaluation reward: 3.11\nepisode: 1311   score: 6.0   memory length: 258921   epsilon: 0.6853344400068311    steps: 374    lr: 4e-05     evaluation reward: 3.17\nepisode: 1312   score: 2.0   memory length: 259102   epsilon: 0.6849760600068389    steps: 181    lr: 4e-05     evaluation reward: 3.19\nepisode: 1313   score: 4.0   memory length: 259398   epsilon: 0.6843899800068516    steps: 296    lr: 4e-05     evaluation reward: 3.16\nepisode: 1314   score: 1.0   memory length: 259549   epsilon: 0.6840910000068581    steps: 151    lr: 4e-05     evaluation reward: 3.14\nepisode: 1315   score: 7.0   memory length: 259978   epsilon: 0.6832415800068765    steps: 429    lr: 4e-05     evaluation reward: 3.18\nepisode: 1316   score: 4.0   memory length: 260255   epsilon: 0.6826931200068884    steps: 277    lr: 4e-05     evaluation reward: 3.21\nepisode: 1317   score: 4.0   memory length: 260532   epsilon: 0.6821446600069003    steps: 277    lr: 4e-05     evaluation reward: 3.24\nepisode: 1318   score: 3.0   memory length: 260757   epsilon: 0.68169916000691    steps: 225    lr: 4e-05     evaluation reward: 3.25\nepisode: 1319   score: 2.0   memory length: 260955   epsilon: 0.6813071200069185    steps: 198    lr: 4e-05     evaluation reward: 3.24\nepisode: 1320   score: 2.0   memory length: 261154   epsilon: 0.6809131000069271    steps: 199    lr: 4e-05     evaluation reward: 3.2\nepisode: 1321   score: 3.0   memory length: 261402   epsilon: 0.6804220600069377    steps: 248    lr: 4e-05     evaluation reward: 3.18\nepisode: 1322   score: 5.0   memory length: 261748   epsilon: 0.6797369800069526    steps: 346    lr: 4e-05     evaluation reward: 3.19\nepisode: 1323   score: 5.0   memory length: 262071   epsilon: 0.6790974400069665    steps: 323    lr: 4e-05     evaluation reward: 3.23\nepisode: 1324   score: 4.0   memory length: 262369   epsilon: 0.6785074000069793    steps: 298    lr: 4e-05     evaluation reward: 3.25\nepisode: 1325   score: 4.0   memory length: 262644   epsilon: 0.6779629000069911    steps: 275    lr: 4e-05     evaluation reward: 3.26\nepisode: 1326   score: 3.0   memory length: 262893   epsilon: 0.6774698800070018    steps: 249    lr: 4e-05     evaluation reward: 3.28\nepisode: 1327   score: 3.0   memory length: 263122   epsilon: 0.6770164600070117    steps: 229    lr: 4e-05     evaluation reward: 3.27\nepisode: 1328   score: 3.0   memory length: 263332   epsilon: 0.6766006600070207    steps: 210    lr: 4e-05     evaluation reward: 3.28\nepisode: 1329   score: 1.0   memory length: 263483   epsilon: 0.6763016800070272    steps: 151    lr: 4e-05     evaluation reward: 3.25\nepisode: 1330   score: 4.0   memory length: 263741   epsilon: 0.6757908400070383    steps: 258    lr: 4e-05     evaluation reward: 3.26\nepisode: 1331   score: 3.0   memory length: 263967   epsilon: 0.675343360007048    steps: 226    lr: 4e-05     evaluation reward: 3.26\nepisode: 1332   score: 5.0   memory length: 264293   epsilon: 0.674697880007062    steps: 326    lr: 4e-05     evaluation reward: 3.28\nepisode: 1333   score: 3.0   memory length: 264545   epsilon: 0.6741989200070728    steps: 252    lr: 4e-05     evaluation reward: 3.27\nepisode: 1334   score: 4.0   memory length: 264825   epsilon: 0.6736445200070849    steps: 280    lr: 4e-05     evaluation reward: 3.27\nepisode: 1335   score: 3.0   memory length: 265053   epsilon: 0.6731930800070947    steps: 228    lr: 4e-05     evaluation reward: 3.29\nepisode: 1336   score: 3.0   memory length: 265278   epsilon: 0.6727475800071043    steps: 225    lr: 4e-05     evaluation reward: 3.3\nepisode: 1337   score: 5.0   memory length: 265620   epsilon: 0.672070420007119    steps: 342    lr: 4e-05     evaluation reward: 3.32\nepisode: 1338   score: 2.0   memory length: 265802   epsilon: 0.6717100600071269    steps: 182    lr: 4e-05     evaluation reward: 3.28\nepisode: 1339   score: 6.0   memory length: 266181   epsilon: 0.6709596400071431    steps: 379    lr: 4e-05     evaluation reward: 3.29\nepisode: 1340   score: 4.0   memory length: 266459   epsilon: 0.6704092000071551    steps: 278    lr: 4e-05     evaluation reward: 3.29\nepisode: 1341   score: 2.0   memory length: 266656   epsilon: 0.6700191400071636    steps: 197    lr: 4e-05     evaluation reward: 3.28\nepisode: 1342   score: 4.0   memory length: 266937   epsilon: 0.6694627600071756    steps: 281    lr: 4e-05     evaluation reward: 3.31\nepisode: 1343   score: 2.0   memory length: 267137   epsilon: 0.6690667600071842    steps: 200    lr: 4e-05     evaluation reward: 3.29\nepisode: 1344   score: 3.0   memory length: 267347   epsilon: 0.6686509600071933    steps: 210    lr: 4e-05     evaluation reward: 3.26\nepisode: 1345   score: 8.0   memory length: 267795   epsilon: 0.6677639200072125    steps: 448    lr: 4e-05     evaluation reward: 3.32\nepisode: 1346   score: 4.0   memory length: 268070   epsilon: 0.6672194200072243    steps: 275    lr: 4e-05     evaluation reward: 3.34\nepisode: 1347   score: 4.0   memory length: 268367   epsilon: 0.6666313600072371    steps: 297    lr: 4e-05     evaluation reward: 3.32\nepisode: 1348   score: 2.0   memory length: 268565   epsilon: 0.6662393200072456    steps: 198    lr: 4e-05     evaluation reward: 3.32\nepisode: 1349   score: 1.0   memory length: 268716   epsilon: 0.6659403400072521    steps: 151    lr: 4e-05     evaluation reward: 3.31\nepisode: 1350   score: 6.0   memory length: 269115   epsilon: 0.6651503200072693    steps: 399    lr: 4e-05     evaluation reward: 3.36\nepisode: 1351   score: 3.0   memory length: 269328   epsilon: 0.6647285800072784    steps: 213    lr: 4e-05     evaluation reward: 3.36\nepisode: 1352   score: 0.0   memory length: 269451   epsilon: 0.6644850400072837    steps: 123    lr: 4e-05     evaluation reward: 3.34\nepisode: 1353   score: 3.0   memory length: 269680   epsilon: 0.6640316200072935    steps: 229    lr: 4e-05     evaluation reward: 3.36\nepisode: 1354   score: 3.0   memory length: 269927   epsilon: 0.6635425600073042    steps: 247    lr: 4e-05     evaluation reward: 3.39\nepisode: 1355   score: 2.0   memory length: 270125   epsilon: 0.6631505200073127    steps: 198    lr: 4e-05     evaluation reward: 3.37\nepisode: 1356   score: 1.0   memory length: 270276   epsilon: 0.6628515400073192    steps: 151    lr: 4e-05     evaluation reward: 3.35\nepisode: 1357   score: 3.0   memory length: 270507   epsilon: 0.6623941600073291    steps: 231    lr: 4e-05     evaluation reward: 3.34\nepisode: 1358   score: 3.0   memory length: 270733   epsilon: 0.6619466800073388    steps: 226    lr: 4e-05     evaluation reward: 3.35\nepisode: 1359   score: 3.0   memory length: 270981   epsilon: 0.6614556400073495    steps: 248    lr: 4e-05     evaluation reward: 3.31\nepisode: 1360   score: 6.0   memory length: 271335   epsilon: 0.6607547200073647    steps: 354    lr: 4e-05     evaluation reward: 3.33\nepisode: 1361   score: 7.0   memory length: 271727   epsilon: 0.6599785600073815    steps: 392    lr: 4e-05     evaluation reward: 3.36\nepisode: 1362   score: 2.0   memory length: 271925   epsilon: 0.65958652000739    steps: 198    lr: 4e-05     evaluation reward: 3.34\nepisode: 1363   score: 1.0   memory length: 272076   epsilon: 0.6592875400073965    steps: 151    lr: 4e-05     evaluation reward: 3.31\nepisode: 1364   score: 4.0   memory length: 272331   epsilon: 0.6587826400074075    steps: 255    lr: 4e-05     evaluation reward: 3.35\nepisode: 1365   score: 5.0   memory length: 272641   epsilon: 0.6581688400074208    steps: 310    lr: 4e-05     evaluation reward: 3.39\nepisode: 1366   score: 5.0   memory length: 272966   epsilon: 0.6575253400074348    steps: 325    lr: 4e-05     evaluation reward: 3.42\nepisode: 1367   score: 1.0   memory length: 273117   epsilon: 0.6572263600074413    steps: 151    lr: 4e-05     evaluation reward: 3.41\nepisode: 1368   score: 2.0   memory length: 273315   epsilon: 0.6568343200074498    steps: 198    lr: 4e-05     evaluation reward: 3.4\nepisode: 1369   score: 3.0   memory length: 273558   epsilon: 0.6563531800074602    steps: 243    lr: 4e-05     evaluation reward: 3.37\nepisode: 1370   score: 3.0   memory length: 273787   epsilon: 0.6558997600074701    steps: 229    lr: 4e-05     evaluation reward: 3.36\nepisode: 1371   score: 4.0   memory length: 274052   epsilon: 0.6553750600074815    steps: 265    lr: 4e-05     evaluation reward: 3.39\nepisode: 1372   score: 0.0   memory length: 274175   epsilon: 0.6551315200074868    steps: 123    lr: 4e-05     evaluation reward: 3.37\nepisode: 1373   score: 2.0   memory length: 274375   epsilon: 0.6547355200074954    steps: 200    lr: 4e-05     evaluation reward: 3.36\nepisode: 1374   score: 5.0   memory length: 274700   epsilon: 0.6540920200075093    steps: 325    lr: 4e-05     evaluation reward: 3.38\nepisode: 1375   score: 3.0   memory length: 274930   epsilon: 0.6536366200075192    steps: 230    lr: 4e-05     evaluation reward: 3.39\nepisode: 1376   score: 3.0   memory length: 275176   epsilon: 0.6531495400075298    steps: 246    lr: 4e-05     evaluation reward: 3.38\nepisode: 1377   score: 2.0   memory length: 275358   epsilon: 0.6527891800075376    steps: 182    lr: 4e-05     evaluation reward: 3.35\nepisode: 1378   score: 5.0   memory length: 275685   epsilon: 0.6521417200075517    steps: 327    lr: 4e-05     evaluation reward: 3.37\nepisode: 1379   score: 3.0   memory length: 275913   epsilon: 0.6516902800075615    steps: 228    lr: 4e-05     evaluation reward: 3.37\nepisode: 1380   score: 5.0   memory length: 276237   epsilon: 0.6510487600075754    steps: 324    lr: 4e-05     evaluation reward: 3.39\nepisode: 1381   score: 4.0   memory length: 276516   epsilon: 0.6504963400075874    steps: 279    lr: 4e-05     evaluation reward: 3.38\nepisode: 1382   score: 5.0   memory length: 276820   epsilon: 0.6498944200076004    steps: 304    lr: 4e-05     evaluation reward: 3.4\nepisode: 1383   score: 4.0   memory length: 277094   epsilon: 0.6493519000076122    steps: 274    lr: 4e-05     evaluation reward: 3.43\nepisode: 1384   score: 4.0   memory length: 277369   epsilon: 0.648807400007624    steps: 275    lr: 4e-05     evaluation reward: 3.45\nepisode: 1385   score: 5.0   memory length: 277690   epsilon: 0.6481718200076378    steps: 321    lr: 4e-05     evaluation reward: 3.45\nepisode: 1386   score: 3.0   memory length: 277937   epsilon: 0.6476827600076485    steps: 247    lr: 4e-05     evaluation reward: 3.46\nepisode: 1387   score: 4.0   memory length: 278218   epsilon: 0.6471263800076605    steps: 281    lr: 4e-05     evaluation reward: 3.46\nepisode: 1388   score: 4.0   memory length: 278476   epsilon: 0.6466155400076716    steps: 258    lr: 4e-05     evaluation reward: 3.49\nepisode: 1389   score: 4.0   memory length: 278731   epsilon: 0.6461106400076826    steps: 255    lr: 4e-05     evaluation reward: 3.52\nepisode: 1390   score: 6.0   memory length: 279120   epsilon: 0.6453404200076993    steps: 389    lr: 4e-05     evaluation reward: 3.55\nepisode: 1391   score: 2.0   memory length: 279319   epsilon: 0.6449464000077079    steps: 199    lr: 4e-05     evaluation reward: 3.54\nepisode: 1392   score: 3.0   memory length: 279546   epsilon: 0.6444969400077176    steps: 227    lr: 4e-05     evaluation reward: 3.57\nepisode: 1393   score: 3.0   memory length: 279791   epsilon: 0.6440118400077282    steps: 245    lr: 4e-05     evaluation reward: 3.55\nepisode: 1394   score: 5.0   memory length: 280136   epsilon: 0.643328740007743    steps: 345    lr: 4e-05     evaluation reward: 3.58\nepisode: 1395   score: 2.0   memory length: 280334   epsilon: 0.6429367000077515    steps: 198    lr: 4e-05     evaluation reward: 3.57\nepisode: 1396   score: 4.0   memory length: 280631   epsilon: 0.6423486400077643    steps: 297    lr: 4e-05     evaluation reward: 3.57\nepisode: 1397   score: 5.0   memory length: 280940   epsilon: 0.6417368200077775    steps: 309    lr: 4e-05     evaluation reward: 3.6\nepisode: 1398   score: 4.0   memory length: 281220   epsilon: 0.6411824200077896    steps: 280    lr: 4e-05     evaluation reward: 3.59\nepisode: 1399   score: 4.0   memory length: 281496   epsilon: 0.6406359400078014    steps: 276    lr: 4e-05     evaluation reward: 3.58\nepisode: 1400   score: 4.0   memory length: 281772   epsilon: 0.6400894600078133    steps: 276    lr: 4e-05     evaluation reward: 3.58\nepisode: 1401   score: 4.0   memory length: 282067   epsilon: 0.639505360007826    steps: 295    lr: 4e-05     evaluation reward: 3.56\nepisode: 1402   score: 2.0   memory length: 282265   epsilon: 0.6391133200078345    steps: 198    lr: 4e-05     evaluation reward: 3.52\nepisode: 1403   score: 3.0   memory length: 282514   epsilon: 0.6386203000078452    steps: 249    lr: 4e-05     evaluation reward: 3.54\nepisode: 1404   score: 3.0   memory length: 282740   epsilon: 0.6381728200078549    steps: 226    lr: 4e-05     evaluation reward: 3.57\nepisode: 1405   score: 1.0   memory length: 282891   epsilon: 0.6378738400078614    steps: 151    lr: 4e-05     evaluation reward: 3.53\nepisode: 1406   score: 6.0   memory length: 283246   epsilon: 0.6371709400078767    steps: 355    lr: 4e-05     evaluation reward: 3.56\nepisode: 1407   score: 4.0   memory length: 283521   epsilon: 0.6366264400078885    steps: 275    lr: 4e-05     evaluation reward: 3.56\nepisode: 1408   score: 3.0   memory length: 283734   epsilon: 0.6362047000078976    steps: 213    lr: 4e-05     evaluation reward: 3.55\nepisode: 1409   score: 2.0   memory length: 283933   epsilon: 0.6358106800079062    steps: 199    lr: 4e-05     evaluation reward: 3.53\nepisode: 1410   score: 4.0   memory length: 284193   epsilon: 0.6352958800079174    steps: 260    lr: 4e-05     evaluation reward: 3.47\nepisode: 1411   score: 4.0   memory length: 284467   epsilon: 0.6347533600079291    steps: 274    lr: 4e-05     evaluation reward: 3.45\nepisode: 1412   score: 3.0   memory length: 284693   epsilon: 0.6343058800079389    steps: 226    lr: 4e-05     evaluation reward: 3.46\nepisode: 1413   score: 4.0   memory length: 284952   epsilon: 0.63379306000795    steps: 259    lr: 4e-05     evaluation reward: 3.46\nepisode: 1414   score: 2.0   memory length: 285134   epsilon: 0.6334327000079578    steps: 182    lr: 4e-05     evaluation reward: 3.47\nepisode: 1415   score: 6.0   memory length: 285505   epsilon: 0.6326981200079738    steps: 371    lr: 4e-05     evaluation reward: 3.46\nepisode: 1416   score: 2.0   memory length: 285687   epsilon: 0.6323377600079816    steps: 182    lr: 4e-05     evaluation reward: 3.44\nepisode: 1417   score: 5.0   memory length: 286012   epsilon: 0.6316942600079956    steps: 325    lr: 4e-05     evaluation reward: 3.45\nepisode: 1418   score: 4.0   memory length: 286253   epsilon: 0.6312170800080059    steps: 241    lr: 4e-05     evaluation reward: 3.46\nepisode: 1419   score: 2.0   memory length: 286435   epsilon: 0.6308567200080137    steps: 182    lr: 4e-05     evaluation reward: 3.46\nepisode: 1420   score: 2.0   memory length: 286614   epsilon: 0.6305023000080214    steps: 179    lr: 4e-05     evaluation reward: 3.46\nepisode: 1421   score: 5.0   memory length: 286958   epsilon: 0.6298211800080362    steps: 344    lr: 4e-05     evaluation reward: 3.48\nepisode: 1422   score: 2.0   memory length: 287156   epsilon: 0.6294291400080447    steps: 198    lr: 4e-05     evaluation reward: 3.45\nepisode: 1423   score: 2.0   memory length: 287356   epsilon: 0.6290331400080533    steps: 200    lr: 4e-05     evaluation reward: 3.42\nepisode: 1424   score: 5.0   memory length: 287661   epsilon: 0.6284292400080664    steps: 305    lr: 4e-05     evaluation reward: 3.43\nepisode: 1425   score: 2.0   memory length: 287843   epsilon: 0.6280688800080743    steps: 182    lr: 4e-05     evaluation reward: 3.41\nepisode: 1426   score: 5.0   memory length: 288148   epsilon: 0.6274649800080874    steps: 305    lr: 4e-05     evaluation reward: 3.43\nepisode: 1427   score: 7.0   memory length: 288499   epsilon: 0.6267700000081025    steps: 351    lr: 4e-05     evaluation reward: 3.47\nepisode: 1428   score: 3.0   memory length: 288725   epsilon: 0.6263225200081122    steps: 226    lr: 4e-05     evaluation reward: 3.47\nepisode: 1429   score: 3.0   memory length: 288956   epsilon: 0.6258651400081221    steps: 231    lr: 4e-05     evaluation reward: 3.49\nepisode: 1430   score: 4.0   memory length: 289231   epsilon: 0.6253206400081339    steps: 275    lr: 4e-05     evaluation reward: 3.49\nepisode: 1431   score: 7.0   memory length: 289650   epsilon: 0.6244910200081519    steps: 419    lr: 4e-05     evaluation reward: 3.53\nepisode: 1432   score: 4.0   memory length: 289929   epsilon: 0.6239386000081639    steps: 279    lr: 4e-05     evaluation reward: 3.52\nepisode: 1433   score: 2.0   memory length: 290111   epsilon: 0.6235782400081717    steps: 182    lr: 4e-05     evaluation reward: 3.51\nepisode: 1434   score: 5.0   memory length: 290390   epsilon: 0.6230258200081837    steps: 279    lr: 4e-05     evaluation reward: 3.52\nepisode: 1435   score: 3.0   memory length: 290637   epsilon: 0.6225367600081944    steps: 247    lr: 4e-05     evaluation reward: 3.52\nepisode: 1436   score: 3.0   memory length: 290867   epsilon: 0.6220813600082042    steps: 230    lr: 4e-05     evaluation reward: 3.52\nepisode: 1437   score: 6.0   memory length: 291207   epsilon: 0.6214081600082189    steps: 340    lr: 4e-05     evaluation reward: 3.53\nepisode: 1438   score: 4.0   memory length: 291483   epsilon: 0.6208616800082307    steps: 276    lr: 4e-05     evaluation reward: 3.55\nepisode: 1439   score: 3.0   memory length: 291734   epsilon: 0.6203647000082415    steps: 251    lr: 4e-05     evaluation reward: 3.52\nepisode: 1440   score: 2.0   memory length: 291916   epsilon: 0.6200043400082493    steps: 182    lr: 4e-05     evaluation reward: 3.5\nepisode: 1441   score: 4.0   memory length: 292156   epsilon: 0.6195291400082596    steps: 240    lr: 4e-05     evaluation reward: 3.52\nepisode: 1442   score: 3.0   memory length: 292384   epsilon: 0.6190777000082694    steps: 228    lr: 4e-05     evaluation reward: 3.51\nepisode: 1443   score: 6.0   memory length: 292722   epsilon: 0.618408460008284    steps: 338    lr: 4e-05     evaluation reward: 3.55\nepisode: 1444   score: 2.0   memory length: 292903   epsilon: 0.6180500800082918    steps: 181    lr: 4e-05     evaluation reward: 3.54\nepisode: 1445   score: 1.0   memory length: 293072   epsilon: 0.617715460008299    steps: 169    lr: 4e-05     evaluation reward: 3.47\nepisode: 1446   score: 2.0   memory length: 293252   epsilon: 0.6173590600083068    steps: 180    lr: 4e-05     evaluation reward: 3.45\nepisode: 1447   score: 2.0   memory length: 293432   epsilon: 0.6170026600083145    steps: 180    lr: 4e-05     evaluation reward: 3.43\nepisode: 1448   score: 4.0   memory length: 293707   epsilon: 0.6164581600083263    steps: 275    lr: 4e-05     evaluation reward: 3.45\nepisode: 1449   score: 4.0   memory length: 293967   epsilon: 0.6159433600083375    steps: 260    lr: 4e-05     evaluation reward: 3.48\nepisode: 1450   score: 4.0   memory length: 294244   epsilon: 0.6153949000083494    steps: 277    lr: 4e-05     evaluation reward: 3.46\nepisode: 1451   score: 7.0   memory length: 294649   epsilon: 0.6145930000083668    steps: 405    lr: 4e-05     evaluation reward: 3.5\nepisode: 1452   score: 6.0   memory length: 294980   epsilon: 0.613937620008381    steps: 331    lr: 4e-05     evaluation reward: 3.56\nepisode: 1453   score: 1.0   memory length: 295131   epsilon: 0.6136386400083875    steps: 151    lr: 4e-05     evaluation reward: 3.54\nepisode: 1454   score: 4.0   memory length: 295406   epsilon: 0.6130941400083993    steps: 275    lr: 4e-05     evaluation reward: 3.55\nepisode: 1455   score: 7.0   memory length: 295852   epsilon: 0.6122110600084185    steps: 446    lr: 4e-05     evaluation reward: 3.6\nepisode: 1456   score: 7.0   memory length: 296278   epsilon: 0.6113675800084368    steps: 426    lr: 4e-05     evaluation reward: 3.66\nepisode: 1457   score: 3.0   memory length: 296504   epsilon: 0.6109201000084465    steps: 226    lr: 4e-05     evaluation reward: 3.66\nepisode: 1458   score: 3.0   memory length: 296733   epsilon: 0.6104666800084564    steps: 229    lr: 4e-05     evaluation reward: 3.66\nepisode: 1459   score: 5.0   memory length: 297039   epsilon: 0.6098608000084695    steps: 306    lr: 4e-05     evaluation reward: 3.68\nepisode: 1460   score: 2.0   memory length: 297258   epsilon: 0.609427180008479    steps: 219    lr: 4e-05     evaluation reward: 3.64\nepisode: 1461   score: 2.0   memory length: 297476   epsilon: 0.6089955400084883    steps: 218    lr: 4e-05     evaluation reward: 3.59\nepisode: 1462   score: 2.0   memory length: 297658   epsilon: 0.6086351800084961    steps: 182    lr: 4e-05     evaluation reward: 3.59\nepisode: 1463   score: 5.0   memory length: 297986   epsilon: 0.6079857400085102    steps: 328    lr: 4e-05     evaluation reward: 3.63\nepisode: 1464   score: 1.0   memory length: 298137   epsilon: 0.6076867600085167    steps: 151    lr: 4e-05     evaluation reward: 3.6\nepisode: 1465   score: 3.0   memory length: 298367   epsilon: 0.6072313600085266    steps: 230    lr: 4e-05     evaluation reward: 3.58\nepisode: 1466   score: 6.0   memory length: 298724   epsilon: 0.606524500008542    steps: 357    lr: 4e-05     evaluation reward: 3.59\nepisode: 1467   score: 5.0   memory length: 299029   epsilon: 0.6059206000085551    steps: 305    lr: 4e-05     evaluation reward: 3.63\nepisode: 1468   score: 1.0   memory length: 299180   epsilon: 0.6056216200085616    steps: 151    lr: 4e-05     evaluation reward: 3.62\nepisode: 1469   score: 5.0   memory length: 299523   epsilon: 0.6049424800085763    steps: 343    lr: 4e-05     evaluation reward: 3.64\nepisode: 1470   score: 2.0   memory length: 299721   epsilon: 0.6045504400085848    steps: 198    lr: 4e-05     evaluation reward: 3.63\nepisode: 1471   score: 4.0   memory length: 299980   epsilon: 0.604037620008596    steps: 259    lr: 4e-05     evaluation reward: 3.63\nepisode: 1472   score: 2.0   memory length: 300160   epsilon: 0.6036812200086037    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.65\nepisode: 1473   score: 8.0   memory length: 300608   epsilon: 0.602794180008623    steps: 448    lr: 1.6000000000000003e-05     evaluation reward: 3.71\nepisode: 1474   score: 6.0   memory length: 300942   epsilon: 0.6021328600086373    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 3.72\nepisode: 1475   score: 4.0   memory length: 301201   epsilon: 0.6016200400086484    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.73\nepisode: 1476   score: 6.0   memory length: 301579   epsilon: 0.6008716000086647    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 3.76\nepisode: 1477   score: 10.0   memory length: 301970   epsilon: 0.6000974200086815    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 3.84\nepisode: 1478   score: 4.0   memory length: 302245   epsilon: 0.5995529200086933    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.83\nepisode: 1479   score: 3.0   memory length: 302470   epsilon: 0.599107420008703    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.83\nepisode: 1480   score: 1.0   memory length: 302621   epsilon: 0.5988084400087095    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.79\nepisode: 1481   score: 5.0   memory length: 302930   epsilon: 0.5981966200087228    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.8\nepisode: 1482   score: 4.0   memory length: 303172   epsilon: 0.5977174600087332    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 3.79\nepisode: 1483   score: 3.0   memory length: 303401   epsilon: 0.597264040008743    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.78\nepisode: 1484   score: 4.0   memory length: 303678   epsilon: 0.5967155800087549    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.78\nepisode: 1485   score: 7.0   memory length: 304065   epsilon: 0.5959493200087715    steps: 387    lr: 1.6000000000000003e-05     evaluation reward: 3.8\nepisode: 1486   score: 5.0   memory length: 304352   epsilon: 0.5953810600087839    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 3.82\nepisode: 1487   score: 4.0   memory length: 304629   epsilon: 0.5948326000087958    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.82\nepisode: 1488   score: 4.0   memory length: 304888   epsilon: 0.5943197800088069    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.82\nepisode: 1489   score: 7.0   memory length: 305293   epsilon: 0.5935178800088243    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 3.85\nepisode: 1490   score: 5.0   memory length: 305604   epsilon: 0.5929021000088377    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 3.84\nepisode: 1491   score: 5.0   memory length: 305899   epsilon: 0.5923180000088504    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.87\nepisode: 1492   score: 3.0   memory length: 306127   epsilon: 0.5918665600088602    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.87\nepisode: 1493   score: 2.0   memory length: 306306   epsilon: 0.5915121400088679    steps: 179    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1494   score: 3.0   memory length: 306535   epsilon: 0.5910587200088777    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.84\nepisode: 1495   score: 3.0   memory length: 306765   epsilon: 0.5906033200088876    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.85\nepisode: 1496   score: 5.0   memory length: 307071   epsilon: 0.5899974400089008    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1497   score: 5.0   memory length: 307359   epsilon: 0.5894272000089131    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1498   score: 4.0   memory length: 307640   epsilon: 0.5888708200089252    steps: 281    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1499   score: 4.0   memory length: 307902   epsilon: 0.5883520600089365    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1500   score: 4.0   memory length: 308184   epsilon: 0.5877937000089486    steps: 282    lr: 1.6000000000000003e-05     evaluation reward: 3.86\nepisode: 1501   score: 2.0   memory length: 308366   epsilon: 0.5874333400089564    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.84\nepisode: 1502   score: 5.0   memory length: 308672   epsilon: 0.5868274600089696    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 3.87\nepisode: 1503   score: 6.0   memory length: 308988   epsilon: 0.5862017800089832    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 3.9\nepisode: 1504   score: 4.0   memory length: 309281   epsilon: 0.5856216400089957    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.91\nepisode: 1505   score: 5.0   memory length: 309605   epsilon: 0.5849801200090097    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.95\nepisode: 1506   score: 6.0   memory length: 309996   epsilon: 0.5842059400090265    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 3.95\nepisode: 1507   score: 0.0   memory length: 310119   epsilon: 0.5839624000090318    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.91\nepisode: 1508   score: 4.0   memory length: 310359   epsilon: 0.5834872000090421    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 3.92\nepisode: 1509   score: 3.0   memory length: 310570   epsilon: 0.5830694200090512    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.93\nepisode: 1510   score: 4.0   memory length: 310867   epsilon: 0.5824813600090639    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.93\nepisode: 1511   score: 5.0   memory length: 311180   epsilon: 0.5818616200090774    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 3.94\nepisode: 1512   score: 10.0   memory length: 311637   epsilon: 0.580956760009097    steps: 457    lr: 1.6000000000000003e-05     evaluation reward: 4.01\nepisode: 1513   score: 3.0   memory length: 311867   epsilon: 0.5805013600091069    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.0\nepisode: 1514   score: 6.0   memory length: 312233   epsilon: 0.5797766800091226    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 4.04\nepisode: 1515   score: 4.0   memory length: 312493   epsilon: 0.5792618800091338    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.02\nepisode: 1516   score: 3.0   memory length: 312719   epsilon: 0.5788144000091435    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.03\nepisode: 1517   score: 3.0   memory length: 312968   epsilon: 0.5783213800091542    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.01\nepisode: 1518   score: 2.0   memory length: 313186   epsilon: 0.5778897400091636    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.99\nepisode: 1519   score: 5.0   memory length: 313491   epsilon: 0.5772858400091767    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.02\nepisode: 1520   score: 6.0   memory length: 313847   epsilon: 0.576580960009192    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.06\nepisode: 1521   score: 0.0   memory length: 313970   epsilon: 0.5763374200091973    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 4.01\nepisode: 1522   score: 6.0   memory length: 314310   epsilon: 0.5756642200092119    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.05\nepisode: 1523   score: 6.0   memory length: 314645   epsilon: 0.5750009200092263    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 4.09\nepisode: 1524   score: 5.0   memory length: 314962   epsilon: 0.5743732600092399    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 4.09\nepisode: 1525   score: 6.0   memory length: 315306   epsilon: 0.5736921400092547    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.13\nepisode: 1526   score: 3.0   memory length: 315550   epsilon: 0.5732090200092652    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.11\nepisode: 1527   score: 3.0   memory length: 315798   epsilon: 0.5727179800092759    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.07\nepisode: 1528   score: 2.0   memory length: 315998   epsilon: 0.5723219800092845    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.06\nepisode: 1529   score: 5.0   memory length: 316305   epsilon: 0.5717141200092977    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.08\nepisode: 1530   score: 5.0   memory length: 316613   epsilon: 0.5711042800093109    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.09\nepisode: 1531   score: 3.0   memory length: 316878   epsilon: 0.5705795800093223    steps: 265    lr: 1.6000000000000003e-05     evaluation reward: 4.05\nepisode: 1532   score: 5.0   memory length: 317200   epsilon: 0.5699420200093361    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 4.06\nepisode: 1533   score: 4.0   memory length: 317461   epsilon: 0.5694252400093474    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.08\nepisode: 1534   score: 3.0   memory length: 317726   epsilon: 0.5689005400093587    steps: 265    lr: 1.6000000000000003e-05     evaluation reward: 4.06\nepisode: 1535   score: 8.0   memory length: 318126   epsilon: 0.5681085400093759    steps: 400    lr: 1.6000000000000003e-05     evaluation reward: 4.11\nepisode: 1536   score: 3.0   memory length: 318354   epsilon: 0.5676571000093857    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.11\nepisode: 1537   score: 2.0   memory length: 318554   epsilon: 0.5672611000093943    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.07\nepisode: 1538   score: 4.0   memory length: 318831   epsilon: 0.5667126400094062    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.07\nepisode: 1539   score: 2.0   memory length: 319013   epsilon: 0.5663522800094141    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.06\nepisode: 1540   score: 9.0   memory length: 319514   epsilon: 0.5653603000094356    steps: 501    lr: 1.6000000000000003e-05     evaluation reward: 4.13\nepisode: 1541   score: 2.0   memory length: 319714   epsilon: 0.5649643000094442    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.11\nepisode: 1542   score: 1.0   memory length: 319885   epsilon: 0.5646257200094515    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 4.09\nepisode: 1543   score: 5.0   memory length: 320175   epsilon: 0.564051520009464    steps: 290    lr: 1.6000000000000003e-05     evaluation reward: 4.08\nepisode: 1544   score: 5.0   memory length: 320481   epsilon: 0.5634456400094772    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.11\nepisode: 1545   score: 5.0   memory length: 320810   epsilon: 0.5627942200094913    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.15\nepisode: 1546   score: 3.0   memory length: 321020   epsilon: 0.5623784200095003    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.16\nepisode: 1547   score: 6.0   memory length: 321382   epsilon: 0.5616616600095159    steps: 362    lr: 1.6000000000000003e-05     evaluation reward: 4.2\nepisode: 1548   score: 1.0   memory length: 321553   epsilon: 0.5613230800095232    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1549   score: 4.0   memory length: 321833   epsilon: 0.5607686800095353    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1550   score: 6.0   memory length: 322174   epsilon: 0.5600935000095499    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 4.19\nepisode: 1551   score: 1.0   memory length: 322345   epsilon: 0.5597549200095573    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 4.13\nepisode: 1552   score: 5.0   memory length: 322689   epsilon: 0.5590738000095721    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.12\nepisode: 1553   score: 4.0   memory length: 322965   epsilon: 0.5585273200095839    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.15\nepisode: 1554   score: 2.0   memory length: 323147   epsilon: 0.5581669600095918    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.13\nepisode: 1555   score: 1.0   memory length: 323298   epsilon: 0.5578679800095983    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.07\nepisode: 1556   score: 4.0   memory length: 323599   epsilon: 0.5572720000096112    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 4.04\nepisode: 1557   score: 2.0   memory length: 323822   epsilon: 0.5568304600096208    steps: 223    lr: 1.6000000000000003e-05     evaluation reward: 4.03\nepisode: 1558   score: 4.0   memory length: 324063   epsilon: 0.5563532800096311    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 4.04\nepisode: 1559   score: 5.0   memory length: 324410   epsilon: 0.555666220009646    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 4.04\nepisode: 1560   score: 3.0   memory length: 324642   epsilon: 0.555206860009656    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 4.05\nepisode: 1561   score: 4.0   memory length: 324938   epsilon: 0.5546207800096687    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.07\nepisode: 1562   score: 5.0   memory length: 325268   epsilon: 0.5539673800096829    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.1\nepisode: 1563   score: 6.0   memory length: 325607   epsilon: 0.5532961600096975    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 4.11\nepisode: 1564   score: 4.0   memory length: 325885   epsilon: 0.5527457200097095    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.14\nepisode: 1565   score: 8.0   memory length: 326336   epsilon: 0.5518527400097288    steps: 451    lr: 1.6000000000000003e-05     evaluation reward: 4.19\nepisode: 1566   score: 4.0   memory length: 326614   epsilon: 0.5513023000097408    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1567   score: 4.0   memory length: 326910   epsilon: 0.5507162200097535    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.16\nepisode: 1568   score: 6.0   memory length: 327280   epsilon: 0.5499836200097694    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 4.21\nepisode: 1569   score: 9.0   memory length: 327703   epsilon: 0.5491460800097876    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.25\nepisode: 1570   score: 3.0   memory length: 327916   epsilon: 0.5487243400097968    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.26\nepisode: 1571   score: 5.0   memory length: 328226   epsilon: 0.5481105400098101    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.27\nepisode: 1572   score: 2.0   memory length: 328424   epsilon: 0.5477185000098186    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.27\nepisode: 1573   score: 3.0   memory length: 328654   epsilon: 0.5472631000098285    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.22\nepisode: 1574   score: 4.0   memory length: 328896   epsilon: 0.5467839400098389    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.2\nepisode: 1575   score: 5.0   memory length: 329204   epsilon: 0.5461741000098521    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.21\nepisode: 1576   score: 4.0   memory length: 329466   epsilon: 0.5456553400098634    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.19\nepisode: 1577   score: 7.0   memory length: 329911   epsilon: 0.5447742400098825    steps: 445    lr: 1.6000000000000003e-05     evaluation reward: 4.16\nepisode: 1578   score: 5.0   memory length: 330200   epsilon: 0.5442020200098949    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1579   score: 6.0   memory length: 330578   epsilon: 0.5434535800099112    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 4.2\nepisode: 1580   score: 6.0   memory length: 330906   epsilon: 0.5428041400099253    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.25\nepisode: 1581   score: 1.0   memory length: 331056   epsilon: 0.5425071400099317    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.21\nepisode: 1582   score: 6.0   memory length: 331412   epsilon: 0.541802260009947    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.23\nepisode: 1583   score: 6.0   memory length: 331773   epsilon: 0.5410874800099625    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 4.26\nepisode: 1584   score: 2.0   memory length: 331971   epsilon: 0.540695440009971    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.24\nepisode: 1585   score: 6.0   memory length: 332331   epsilon: 0.5399826400099865    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 4.23\nepisode: 1586   score: 2.0   memory length: 332513   epsilon: 0.5396222800099943    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.2\nepisode: 1587   score: 5.0   memory length: 332804   epsilon: 0.5390461000100069    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.21\nepisode: 1588   score: 3.0   memory length: 333032   epsilon: 0.5385946600100167    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.2\nepisode: 1589   score: 4.0   memory length: 333312   epsilon: 0.5380402600100287    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1590   score: 3.0   memory length: 333538   epsilon: 0.5375927800100384    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.15\nepisode: 1591   score: 3.0   memory length: 333766   epsilon: 0.5371413400100482    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.13\nepisode: 1592   score: 4.0   memory length: 334026   epsilon: 0.5366265400100594    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.14\nepisode: 1593   score: 5.0   memory length: 334318   epsilon: 0.5360483800100719    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1594   score: 8.0   memory length: 334741   epsilon: 0.5352108400100901    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.22\nepisode: 1595   score: 2.0   memory length: 334938   epsilon: 0.5348207800100986    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 4.21\nepisode: 1596   score: 2.0   memory length: 335138   epsilon: 0.5344247800101072    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.18\nepisode: 1597   score: 2.0   memory length: 335320   epsilon: 0.534064420010115    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.15\nepisode: 1598   score: 6.0   memory length: 335659   epsilon: 0.5333932000101296    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1599   score: 5.0   memory length: 336008   epsilon: 0.5327021800101446    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 4.18\nepisode: 1600   score: 4.0   memory length: 336284   epsilon: 0.5321557000101564    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.18\nepisode: 1601   score: 3.0   memory length: 336535   epsilon: 0.5316587200101672    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 4.19\nepisode: 1602   score: 3.0   memory length: 336779   epsilon: 0.5311756000101777    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1603   score: 3.0   memory length: 337010   epsilon: 0.5307182200101876    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.14\nepisode: 1604   score: 5.0   memory length: 337324   epsilon: 0.5300965000102011    steps: 314    lr: 1.6000000000000003e-05     evaluation reward: 4.15\nepisode: 1605   score: 7.0   memory length: 337714   epsilon: 0.5293243000102179    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 4.17\nepisode: 1606   score: 7.0   memory length: 338140   epsilon: 0.5284808200102362    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 4.18\nepisode: 1607   score: 5.0   memory length: 338438   epsilon: 0.527890780010249    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 4.23\nepisode: 1608   score: 8.0   memory length: 338897   epsilon: 0.5269819600102688    steps: 459    lr: 1.6000000000000003e-05     evaluation reward: 4.27\nepisode: 1609   score: 2.0   memory length: 339078   epsilon: 0.5266235800102765    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.26\nepisode: 1610   score: 5.0   memory length: 339403   epsilon: 0.5259800800102905    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.27\nepisode: 1611   score: 10.0   memory length: 339811   epsilon: 0.525172240010308    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 4.32\nepisode: 1612   score: 5.0   memory length: 340139   epsilon: 0.5245228000103221    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.27\nepisode: 1613   score: 4.0   memory length: 340416   epsilon: 0.523974340010334    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.28\nepisode: 1614   score: 3.0   memory length: 340644   epsilon: 0.5235229000103439    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.25\nepisode: 1615   score: 4.0   memory length: 340904   epsilon: 0.523008100010355    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.25\nepisode: 1616   score: 11.0   memory length: 341375   epsilon: 0.5220755200103753    steps: 471    lr: 1.6000000000000003e-05     evaluation reward: 4.33\nepisode: 1617   score: 4.0   memory length: 341617   epsilon: 0.5215963600103857    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.34\nepisode: 1618   score: 5.0   memory length: 341961   epsilon: 0.5209152400104005    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1619   score: 6.0   memory length: 342370   epsilon: 0.520105420010418    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1620   score: 6.0   memory length: 342725   epsilon: 0.5194025200104333    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1621   score: 1.0   memory length: 342877   epsilon: 0.5191015600104398    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1622   score: 10.0   memory length: 343267   epsilon: 0.5183293600104566    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1623   score: 5.0   memory length: 343571   epsilon: 0.5177274400104697    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1624   score: 3.0   memory length: 343798   epsilon: 0.5172779800104794    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1625   score: 2.0   memory length: 343980   epsilon: 0.5169176200104872    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1626   score: 4.0   memory length: 344254   epsilon: 0.516375100010499    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1627   score: 3.0   memory length: 344465   epsilon: 0.5159573200105081    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1628   score: 3.0   memory length: 344678   epsilon: 0.5155355800105172    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1629   score: 13.0   memory length: 345191   epsilon: 0.5145198400105393    steps: 513    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1630   score: 5.0   memory length: 345534   epsilon: 0.513840700010554    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1631   score: 3.0   memory length: 345781   epsilon: 0.5133516400105647    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1632   score: 7.0   memory length: 346204   epsilon: 0.5125141000105828    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.48\nepisode: 1633   score: 2.0   memory length: 346402   epsilon: 0.5121220600105914    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1634   score: 7.0   memory length: 346792   epsilon: 0.5113498600106081    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 4.5\nepisode: 1635   score: 3.0   memory length: 347061   epsilon: 0.5108172400106197    steps: 269    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1636   score: 4.0   memory length: 347336   epsilon: 0.5102727400106315    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1637   score: 3.0   memory length: 347583   epsilon: 0.5097836800106421    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.47\nepisode: 1638   score: 1.0   memory length: 347754   epsilon: 0.5094451000106495    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1639   score: 5.0   memory length: 348078   epsilon: 0.5088035800106634    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.47\nepisode: 1640   score: 4.0   memory length: 348374   epsilon: 0.5082175000106761    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1641   score: 6.0   memory length: 348699   epsilon: 0.5075740000106901    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1642   score: 3.0   memory length: 348931   epsilon: 0.5071146400107001    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 4.48\nepisode: 1643   score: 2.0   memory length: 349113   epsilon: 0.5067542800107079    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1644   score: 2.0   memory length: 349293   epsilon: 0.5063978800107156    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1645   score: 5.0   memory length: 349622   epsilon: 0.5057464600107298    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1646   score: 2.0   memory length: 349803   epsilon: 0.5053880800107375    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1647   score: 5.0   memory length: 350112   epsilon: 0.5047762600107508    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1648   score: 2.0   memory length: 350311   epsilon: 0.5043822400107594    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1649   score: 6.0   memory length: 350683   epsilon: 0.5036456800107754    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1650   score: 5.0   memory length: 351015   epsilon: 0.5029883200107896    steps: 332    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1651   score: 3.0   memory length: 351261   epsilon: 0.5025012400108002    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1652   score: 4.0   memory length: 351505   epsilon: 0.5020181200108107    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1653   score: 3.0   memory length: 351753   epsilon: 0.5015270800108214    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1654   score: 3.0   memory length: 351966   epsilon: 0.5011053400108305    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1655   score: 2.0   memory length: 352148   epsilon: 0.5007449800108383    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1656   score: 5.0   memory length: 352440   epsilon: 0.5001668200108509    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1657   score: 2.0   memory length: 352642   epsilon: 0.499766860010853    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1658   score: 3.0   memory length: 352854   epsilon: 0.49934710001085036    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1659   score: 2.0   memory length: 353073   epsilon: 0.4989134800108476    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1660   score: 7.0   memory length: 353445   epsilon: 0.49817692001084296    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1661   score: 3.0   memory length: 353692   epsilon: 0.49768786001083987    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1662   score: 4.0   memory length: 353951   epsilon: 0.4971750400108366    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1663   score: 3.0   memory length: 354200   epsilon: 0.4966820200108335    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1664   score: 6.0   memory length: 354552   epsilon: 0.4959850600108291    steps: 352    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1665   score: 5.0   memory length: 354861   epsilon: 0.4953732400108252    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1666   score: 5.0   memory length: 355149   epsilon: 0.4948030000108216    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1667   score: 6.0   memory length: 355522   epsilon: 0.49406446001081694    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1668   score: 7.0   memory length: 355936   epsilon: 0.49324474001081176    steps: 414    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1669   score: 2.0   memory length: 356134   epsilon: 0.4928527000108093    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1670   score: 4.0   memory length: 356394   epsilon: 0.492337900010806    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1671   score: 4.0   memory length: 356695   epsilon: 0.49174192001080225    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1672   score: 5.0   memory length: 357020   epsilon: 0.4910984200107982    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1673   score: 3.0   memory length: 357230   epsilon: 0.49068262001079554    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1674   score: 3.0   memory length: 357459   epsilon: 0.4902292000107927    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1675   score: 5.0   memory length: 357768   epsilon: 0.4896173800107888    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1676   score: 6.0   memory length: 358123   epsilon: 0.48891448001078436    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1677   score: 3.0   memory length: 358336   epsilon: 0.4884927400107817    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1678   score: 4.0   memory length: 358596   epsilon: 0.48797794001077843    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.35\nepisode: 1679   score: 6.0   memory length: 358934   epsilon: 0.4873087000107742    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.35\nepisode: 1680   score: 7.0   memory length: 359309   epsilon: 0.4865662000107695    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1681   score: 3.0   memory length: 359562   epsilon: 0.48606526001076633    steps: 253    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1682   score: 6.0   memory length: 359880   epsilon: 0.48543562001076235    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1683   score: 5.0   memory length: 360205   epsilon: 0.4847921200107583    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1684   score: 3.0   memory length: 360452   epsilon: 0.4843030600107552    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1685   score: 1.0   memory length: 360604   epsilon: 0.4840021000107533    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.33\nepisode: 1686   score: 4.0   memory length: 360880   epsilon: 0.4834556200107498    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.35\nepisode: 1687   score: 7.0   memory length: 361286   epsilon: 0.48265174001074473    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1688   score: 6.0   memory length: 361643   epsilon: 0.48194488001074026    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1689   score: 4.0   memory length: 361883   epsilon: 0.48146968001073726    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1690   score: 3.0   memory length: 362132   epsilon: 0.48097666001073414    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1691   score: 5.0   memory length: 362442   epsilon: 0.48036286001073025    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1692   score: 7.0   memory length: 362823   epsilon: 0.4796084800107255    steps: 381    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1693   score: 5.0   memory length: 363111   epsilon: 0.47903824001072187    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1694   score: 5.0   memory length: 363382   epsilon: 0.4785016600107185    steps: 271    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1695   score: 5.0   memory length: 363685   epsilon: 0.4779017200107147    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1696   score: 6.0   memory length: 364006   epsilon: 0.47726614001071066    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1697   score: 2.0   memory length: 364188   epsilon: 0.4769057800107084    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1698   score: 2.0   memory length: 364370   epsilon: 0.4765454200107061    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1699   score: 3.0   memory length: 364600   epsilon: 0.4760900200107032    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1700   score: 0.0   memory length: 364723   epsilon: 0.4758464800107017    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1701   score: 7.0   memory length: 365115   epsilon: 0.47507032001069677    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1702   score: 6.0   memory length: 365444   epsilon: 0.47441890001069265    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1703   score: 4.0   memory length: 365687   epsilon: 0.4739377600106896    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 4.47\nepisode: 1704   score: 9.0   memory length: 366187   epsilon: 0.47294776001068334    steps: 500    lr: 1.6000000000000003e-05     evaluation reward: 4.51\nepisode: 1705   score: 5.0   memory length: 366494   epsilon: 0.4723399000106795    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1706   score: 4.0   memory length: 366736   epsilon: 0.47186074001067646    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.46\nepisode: 1707   score: 1.0   memory length: 366888   epsilon: 0.47155978001067456    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1708   score: 5.0   memory length: 367212   epsilon: 0.4709182600106705    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1709   score: 5.0   memory length: 367482   epsilon: 0.4703836600106671    steps: 270    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1710   score: 7.0   memory length: 367894   epsilon: 0.46956790001066195    steps: 412    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1711   score: 3.0   memory length: 368122   epsilon: 0.4691164600106591    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1712   score: 2.0   memory length: 368324   epsilon: 0.46871650001065657    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 4.34\nepisode: 1713   score: 6.0   memory length: 368697   epsilon: 0.4679779600106519    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1714   score: 9.0   memory length: 369132   epsilon: 0.46711666001064645    steps: 435    lr: 1.6000000000000003e-05     evaluation reward: 4.42\nepisode: 1715   score: 3.0   memory length: 369342   epsilon: 0.4667008600106438    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1716   score: 4.0   memory length: 369584   epsilon: 0.4662217000106408    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.34\nepisode: 1717   score: 6.0   memory length: 369940   epsilon: 0.4655168200106363    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1718   score: 2.0   memory length: 370160   epsilon: 0.46508122001063357    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 4.33\nepisode: 1719   score: 7.0   memory length: 370579   epsilon: 0.4642516000106283    steps: 419    lr: 1.6000000000000003e-05     evaluation reward: 4.34\nepisode: 1720   score: 6.0   memory length: 370936   epsilon: 0.46354474001062385    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.34\nepisode: 1721   score: 4.0   memory length: 371233   epsilon: 0.4629566800106201    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1722   score: 5.0   memory length: 371560   epsilon: 0.46230922001061603    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.32\nepisode: 1723   score: 10.0   memory length: 371975   epsilon: 0.46148752001061083    steps: 415    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1724   score: 6.0   memory length: 372297   epsilon: 0.4608499600106068    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1725   score: 3.0   memory length: 372507   epsilon: 0.46043416001060417    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1726   score: 6.0   memory length: 372861   epsilon: 0.45973324001059973    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1727   score: 3.0   memory length: 373091   epsilon: 0.45927784001059685    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1728   score: 5.0   memory length: 373395   epsilon: 0.45867592001059304    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 4.45\nepisode: 1729   score: 4.0   memory length: 373658   epsilon: 0.45815518001058975    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1730   score: 5.0   memory length: 373988   epsilon: 0.4575017800105856    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1731   score: 3.0   memory length: 374199   epsilon: 0.45708400001058297    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.36\nepisode: 1732   score: 4.0   memory length: 374478   epsilon: 0.4565315800105795    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.33\nepisode: 1733   score: 2.0   memory length: 374679   epsilon: 0.45613360001057696    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 4.33\nepisode: 1734   score: 4.0   memory length: 374975   epsilon: 0.45554752001057325    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.3\nepisode: 1735   score: 5.0   memory length: 375250   epsilon: 0.4550030200105698    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.32\nepisode: 1736   score: 4.0   memory length: 375492   epsilon: 0.45452386001056677    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.32\nepisode: 1737   score: 10.0   memory length: 375900   epsilon: 0.45371602001056166    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1738   score: 3.0   memory length: 376126   epsilon: 0.45326854001055883    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1739   score: 4.0   memory length: 376368   epsilon: 0.4527893800105558    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.4\nepisode: 1740   score: 5.0   memory length: 376674   epsilon: 0.45218350001055196    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.41\nepisode: 1741   score: 2.0   memory length: 376856   epsilon: 0.4518231400105497    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.37\nepisode: 1742   score: 4.0   memory length: 377116   epsilon: 0.4513083400105464    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.38\nepisode: 1743   score: 3.0   memory length: 377326   epsilon: 0.4508925400105438    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.39\nepisode: 1744   score: 7.0   memory length: 377713   epsilon: 0.45012628001053895    steps: 387    lr: 1.6000000000000003e-05     evaluation reward: 4.44\nepisode: 1745   score: 4.0   memory length: 377991   epsilon: 0.44957584001053547    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.43\nepisode: 1746   score: 9.0   memory length: 378499   epsilon: 0.4485700000105291    steps: 508    lr: 1.6000000000000003e-05     evaluation reward: 4.5\nepisode: 1747   score: 4.0   memory length: 378795   epsilon: 0.4479839200105254    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.49\nepisode: 1748   score: 7.0   memory length: 379184   epsilon: 0.4472137000105205    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 4.54\nepisode: 1749   score: 5.0   memory length: 379475   epsilon: 0.4466375200105169    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1750   score: 6.0   memory length: 379830   epsilon: 0.44593462001051243    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.54\nepisode: 1751   score: 8.0   memory length: 380248   epsilon: 0.4451069800105072    steps: 418    lr: 1.6000000000000003e-05     evaluation reward: 4.59\nepisode: 1752   score: 4.0   memory length: 380524   epsilon: 0.44456050001050373    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.59\nepisode: 1753   score: 7.0   memory length: 380887   epsilon: 0.4438417600104992    steps: 363    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1754   score: 5.0   memory length: 381210   epsilon: 0.44320222001049514    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1755   score: 5.0   memory length: 381499   epsilon: 0.4426300000104915    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.68\nepisode: 1756   score: 2.0   memory length: 381697   epsilon: 0.44223796001048904    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1757   score: 4.0   memory length: 381971   epsilon: 0.4416954400104856    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1758   score: 1.0   memory length: 382121   epsilon: 0.44139844001048373    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1759   score: 3.0   memory length: 382332   epsilon: 0.4409806600104811    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1760   score: 4.0   memory length: 382628   epsilon: 0.4403945800104774    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1761   score: 4.0   memory length: 382882   epsilon: 0.4398916600104742    steps: 254    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1762   score: 3.0   memory length: 383092   epsilon: 0.43947586001047156    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1763   score: 4.0   memory length: 383367   epsilon: 0.4389313600104681    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1764   score: 7.0   memory length: 383772   epsilon: 0.43812946001046305    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1765   score: 7.0   memory length: 384199   epsilon: 0.4372840000104577    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1766   score: 7.0   memory length: 384644   epsilon: 0.4364029000104521    steps: 445    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1767   score: 2.0   memory length: 384825   epsilon: 0.43604452001044985    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1768   score: 3.0   memory length: 385055   epsilon: 0.435589120010447    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.61\nepisode: 1769   score: 5.0   memory length: 385379   epsilon: 0.4349476000104429    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1770   score: 2.0   memory length: 385579   epsilon: 0.4345516000104404    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.62\nepisode: 1771   score: 3.0   memory length: 385807   epsilon: 0.43410016001043755    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.61\nepisode: 1772   score: 3.0   memory length: 386036   epsilon: 0.4336467400104347    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.59\nepisode: 1773   score: 9.0   memory length: 386556   epsilon: 0.43261714001042817    steps: 520    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1774   score: 5.0   memory length: 386863   epsilon: 0.4320092800104243    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1775   score: 7.0   memory length: 387249   epsilon: 0.4312450000104195    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1776   score: 2.0   memory length: 387450   epsilon: 0.43084702001041697    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1777   score: 6.0   memory length: 387797   epsilon: 0.4301599600104126    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 4.68\nepisode: 1778   score: 3.0   memory length: 388004   epsilon: 0.42975010001041003    steps: 207    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1779   score: 3.0   memory length: 388251   epsilon: 0.42926104001040694    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1780   score: 5.0   memory length: 388558   epsilon: 0.4286531800104031    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.62\nepisode: 1781   score: 7.0   memory length: 388989   epsilon: 0.4277998000103977    steps: 431    lr: 1.6000000000000003e-05     evaluation reward: 4.66\nepisode: 1782   score: 5.0   memory length: 389277   epsilon: 0.4272295600103941    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1783   score: 2.0   memory length: 389475   epsilon: 0.4268375200103916    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.62\nepisode: 1784   score: 4.0   memory length: 389754   epsilon: 0.4262851000103881    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1785   score: 6.0   memory length: 390092   epsilon: 0.4256158600103839    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.68\nepisode: 1786   score: 6.0   memory length: 390408   epsilon: 0.4249901800103799    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1787   score: 2.0   memory length: 390590   epsilon: 0.42462982001037763    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1788   score: 6.0   memory length: 390945   epsilon: 0.4239269200103732    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.65\nepisode: 1789   score: 2.0   memory length: 391127   epsilon: 0.4235665600103709    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1790   score: 2.0   memory length: 391308   epsilon: 0.42320818001036864    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.62\nepisode: 1791   score: 2.0   memory length: 391489   epsilon: 0.4228498000103664    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.59\nepisode: 1792   score: 4.0   memory length: 391731   epsilon: 0.42237064001036334    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.56\nepisode: 1793   score: 2.0   memory length: 391913   epsilon: 0.42201028001036106    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1794   score: 7.0   memory length: 392318   epsilon: 0.421208380010356    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 4.55\nepisode: 1795   score: 4.0   memory length: 392595   epsilon: 0.4206599200103525    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.54\nepisode: 1796   score: 4.0   memory length: 392853   epsilon: 0.4201490800103493    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.52\nepisode: 1797   score: 3.0   memory length: 393085   epsilon: 0.4196897200103464    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 4.53\nepisode: 1798   score: 4.0   memory length: 393361   epsilon: 0.4191432400103429    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.55\nepisode: 1799   score: 8.0   memory length: 393792   epsilon: 0.4182898600103375    steps: 431    lr: 1.6000000000000003e-05     evaluation reward: 4.6\nepisode: 1800   score: 7.0   memory length: 394167   epsilon: 0.4175473600103328    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1801   score: 3.0   memory length: 394377   epsilon: 0.4171315600103302    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.63\nepisode: 1802   score: 10.0   memory length: 394805   epsilon: 0.41628412001032483    steps: 428    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1803   score: 4.0   memory length: 395060   epsilon: 0.41577922001032164    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 4.67\nepisode: 1804   score: 6.0   memory length: 395383   epsilon: 0.4151396800103176    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1805   score: 5.0   memory length: 395665   epsilon: 0.41458132001031406    steps: 282    lr: 1.6000000000000003e-05     evaluation reward: 4.64\nepisode: 1806   score: 10.0   memory length: 396150   epsilon: 0.413621020010308    steps: 485    lr: 1.6000000000000003e-05     evaluation reward: 4.7\nepisode: 1807   score: 7.0   memory length: 396553   epsilon: 0.41282308001030293    steps: 403    lr: 1.6000000000000003e-05     evaluation reward: 4.76\nepisode: 1808   score: 4.0   memory length: 396832   epsilon: 0.41227066001029944    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.75\nepisode: 1809   score: 6.0   memory length: 397183   epsilon: 0.41157568001029504    steps: 351    lr: 1.6000000000000003e-05     evaluation reward: 4.76\nepisode: 1810   score: 5.0   memory length: 397507   epsilon: 0.410934160010291    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.74\nepisode: 1811   score: 11.0   memory length: 397981   epsilon: 0.40999564001028505    steps: 474    lr: 1.6000000000000003e-05     evaluation reward: 4.82\nepisode: 1812   score: 2.0   memory length: 398161   epsilon: 0.4096392400102828    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.82\nepisode: 1813   score: 4.0   memory length: 398421   epsilon: 0.40912444001027953    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.8\nepisode: 1814   score: 4.0   memory length: 398706   epsilon: 0.40856014001027596    steps: 285    lr: 1.6000000000000003e-05     evaluation reward: 4.75\nepisode: 1815   score: 2.0   memory length: 398904   epsilon: 0.4081681000102735    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.74\nepisode: 1816   score: 3.0   memory length: 399132   epsilon: 0.4077166600102706    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.73\nepisode: 1817   score: 2.0   memory length: 399332   epsilon: 0.4073206600102681    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.69\nepisode: 1818   score: 7.0   memory length: 399760   epsilon: 0.40647322001026276    steps: 428    lr: 1.6000000000000003e-05     evaluation reward: 4.74\nepisode: 1819   score: 5.0   memory length: 400090   epsilon: 0.4058198200102586    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 4.72\nepisode: 1820   score: 8.0   memory length: 400544   epsilon: 0.40492090001025294    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 4.74\nepisode: 1826   score: 7.0   memory length: 402406   epsilon: 0.4012341400102296    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 4.7\nepisode: 1827   score: 6.0   memory length: 402745   epsilon: 0.40056292001022537    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.73\nepisode: 1828   score: 4.0   memory length: 403030   epsilon: 0.3999986200102218    steps: 285    lr: 6.400000000000001e-06     evaluation reward: 4.72\nepisode: 1829   score: 2.0   memory length: 403211   epsilon: 0.3996402400102195    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.7\nepisode: 1830   score: 4.0   memory length: 403470   epsilon: 0.3991274200102163    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.69\nepisode: 1831   score: 6.0   memory length: 403846   epsilon: 0.3983829400102116    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.72\nepisode: 1832   score: 3.0   memory length: 404060   epsilon: 0.3979592200102089    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 4.71\nepisode: 1833   score: 5.0   memory length: 404387   epsilon: 0.3973117600102048    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.74\nepisode: 1834   score: 5.0   memory length: 404695   epsilon: 0.39670192001020094    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.75\nepisode: 1835   score: 12.0   memory length: 405234   epsilon: 0.3956347000101942    steps: 539    lr: 6.400000000000001e-06     evaluation reward: 4.82\nepisode: 1836   score: 9.0   memory length: 405700   epsilon: 0.39471202001018835    steps: 466    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1837   score: 6.0   memory length: 406032   epsilon: 0.3940546600101842    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 4.83\nepisode: 1838   score: 4.0   memory length: 406277   epsilon: 0.3935695600101811    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 4.84\nepisode: 1839   score: 6.0   memory length: 406633   epsilon: 0.39286468001017666    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1840   score: 4.0   memory length: 406909   epsilon: 0.3923182000101732    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1841   score: 7.0   memory length: 407313   epsilon: 0.39151828001016814    steps: 404    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1842   score: 4.0   memory length: 407568   epsilon: 0.39101338001016495    steps: 255    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1843   score: 5.0   memory length: 407873   epsilon: 0.3904094800101611    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1844   score: 4.0   memory length: 408121   epsilon: 0.389918440010158    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.89\nepisode: 1845   score: 7.0   memory length: 408496   epsilon: 0.3891759400101533    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1846   score: 3.0   memory length: 408725   epsilon: 0.38872252001015045    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1847   score: 5.0   memory length: 408999   epsilon: 0.388180000010147    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1848   score: 6.0   memory length: 409395   epsilon: 0.38739592001014206    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1849   score: 4.0   memory length: 409676   epsilon: 0.38683954001013854    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1850   score: 6.0   memory length: 410033   epsilon: 0.38613268001013407    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1851   score: 4.0   memory length: 410308   epsilon: 0.3855881800101306    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.81\nepisode: 1852   score: 7.0   memory length: 410677   epsilon: 0.384857560010126    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 4.84\nepisode: 1853   score: 5.0   memory length: 410985   epsilon: 0.38424772001012214    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.82\nepisode: 1854   score: 3.0   memory length: 411233   epsilon: 0.38375668001011903    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.8\nepisode: 1855   score: 9.0   memory length: 411698   epsilon: 0.3828359800101132    steps: 465    lr: 6.400000000000001e-06     evaluation reward: 4.84\nepisode: 1856   score: 9.0   memory length: 412030   epsilon: 0.38217862001010905    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1857   score: 5.0   memory length: 412325   epsilon: 0.38159452001010535    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1858   score: 7.0   memory length: 412678   epsilon: 0.38089558001010093    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1859   score: 2.0   memory length: 412860   epsilon: 0.38053522001009865    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1860   score: 4.0   memory length: 413119   epsilon: 0.3800224000100954    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1861   score: 4.0   memory length: 413360   epsilon: 0.3795452200100924    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1862   score: 4.0   memory length: 413620   epsilon: 0.37903042001008913    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1863   score: 3.0   memory length: 413865   epsilon: 0.37854532001008606    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1864   score: 4.0   memory length: 414125   epsilon: 0.3780305200100828    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 1865   score: 4.0   memory length: 414365   epsilon: 0.3775553200100798    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1866   score: 5.0   memory length: 414713   epsilon: 0.37686628001007544    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 4.89\nepisode: 1867   score: 6.0   memory length: 415029   epsilon: 0.3762406000100715    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1868   score: 5.0   memory length: 415355   epsilon: 0.3755951200100674    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1869   score: 6.0   memory length: 415696   epsilon: 0.3749199400100631    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1870   score: 4.0   memory length: 415972   epsilon: 0.37437346001005967    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1871   score: 5.0   memory length: 416260   epsilon: 0.37380322001005606    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 5.0\nepisode: 1872   score: 2.0   memory length: 416442   epsilon: 0.3734428600100538    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1873   score: 7.0   memory length: 416838   epsilon: 0.3726587800100488    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1874   score: 6.0   memory length: 417182   epsilon: 0.3719776600100445    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1875   score: 2.0   memory length: 417364   epsilon: 0.37161730001004223    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1876   score: 3.0   memory length: 417594   epsilon: 0.37116190001003935    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 1877   score: 4.0   memory length: 417854   epsilon: 0.3706471000100361    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1878   score: 2.0   memory length: 418036   epsilon: 0.3702867400100338    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1879   score: 4.0   memory length: 418278   epsilon: 0.3698075800100308    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1880   score: 3.0   memory length: 418492   epsilon: 0.3693838600100281    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1881   score: 2.0   memory length: 418674   epsilon: 0.3690235000100258    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1882   score: 5.0   memory length: 418982   epsilon: 0.36841366001002196    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1883   score: 9.0   memory length: 419430   epsilon: 0.36752662001001635    steps: 448    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1884   score: 2.0   memory length: 419630   epsilon: 0.36713062001001384    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1885   score: 6.0   memory length: 419969   epsilon: 0.3664594000100096    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1886   score: 4.0   memory length: 420228   epsilon: 0.36594658001000635    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.88\nepisode: 1887   score: 3.0   memory length: 420439   epsilon: 0.3655288000100037    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 4.89\nepisode: 1888   score: 5.0   memory length: 420764   epsilon: 0.36488530000999964    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.88\nepisode: 1889   score: 5.0   memory length: 421095   epsilon: 0.3642299200099955    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1890   score: 4.0   memory length: 421354   epsilon: 0.36371710000999224    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1891   score: 4.0   memory length: 421653   epsilon: 0.3631250800099885    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1892   score: 6.0   memory length: 422007   epsilon: 0.36242416000998406    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1893   score: 3.0   memory length: 422220   epsilon: 0.3620024200099814    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1894   score: 6.0   memory length: 422559   epsilon: 0.36133120000997715    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1895   score: 3.0   memory length: 422788   epsilon: 0.3608777800099743    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1896   score: 8.0   memory length: 423214   epsilon: 0.36003430000996894    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 5.0\nepisode: 1897   score: 6.0   memory length: 423552   epsilon: 0.3593650600099647    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 5.03\nepisode: 1898   score: 2.0   memory length: 423754   epsilon: 0.3589651000099622    steps: 202    lr: 6.400000000000001e-06     evaluation reward: 5.01\nepisode: 1899   score: 2.0   memory length: 423934   epsilon: 0.3586087000099599    steps: 180    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1900   score: 4.0   memory length: 424193   epsilon: 0.3580958800099567    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1901   score: 15.0   memory length: 424866   epsilon: 0.35676334000994825    steps: 673    lr: 6.400000000000001e-06     evaluation reward: 5.04\nepisode: 1902   score: 5.0   memory length: 425172   epsilon: 0.3561574600099444    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1903   score: 7.0   memory length: 425583   epsilon: 0.35534368000993927    steps: 411    lr: 6.400000000000001e-06     evaluation reward: 5.02\nepisode: 1904   score: 2.0   memory length: 425765   epsilon: 0.354983320009937    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1905   score: 8.0   memory length: 426189   epsilon: 0.3541438000099317    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 5.01\nepisode: 1906   score: 7.0   memory length: 426562   epsilon: 0.353405260009927    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1907   score: 5.0   memory length: 426875   epsilon: 0.3527855200099231    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1908   score: 4.0   memory length: 427134   epsilon: 0.35227270000991984    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1909   score: 5.0   memory length: 427462   epsilon: 0.35162326000991573    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1910   score: 2.0   memory length: 427643   epsilon: 0.35126488000991346    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1911   score: 2.0   memory length: 427824   epsilon: 0.3509065000099112    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.83\nepisode: 1912   score: 9.0   memory length: 428183   epsilon: 0.3501956800099067    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1913   score: 4.0   memory length: 428443   epsilon: 0.34968088000990344    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1914   score: 10.0   memory length: 428799   epsilon: 0.348976000009899    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1915   score: 5.0   memory length: 429104   epsilon: 0.34837210000989516    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1916   score: 2.0   memory length: 429284   epsilon: 0.3480157000098929    steps: 180    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1917   score: 7.0   memory length: 429673   epsilon: 0.34724548000988803    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 5.03\nepisode: 1918   score: 5.0   memory length: 429980   epsilon: 0.3466376200098842    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 5.01\nepisode: 1919   score: 4.0   memory length: 430260   epsilon: 0.3460832200098807    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 5.0\nepisode: 1920   score: 3.0   memory length: 430469   epsilon: 0.34566940000987806    steps: 209    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1921   score: 4.0   memory length: 430710   epsilon: 0.34519222000987504    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1922   score: 8.0   memory length: 431112   epsilon: 0.34439626000987    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1923   score: 7.0   memory length: 431539   epsilon: 0.34355080000986465    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1924   score: 7.0   memory length: 431964   epsilon: 0.34270930000985933    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 5.02\nepisode: 1925   score: 3.0   memory length: 432193   epsilon: 0.34225588000985646    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.01\nepisode: 1926   score: 3.0   memory length: 432406   epsilon: 0.3418341400098538    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1927   score: 4.0   memory length: 432687   epsilon: 0.3412777600098503    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1928   score: 3.0   memory length: 432916   epsilon: 0.3408243400098474    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 1929   score: 4.0   memory length: 433176   epsilon: 0.34030954000984415    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1930   score: 4.0   memory length: 433417   epsilon: 0.33983236000984113    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1931   score: 3.0   memory length: 433644   epsilon: 0.3393829000098383    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1932   score: 5.0   memory length: 433946   epsilon: 0.3387849400098345    steps: 302    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1933   score: 4.0   memory length: 434221   epsilon: 0.33824044000983106    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 1934   score: 4.0   memory length: 434502   epsilon: 0.33768406000982754    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1935   score: 12.0   memory length: 435007   epsilon: 0.3366841600098212    steps: 505    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1936   score: 8.0   memory length: 435460   epsilon: 0.33578722000981553    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1937   score: 5.0   memory length: 435770   epsilon: 0.33517342000981165    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1938   score: 8.0   memory length: 436253   epsilon: 0.3342170800098056    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1939   score: 4.0   memory length: 436532   epsilon: 0.3336646600098021    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1940   score: 6.0   memory length: 436931   epsilon: 0.3328746400097971    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1941   score: 4.0   memory length: 437173   epsilon: 0.3323954800097941    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1942   score: 2.0   memory length: 437373   epsilon: 0.33199948000979157    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1943   score: 4.0   memory length: 437647   epsilon: 0.33145696000978814    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.89\nepisode: 1944   score: 8.0   memory length: 438088   epsilon: 0.3305837800097826    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1945   score: 2.0   memory length: 438290   epsilon: 0.3301838200097801    steps: 202    lr: 6.400000000000001e-06     evaluation reward: 4.88\nepisode: 1946   score: 6.0   memory length: 438629   epsilon: 0.32951260000977584    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1947   score: 7.0   memory length: 439030   epsilon: 0.3287186200097708    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 4.93\nepisode: 1948   score: 12.0   memory length: 439505   epsilon: 0.32777812000976486    steps: 475    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1949   score: 4.0   memory length: 439800   epsilon: 0.32719402000976117    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1950   score: 8.0   memory length: 440279   epsilon: 0.32624560000975517    steps: 479    lr: 6.400000000000001e-06     evaluation reward: 5.01\nepisode: 1951   score: 4.0   memory length: 440539   epsilon: 0.3257308000097519    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.01\nepisode: 1952   score: 3.0   memory length: 440769   epsilon: 0.325275400009749    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1953   score: 6.0   memory length: 441143   epsilon: 0.32453488000974434    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1954   score: 1.0   memory length: 441295   epsilon: 0.32423392000974244    steps: 152    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1955   score: 2.0   memory length: 441477   epsilon: 0.32387356000974016    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.89\nepisode: 1956   score: 6.0   memory length: 441809   epsilon: 0.323216200009736    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1957   score: 6.0   memory length: 442186   epsilon: 0.3224697400097313    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1958   score: 2.0   memory length: 442368   epsilon: 0.322109380009729    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.82\nepisode: 1959   score: 5.0   memory length: 442684   epsilon: 0.32148370000972504    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1960   score: 6.0   memory length: 443007   epsilon: 0.320844160009721    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1961   score: 3.0   memory length: 443234   epsilon: 0.32039470000971815    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1962   score: 4.0   memory length: 443495   epsilon: 0.3198779200097149    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1963   score: 4.0   memory length: 443795   epsilon: 0.3192839200097111    steps: 300    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1964   score: 5.0   memory length: 444084   epsilon: 0.3187117000097075    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.88\nepisode: 1965   score: 3.0   memory length: 444333   epsilon: 0.3182186800097044    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1966   score: 5.0   memory length: 444675   epsilon: 0.3175415200097001    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1967   score: 6.0   memory length: 445051   epsilon: 0.3167970400096954    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.87\nepisode: 1968   score: 3.0   memory length: 445280   epsilon: 0.3163436200096925    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1969   score: 10.0   memory length: 445777   epsilon: 0.3153595600096863    steps: 497    lr: 6.400000000000001e-06     evaluation reward: 4.89\nepisode: 1970   score: 9.0   memory length: 446265   epsilon: 0.3143933200096802    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 1971   score: 2.0   memory length: 446446   epsilon: 0.3140349400096779    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.91\nepisode: 1972   score: 3.0   memory length: 446676   epsilon: 0.31357954000967503    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.92\nepisode: 1973   score: 1.0   memory length: 446828   epsilon: 0.3132785800096731    steps: 152    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1974   score: 2.0   memory length: 447010   epsilon: 0.31291822000967084    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.82\nepisode: 1975   score: 6.0   memory length: 447344   epsilon: 0.31225690000966666    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 4.86\nepisode: 1976   score: 2.0   memory length: 447526   epsilon: 0.3118965400096644    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.85\nepisode: 1977   score: 3.0   memory length: 447739   epsilon: 0.3114748000096617    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.84\nepisode: 1978   score: 6.0   memory length: 448092   epsilon: 0.3107758600096573    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 4.88\nepisode: 1979   score: 6.0   memory length: 448463   epsilon: 0.31004128000965264    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 4.9\nepisode: 1980   score: 7.0   memory length: 448852   epsilon: 0.30927106000964777    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 1981   score: 5.0   memory length: 449159   epsilon: 0.3086632000096439    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1982   score: 6.0   memory length: 449516   epsilon: 0.30795634000963945    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1983   score: 6.0   memory length: 449855   epsilon: 0.3072851200096352    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1984   score: 5.0   memory length: 450161   epsilon: 0.30667924000963137    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1985   score: 3.0   memory length: 450371   epsilon: 0.30626344000962874    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 4.95\nepisode: 1986   score: 6.0   memory length: 450714   epsilon: 0.30558430000962444    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1987   score: 2.0   memory length: 450896   epsilon: 0.30522394000962216    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 1988   score: 6.0   memory length: 451212   epsilon: 0.3045982600096182    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1989   score: 5.0   memory length: 451515   epsilon: 0.3039983200096144    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1990   score: 5.0   memory length: 451801   epsilon: 0.3034320400096108    steps: 286    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 1991   score: 6.0   memory length: 452155   epsilon: 0.3027311200096064    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 5.0\nepisode: 1992   score: 3.0   memory length: 452368   epsilon: 0.3023093800096037    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1993   score: 3.0   memory length: 452597   epsilon: 0.30185596000960085    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 1994   score: 8.0   memory length: 453008   epsilon: 0.3010421800095957    steps: 411    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1995   score: 7.0   memory length: 453409   epsilon: 0.3002482000095907    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 5.03\nepisode: 1996   score: 4.0   memory length: 453668   epsilon: 0.29973538000958744    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1997   score: 6.0   memory length: 454030   epsilon: 0.2990186200095829    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 1998   score: 6.0   memory length: 454368   epsilon: 0.29834938000957867    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 5.03\nepisode: 1999   score: 5.0   memory length: 454695   epsilon: 0.29770192000957457    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 5.06\nepisode: 2000   score: 2.0   memory length: 454876   epsilon: 0.2973435400095723    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 5.04\nepisode: 2005   score: 6.0   memory length: 456642   epsilon: 0.2938468600095502    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 5.0\nepisode: 2006   score: 4.0   memory length: 456899   epsilon: 0.29333800000954696    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 2007   score: 2.0   memory length: 457080   epsilon: 0.2929796200095447    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 2008   score: 6.0   memory length: 457420   epsilon: 0.29230642000954044    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 2009   score: 6.0   memory length: 457777   epsilon: 0.29159956000953596    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.97\nepisode: 2010   score: 4.0   memory length: 458058   epsilon: 0.29104318000953244    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 2011   score: 5.0   memory length: 458405   epsilon: 0.2903561200095281    steps: 347    lr: 6.400000000000001e-06     evaluation reward: 5.02\nepisode: 2012   score: 5.0   memory length: 458693   epsilon: 0.2897858800095245    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 4.98\nepisode: 2013   score: 5.0   memory length: 459003   epsilon: 0.2891720800095206    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.99\nepisode: 2014   score: 5.0   memory length: 459294   epsilon: 0.28859590000951696    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 4.94\nepisode: 2015   score: 7.0   memory length: 459666   epsilon: 0.2878593400095123    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 4.96\nepisode: 2016   score: 11.0   memory length: 460105   epsilon: 0.2869901200095068    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 5.05\nepisode: 2017   score: 6.0   memory length: 460453   epsilon: 0.28630108000950244    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 5.04\nepisode: 2018   score: 3.0   memory length: 460664   epsilon: 0.2858833000094998    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 5.02\nepisode: 2019   score: 6.0   memory length: 461018   epsilon: 0.28518238000949536    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 5.04\nepisode: 2020   score: 5.0   memory length: 461325   epsilon: 0.2845745200094915    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 5.06\nepisode: 2021   score: 7.0   memory length: 461731   epsilon: 0.28377064000948643    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 5.09\nepisode: 2022   score: 6.0   memory length: 462069   epsilon: 0.2831014000094822    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 5.07\nepisode: 2023   score: 8.0   memory length: 462385   epsilon: 0.28247572000947824    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 5.08\nepisode: 2024   score: 7.0   memory length: 462756   epsilon: 0.2817411400094736    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 5.08\nepisode: 2025   score: 4.0   memory length: 463034   epsilon: 0.2811907000094701    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.09\nepisode: 2026   score: 6.0   memory length: 463393   epsilon: 0.2804798800094656    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 5.12\nepisode: 2027   score: 4.0   memory length: 463690   epsilon: 0.2798918200094619    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 5.12\nepisode: 2028   score: 5.0   memory length: 463999   epsilon: 0.279280000009458    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 5.14\nepisode: 2029   score: 5.0   memory length: 464325   epsilon: 0.27863452000945393    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.15\nepisode: 2030   score: 4.0   memory length: 464584   epsilon: 0.2781217000094507    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.15\nepisode: 2031   score: 6.0   memory length: 464922   epsilon: 0.27745246000944646    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 5.18\nepisode: 2032   score: 4.0   memory length: 465182   epsilon: 0.2769376600094432    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.17\nepisode: 2033   score: 4.0   memory length: 465459   epsilon: 0.27638920000943973    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.17\nepisode: 2034   score: 7.0   memory length: 465850   epsilon: 0.27561502000943483    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 2035   score: 7.0   memory length: 466216   epsilon: 0.27489034000943025    steps: 366    lr: 6.400000000000001e-06     evaluation reward: 5.15\nepisode: 2036   score: 3.0   memory length: 466446   epsilon: 0.27443494000942736    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 5.1\nepisode: 2037   score: 8.0   memory length: 466887   epsilon: 0.27356176000942184    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 5.13\nepisode: 2038   score: 8.0   memory length: 467305   epsilon: 0.2727341200094166    steps: 418    lr: 6.400000000000001e-06     evaluation reward: 5.13\nepisode: 2039   score: 6.0   memory length: 467629   epsilon: 0.27209260000941254    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 5.15\nepisode: 2040   score: 7.0   memory length: 468001   epsilon: 0.2713560400094079    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 5.16\nepisode: 2041   score: 8.0   memory length: 468420   epsilon: 0.27052642000940264    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 2042   score: 3.0   memory length: 468633   epsilon: 0.27010468000939997    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.21\nepisode: 2043   score: 8.0   memory length: 469066   epsilon: 0.26924734000939454    steps: 433    lr: 6.400000000000001e-06     evaluation reward: 5.25\nepisode: 2044   score: 2.0   memory length: 469265   epsilon: 0.26885332000939205    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 5.19\nepisode: 2045   score: 6.0   memory length: 469627   epsilon: 0.2681365600093875    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 5.23\nepisode: 2046   score: 7.0   memory length: 470053   epsilon: 0.2672930800093822    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 5.24\nepisode: 2047   score: 2.0   memory length: 470234   epsilon: 0.2669347000093799    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 5.19\nepisode: 2048   score: 6.0   memory length: 470557   epsilon: 0.26629516000937586    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 5.13\nepisode: 2049   score: 2.0   memory length: 470739   epsilon: 0.2659348000093736    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 5.11\nepisode: 2050   score: 2.0   memory length: 470921   epsilon: 0.2655744400093713    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 5.05\nepisode: 2051   score: 6.0   memory length: 471241   epsilon: 0.2649408400093673    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 5.07\nepisode: 2052   score: 6.0   memory length: 471634   epsilon: 0.2641627000093624    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 5.1\nepisode: 2053   score: 9.0   memory length: 472056   epsilon: 0.2633271400093571    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 5.13\nepisode: 2054   score: 6.0   memory length: 472438   epsilon: 0.2625707800093523    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 5.18\nepisode: 2055   score: 4.0   memory length: 472715   epsilon: 0.26202232000934883    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 2056   score: 4.0   memory length: 472957   epsilon: 0.2615431600093458    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.18\nepisode: 2057   score: 5.0   memory length: 473286   epsilon: 0.2608917400093417    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 5.17\nepisode: 2058   score: 6.0   memory length: 473642   epsilon: 0.2601868600093372    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 5.21\nepisode: 2059   score: 4.0   memory length: 473920   epsilon: 0.25963642000933373    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 2060   score: 6.0   memory length: 474255   epsilon: 0.25897312000932954    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 2061   score: 3.0   memory length: 474484   epsilon: 0.25851970000932667    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.2\nepisode: 2062   score: 6.0   memory length: 474880   epsilon: 0.2577356200093217    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 5.22\nepisode: 2063   score: 5.0   memory length: 475183   epsilon: 0.2571356800093179    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 5.23\nepisode: 2064   score: 4.0   memory length: 475440   epsilon: 0.2566268200093147    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.22\nepisode: 2065   score: 7.0   memory length: 475813   epsilon: 0.25588828000931    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 5.26\nepisode: 2066   score: 6.0   memory length: 476133   epsilon: 0.255254680009306    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 5.27\nepisode: 2067   score: 8.0   memory length: 476552   epsilon: 0.25442506000930076    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 5.29\nepisode: 2068   score: 2.0   memory length: 476732   epsilon: 0.2540686600092985    steps: 180    lr: 6.400000000000001e-06     evaluation reward: 5.28\nepisode: 2069   score: 4.0   memory length: 477029   epsilon: 0.2534806000092948    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 5.22\nepisode: 2070   score: 6.0   memory length: 477366   epsilon: 0.25281334000929057    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 5.19\nepisode: 2071   score: 4.0   memory length: 477623   epsilon: 0.25230448000928735    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.21\nepisode: 2072   score: 4.0   memory length: 477865   epsilon: 0.2518253200092843    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.22\nepisode: 2073   score: 7.0   memory length: 478281   epsilon: 0.2510016400092791    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 5.28\nepisode: 2074   score: 13.0   memory length: 478774   epsilon: 0.2500255000092729    steps: 493    lr: 6.400000000000001e-06     evaluation reward: 5.39\nepisode: 2075   score: 4.0   memory length: 479015   epsilon: 0.2495483200092699    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 5.37\nepisode: 2076   score: 2.0   memory length: 479195   epsilon: 0.24919192000926765    steps: 180    lr: 6.400000000000001e-06     evaluation reward: 5.37\nepisode: 2077   score: 8.0   memory length: 479616   epsilon: 0.24835834000926238    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 5.42\nepisode: 2078   score: 4.0   memory length: 479875   epsilon: 0.24784552000925913    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.4\nepisode: 2079   score: 6.0   memory length: 480218   epsilon: 0.24716638000925484    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 5.4\nepisode: 2080   score: 8.0   memory length: 480655   epsilon: 0.24630112000924936    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 5.41\nepisode: 2081   score: 4.0   memory length: 480895   epsilon: 0.24582592000924636    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 5.4\nepisode: 2082   score: 4.0   memory length: 481154   epsilon: 0.2453131000092431    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.38\nepisode: 2083   score: 7.0   memory length: 481511   epsilon: 0.24460624000923864    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 5.39\nepisode: 2084   score: 8.0   memory length: 481926   epsilon: 0.24378454000923344    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 5.42\nepisode: 2085   score: 7.0   memory length: 482268   epsilon: 0.24310738000922916    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 5.46\nepisode: 2086   score: 6.0   memory length: 482609   epsilon: 0.24243220000922489    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 5.46\nepisode: 2087   score: 10.0   memory length: 483023   epsilon: 0.2416124800092197    steps: 414    lr: 6.400000000000001e-06     evaluation reward: 5.54\nepisode: 2088   score: 12.0   memory length: 483447   epsilon: 0.2407729600092144    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 5.6\nepisode: 2089   score: 7.0   memory length: 483836   epsilon: 0.24000274000920951    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 5.62\nepisode: 2090   score: 8.0   memory length: 484270   epsilon: 0.23914342000920408    steps: 434    lr: 6.400000000000001e-06     evaluation reward: 5.65\nepisode: 2091   score: 6.0   memory length: 484628   epsilon: 0.2384345800091996    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 5.65\nepisode: 2092   score: 4.0   memory length: 484892   epsilon: 0.23791186000919629    steps: 264    lr: 6.400000000000001e-06     evaluation reward: 5.66\nepisode: 2093   score: 7.0   memory length: 485313   epsilon: 0.237078280009191    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 5.7\nepisode: 2094   score: 8.0   memory length: 485736   epsilon: 0.2362407400091857    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 5.7\nepisode: 2095   score: 8.0   memory length: 486190   epsilon: 0.23534182000918002    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 5.71\nepisode: 2096   score: 6.0   memory length: 486565   epsilon: 0.23459932000917533    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 2097   score: 5.0   memory length: 486840   epsilon: 0.23405482000917188    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2098   score: 6.0   memory length: 487215   epsilon: 0.23331232000916718    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2099   score: 6.0   memory length: 487571   epsilon: 0.23260744000916272    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 2100   score: 2.0   memory length: 487753   epsilon: 0.23224708000916044    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 2101   score: 5.0   memory length: 488057   epsilon: 0.23164516000915664    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2102   score: 7.0   memory length: 488482   epsilon: 0.2308036600091513    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 5.71\nepisode: 2103   score: 4.0   memory length: 488739   epsilon: 0.2302948000091481    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.66\nepisode: 2104   score: 7.0   memory length: 489108   epsilon: 0.22956418000914347    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 2105   score: 6.0   memory length: 489466   epsilon: 0.22885534000913899    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 2106   score: 7.0   memory length: 489873   epsilon: 0.2280494800091339    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2107   score: 7.0   memory length: 490293   epsilon: 0.22721788000912863    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2108   score: 6.0   memory length: 490635   epsilon: 0.22654072000912434    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2109   score: 4.0   memory length: 490913   epsilon: 0.22599028000912086    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.75\nepisode: 2110   score: 4.0   memory length: 491172   epsilon: 0.22547746000911761    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.75\nepisode: 2111   score: 7.0   memory length: 491554   epsilon: 0.22472110000911283    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2112   score: 5.0   memory length: 491844   epsilon: 0.2241469000091092    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2113   score: 6.0   memory length: 492167   epsilon: 0.22350736000910515    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 5.78\nepisode: 2114   score: 9.0   memory length: 492658   epsilon: 0.222535180009099    steps: 491    lr: 6.400000000000001e-06     evaluation reward: 5.82\nepisode: 2115   score: 5.0   memory length: 492933   epsilon: 0.22199068000909555    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 5.8\nepisode: 2116   score: 6.0   memory length: 493269   epsilon: 0.22132540000909134    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 5.75\nepisode: 2117   score: 7.0   memory length: 493663   epsilon: 0.2205452800090864    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2118   score: 6.0   memory length: 494036   epsilon: 0.21980674000908174    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2119   score: 6.0   memory length: 494373   epsilon: 0.21913948000907751    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 5.79\nepisode: 2120   score: 3.0   memory length: 494584   epsilon: 0.21872170000907487    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2121   score: 6.0   memory length: 494927   epsilon: 0.21804256000907057    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2122   score: 7.0   memory length: 495307   epsilon: 0.2172901600090658    steps: 380    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2123   score: 3.0   memory length: 495537   epsilon: 0.21683476000906293    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2124   score: 4.0   memory length: 495795   epsilon: 0.2163239200090597    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 5.69\nepisode: 2125   score: 5.0   memory length: 496092   epsilon: 0.21573586000905598    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 5.7\nepisode: 2126   score: 10.0   memory length: 496594   epsilon: 0.2147419000090497    steps: 502    lr: 6.400000000000001e-06     evaluation reward: 5.74\nepisode: 2127   score: 7.0   memory length: 496959   epsilon: 0.21401920000904512    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2128   score: 6.0   memory length: 497279   epsilon: 0.2133856000090411    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 5.78\nepisode: 2129   score: 1.0   memory length: 497447   epsilon: 0.213052960009039    steps: 168    lr: 6.400000000000001e-06     evaluation reward: 5.74\nepisode: 2130   score: 6.0   memory length: 497820   epsilon: 0.21231442000903433    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2131   score: 4.0   memory length: 498100   epsilon: 0.21176002000903082    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 5.74\nepisode: 2132   score: 6.0   memory length: 498462   epsilon: 0.2110432600090263    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 5.76\nepisode: 2133   score: 5.0   memory length: 498751   epsilon: 0.21047104000902267    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2134   score: 3.0   memory length: 498996   epsilon: 0.2099859400090196    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.73\nepisode: 2135   score: 6.0   memory length: 499329   epsilon: 0.20932660000901543    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 5.72\nepisode: 2136   score: 8.0   memory length: 499772   epsilon: 0.20844946000900988    steps: 443    lr: 6.400000000000001e-06     evaluation reward: 5.77\nepisode: 2137   score: 9.0   memory length: 500189   epsilon: 0.20762380000900466    steps: 417    lr: 2.560000000000001e-06     evaluation reward: 5.78\nepisode: 2138   score: 10.0   memory length: 500716   epsilon: 0.20658034000899805    steps: 527    lr: 2.560000000000001e-06     evaluation reward: 5.8\nepisode: 2139   score: 7.0   memory length: 501096   epsilon: 0.2058279400089933    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 5.81\nepisode: 2140   score: 16.0   memory length: 501711   epsilon: 0.2046102400089856    steps: 615    lr: 2.560000000000001e-06     evaluation reward: 5.9\nepisode: 2141   score: 6.0   memory length: 502044   epsilon: 0.20395090000898142    steps: 333    lr: 2.560000000000001e-06     evaluation reward: 5.88\nepisode: 2142   score: 8.0   memory length: 502467   epsilon: 0.20311336000897612    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 5.93\nepisode: 2143   score: 9.0   memory length: 502961   epsilon: 0.20213524000896993    steps: 494    lr: 2.560000000000001e-06     evaluation reward: 5.94\nepisode: 2144   score: 5.0   memory length: 503268   epsilon: 0.20152738000896608    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.97\nepisode: 2145   score: 8.0   memory length: 503724   epsilon: 0.20062450000896037    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 5.99\nepisode: 2146   score: 4.0   memory length: 504004   epsilon: 0.20007010000895686    steps: 280    lr: 2.560000000000001e-06     evaluation reward: 5.96\nepisode: 2147   score: 3.0   memory length: 504215   epsilon: 0.19965232000895422    steps: 211    lr: 2.560000000000001e-06     evaluation reward: 5.97\nepisode: 2148   score: 8.0   memory length: 504644   epsilon: 0.19880290000894885    steps: 429    lr: 2.560000000000001e-06     evaluation reward: 5.99\nepisode: 2149   score: 8.0   memory length: 505016   epsilon: 0.1980663400089442    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 6.05\nepisode: 2150   score: 4.0   memory length: 505275   epsilon: 0.19755352000894094    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 6.07\nepisode: 2151   score: 7.0   memory length: 505661   epsilon: 0.1967892400089361    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 6.08\nepisode: 2152   score: 14.0   memory length: 506152   epsilon: 0.19581706000892996    steps: 491    lr: 2.560000000000001e-06     evaluation reward: 6.16\nepisode: 2153   score: 7.0   memory length: 506530   epsilon: 0.19506862000892522    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 6.14\nepisode: 2154   score: 13.0   memory length: 507059   epsilon: 0.1940212000089186    steps: 529    lr: 2.560000000000001e-06     evaluation reward: 6.21\nepisode: 2155   score: 7.0   memory length: 507428   epsilon: 0.19329058000891397    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 6.24\nepisode: 2156   score: 7.0   memory length: 507851   epsilon: 0.19245304000890867    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 6.27\nepisode: 2157   score: 5.0   memory length: 508121   epsilon: 0.1919184400089053    steps: 270    lr: 2.560000000000001e-06     evaluation reward: 6.27\nepisode: 2158   score: 7.0   memory length: 508491   epsilon: 0.19118584000890065    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 6.28\nepisode: 2159   score: 8.0   memory length: 508887   epsilon: 0.1904017600088957    steps: 396    lr: 2.560000000000001e-06     evaluation reward: 6.32\nepisode: 2160   score: 4.0   memory length: 509146   epsilon: 0.18988894000889245    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 6.3\nepisode: 2161   score: 5.0   memory length: 509491   epsilon: 0.18920584000888813    steps: 345    lr: 2.560000000000001e-06     evaluation reward: 6.32\nepisode: 2162   score: 8.0   memory length: 509924   epsilon: 0.1883485000088827    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 6.34\nepisode: 2163   score: 6.0   memory length: 510299   epsilon: 0.187606000008878    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.35\nepisode: 2164   score: 7.0   memory length: 510689   epsilon: 0.18683380000887312    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 6.38\nepisode: 2165   score: 6.0   memory length: 511008   epsilon: 0.18620218000886912    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 6.37\nepisode: 2166   score: 9.0   memory length: 511475   epsilon: 0.18527752000886327    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 6.4\nepisode: 2167   score: 2.0   memory length: 511656   epsilon: 0.184919140008861    steps: 181    lr: 2.560000000000001e-06     evaluation reward: 6.34\nepisode: 2168   score: 6.0   memory length: 512029   epsilon: 0.18418060000885633    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.38\nepisode: 2169   score: 4.0   memory length: 512291   epsilon: 0.18366184000885305    steps: 262    lr: 2.560000000000001e-06     evaluation reward: 6.38\nepisode: 2170   score: 8.0   memory length: 512763   epsilon: 0.18272728000884714    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 6.4\nepisode: 2171   score: 5.0   memory length: 513087   epsilon: 0.18208576000884308    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 6.41\nepisode: 2172   score: 8.0   memory length: 513486   epsilon: 0.18129574000883808    steps: 399    lr: 2.560000000000001e-06     evaluation reward: 6.45\nepisode: 2173   score: 7.0   memory length: 513855   epsilon: 0.18056512000883346    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 6.45\nepisode: 2174   score: 9.0   memory length: 514221   epsilon: 0.17984044000882887    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 6.41\nepisode: 2175   score: 11.0   memory length: 514816   epsilon: 0.17866234000882142    steps: 595    lr: 2.560000000000001e-06     evaluation reward: 6.48\nepisode: 2176   score: 7.0   memory length: 515220   epsilon: 0.17786242000881636    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 6.53\nepisode: 2177   score: 12.0   memory length: 515739   epsilon: 0.17683480000880986    steps: 519    lr: 2.560000000000001e-06     evaluation reward: 6.57\nepisode: 2178   score: 5.0   memory length: 516052   epsilon: 0.17621506000880593    steps: 313    lr: 2.560000000000001e-06     evaluation reward: 6.58\nepisode: 2179   score: 10.0   memory length: 516538   epsilon: 0.17525278000879985    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2180   score: 5.0   memory length: 516837   epsilon: 0.1746607600087961    steps: 299    lr: 2.560000000000001e-06     evaluation reward: 6.59\nepisode: 2181   score: 9.0   memory length: 517179   epsilon: 0.17398360000879182    steps: 342    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2182   score: 7.0   memory length: 517586   epsilon: 0.17317774000878672    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 6.67\nepisode: 2183   score: 4.0   memory length: 517844   epsilon: 0.17266690000878349    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2184   score: 5.0   memory length: 518134   epsilon: 0.17209270000877985    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 6.61\nepisode: 2185   score: 10.0   memory length: 518593   epsilon: 0.1711838800087741    steps: 459    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2186   score: 6.0   memory length: 518932   epsilon: 0.17051266000876986    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2187   score: 7.0   memory length: 519365   epsilon: 0.16965532000876443    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 6.61\nepisode: 2188   score: 6.0   memory length: 519718   epsilon: 0.16895638000876    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2189   score: 7.0   memory length: 520087   epsilon: 0.1682257600087554    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 6.55\nepisode: 2190   score: 12.0   memory length: 520668   epsilon: 0.1670753800087481    steps: 581    lr: 2.560000000000001e-06     evaluation reward: 6.59\nepisode: 2191   score: 8.0   memory length: 521052   epsilon: 0.1663150600087433    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.61\nepisode: 2192   score: 5.0   memory length: 521359   epsilon: 0.16570720000873945    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2193   score: 7.0   memory length: 521712   epsilon: 0.16500826000873503    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2194   score: 6.0   memory length: 522068   epsilon: 0.16430338000873057    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.6\nepisode: 2195   score: 5.0   memory length: 522390   epsilon: 0.16366582000872654    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 6.57\nepisode: 2196   score: 13.0   memory length: 522892   epsilon: 0.16267186000872025    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2197   score: 4.0   memory length: 523133   epsilon: 0.16219468000871723    steps: 241    lr: 2.560000000000001e-06     evaluation reward: 6.63\nepisode: 2198   score: 7.0   memory length: 523517   epsilon: 0.16143436000871242    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2199   score: 4.0   memory length: 523794   epsilon: 0.16088590000870895    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 6.62\nepisode: 2200   score: 8.0   memory length: 524227   epsilon: 0.16002856000870352    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 6.68\nepisode: 2201   score: 5.0   memory length: 524535   epsilon: 0.15941872000869967    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 6.68\nepisode: 2202   score: 5.0   memory length: 524824   epsilon: 0.15884650000869605    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 6.66\nepisode: 2203   score: 4.0   memory length: 525117   epsilon: 0.15826636000869237    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 6.66\nepisode: 2204   score: 7.0   memory length: 525483   epsilon: 0.1575416800086878    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 6.66\nepisode: 2205   score: 5.0   memory length: 525782   epsilon: 0.15694966000868404    steps: 299    lr: 2.560000000000001e-06     evaluation reward: 6.65\nepisode: 2206   score: 7.0   memory length: 526208   epsilon: 0.1561061800086787    steps: 426    lr: 2.560000000000001e-06     evaluation reward: 6.65\nepisode: 2207   score: 5.0   memory length: 526496   epsilon: 0.1555359400086751    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 6.63\nepisode: 2208   score: 7.0   memory length: 526904   epsilon: 0.15472810000867    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 6.64\nepisode: 2209   score: 5.0   memory length: 527196   epsilon: 0.15414994000866633    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 6.65\nepisode: 2210   score: 6.0   memory length: 527519   epsilon: 0.15351040000866228    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 6.67\nepisode: 2211   score: 7.0   memory length: 527884   epsilon: 0.1527877000086577    steps: 365    lr: 2.560000000000001e-06     evaluation reward: 6.67\nepisode: 2212   score: 7.0   memory length: 528308   epsilon: 0.1519481800086524    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 6.69\nepisode: 2213   score: 9.0   memory length: 528743   epsilon: 0.15108688000864695    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 6.72\nepisode: 2214   score: 4.0   memory length: 528998   epsilon: 0.15058198000864376    steps: 255    lr: 2.560000000000001e-06     evaluation reward: 6.67\nepisode: 2215   score: 5.0   memory length: 529305   epsilon: 0.1499741200086399    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.67\nepisode: 2216   score: 7.0   memory length: 529694   epsilon: 0.14920390000863504    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 6.68\nepisode: 2217   score: 7.0   memory length: 530078   epsilon: 0.14844358000863023    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.68\nepisode: 2218   score: 7.0   memory length: 530483   epsilon: 0.14764168000862515    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 6.69\nepisode: 2219   score: 7.0   memory length: 530895   epsilon: 0.14682592000862    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 6.7\nepisode: 2220   score: 6.0   memory length: 531217   epsilon: 0.14618836000861596    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 6.73\nepisode: 2221   score: 10.0   memory length: 531758   epsilon: 0.14511718000860918    steps: 541    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2222   score: 5.0   memory length: 532048   epsilon: 0.14454298000860555    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 6.75\nepisode: 2223   score: 5.0   memory length: 532339   epsilon: 0.1439668000086019    steps: 291    lr: 2.560000000000001e-06     evaluation reward: 6.77\nepisode: 2224   score: 7.0   memory length: 532745   epsilon: 0.14316292000859682    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 6.8\nepisode: 2225   score: 6.0   memory length: 533091   epsilon: 0.14247784000859248    steps: 346    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2226   score: 13.0   memory length: 533616   epsilon: 0.1414383400085859    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 6.84\nepisode: 2227   score: 4.0   memory length: 533876   epsilon: 0.14092354000858265    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.81\nepisode: 2228   score: 7.0   memory length: 534278   epsilon: 0.1401275800085776    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 6.82\nepisode: 2229   score: 2.0   memory length: 534459   epsilon: 0.13976920000857534    steps: 181    lr: 2.560000000000001e-06     evaluation reward: 6.83\nepisode: 2230   score: 6.0   memory length: 534799   epsilon: 0.13909600000857109    steps: 340    lr: 2.560000000000001e-06     evaluation reward: 6.83\nepisode: 2231   score: 9.0   memory length: 535242   epsilon: 0.13821886000856554    steps: 443    lr: 2.560000000000001e-06     evaluation reward: 6.88\nepisode: 2232   score: 6.0   memory length: 535580   epsilon: 0.1375496200085613    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.88\nepisode: 2233   score: 10.0   memory length: 536012   epsilon: 0.1366942600085559    steps: 432    lr: 2.560000000000001e-06     evaluation reward: 6.93\nepisode: 2234   score: 7.0   memory length: 536386   epsilon: 0.1359537400085512    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 6.97\nepisode: 2235   score: 5.0   memory length: 536701   epsilon: 0.13533004000854726    steps: 315    lr: 2.560000000000001e-06     evaluation reward: 6.96\nepisode: 2236   score: 10.0   memory length: 537214   epsilon: 0.13431430000854083    steps: 513    lr: 2.560000000000001e-06     evaluation reward: 6.98\nepisode: 2237   score: 6.0   memory length: 537533   epsilon: 0.13368268000853684    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 6.95\nepisode: 2238   score: 9.0   memory length: 538016   epsilon: 0.13272634000853079    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 6.94\nepisode: 2239   score: 11.0   memory length: 538554   epsilon: 0.13166110000852405    steps: 538    lr: 2.560000000000001e-06     evaluation reward: 6.98\nepisode: 2240   score: 4.0   memory length: 538795   epsilon: 0.13118392000852103    steps: 241    lr: 2.560000000000001e-06     evaluation reward: 6.86\nepisode: 2241   score: 7.0   memory length: 539150   epsilon: 0.13048102000851658    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 6.87\nepisode: 2242   score: 8.0   memory length: 539542   epsilon: 0.12970486000851167    steps: 392    lr: 2.560000000000001e-06     evaluation reward: 6.87\nepisode: 2243   score: 7.0   memory length: 539953   epsilon: 0.12889108000850652    steps: 411    lr: 2.560000000000001e-06     evaluation reward: 6.85\nepisode: 2244   score: 6.0   memory length: 540329   epsilon: 0.1281466000085018    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 6.86\nepisode: 2245   score: 11.0   memory length: 540741   epsilon: 0.12733084000849665    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 6.89\nepisode: 2246   score: 6.0   memory length: 541080   epsilon: 0.1266596200084924    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 6.91\nepisode: 2247   score: 10.0   memory length: 541460   epsilon: 0.12590722000848764    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 6.98\nepisode: 2248   score: 9.0   memory length: 541971   epsilon: 0.12489544000848198    steps: 511    lr: 2.560000000000001e-06     evaluation reward: 6.99\nepisode: 2249   score: 7.0   memory length: 542339   epsilon: 0.12416680000848247    steps: 368    lr: 2.560000000000001e-06     evaluation reward: 6.98\nepisode: 2250   score: 7.0   memory length: 542749   epsilon: 0.12335500000848303    steps: 410    lr: 2.560000000000001e-06     evaluation reward: 7.01\nepisode: 2251   score: 8.0   memory length: 543157   epsilon: 0.12254716000848358    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 7.02\nepisode: 2252   score: 7.0   memory length: 543545   epsilon: 0.1217789200084841    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 6.95\nepisode: 2253   score: 7.0   memory length: 543920   epsilon: 0.12103642000848461    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.95\nepisode: 2254   score: 7.0   memory length: 544344   epsilon: 0.12019690000848518    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 6.89\nepisode: 2255   score: 7.0   memory length: 544723   epsilon: 0.11944648000848569    steps: 379    lr: 2.560000000000001e-06     evaluation reward: 6.89\nepisode: 2256   score: 6.0   memory length: 545059   epsilon: 0.11878120000848615    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.88\nepisode: 2257   score: 9.0   memory length: 545520   epsilon: 0.11786842000848677    steps: 461    lr: 2.560000000000001e-06     evaluation reward: 6.92\nepisode: 2258   score: 5.0   memory length: 545811   epsilon: 0.11729224000848716    steps: 291    lr: 2.560000000000001e-06     evaluation reward: 6.9\nepisode: 2259   score: 6.0   memory length: 546184   epsilon: 0.11655370000848767    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.88\nepisode: 2260   score: 6.0   memory length: 546559   epsilon: 0.11581120000848817    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.9\nepisode: 2261   score: 6.0   memory length: 546897   epsilon: 0.11514196000848863    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.91\nepisode: 2262   score: 7.0   memory length: 547321   epsilon: 0.1143024400084892    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 6.9\nepisode: 2263   score: 6.0   memory length: 547682   epsilon: 0.11358766000848969    steps: 361    lr: 2.560000000000001e-06     evaluation reward: 6.9\nepisode: 2264   score: 14.0   memory length: 548194   epsilon: 0.11257390000849038    steps: 512    lr: 2.560000000000001e-06     evaluation reward: 6.97\nepisode: 2265   score: 9.0   memory length: 548535   epsilon: 0.11189872000849084    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 7.0\nepisode: 2266   score: 10.0   memory length: 549033   epsilon: 0.11091268000849151    steps: 498    lr: 2.560000000000001e-06     evaluation reward: 7.01\nepisode: 2267   score: 6.0   memory length: 549367   epsilon: 0.11025136000849196    steps: 334    lr: 2.560000000000001e-06     evaluation reward: 7.05\nepisode: 2268   score: 11.0   memory length: 549788   epsilon: 0.10941778000849253    steps: 421    lr: 2.560000000000001e-06     evaluation reward: 7.1\nepisode: 2269   score: 8.0   memory length: 550224   epsilon: 0.10855450000849312    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 7.14\nepisode: 2270   score: 7.0   memory length: 550593   epsilon: 0.10782388000849362    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2271   score: 6.0   memory length: 550915   epsilon: 0.10718632000849405    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 7.14\nepisode: 2272   score: 7.0   memory length: 551293   epsilon: 0.10643788000849456    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2273   score: 9.0   memory length: 551804   epsilon: 0.10542610000849525    steps: 511    lr: 2.560000000000001e-06     evaluation reward: 7.15\nepisode: 2274   score: 9.0   memory length: 552262   epsilon: 0.10451926000849587    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 7.15\nepisode: 2275   score: 6.0   memory length: 552594   epsilon: 0.10386190000849632    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 7.1\nepisode: 2276   score: 10.0   memory length: 553103   epsilon: 0.10285408000849701    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2277   score: 12.0   memory length: 553687   epsilon: 0.1016977600084978    steps: 584    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2278   score: 7.0   memory length: 554053   epsilon: 0.10097308000849829    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 7.15\nepisode: 2279   score: 9.0   memory length: 554401   epsilon: 0.10028404000849876    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 7.14\nepisode: 2280   score: 5.0   memory length: 554706   epsilon: 0.09968014000849917    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 7.14\nepisode: 2281   score: 5.0   memory length: 555033   epsilon: 0.09903268000849962    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 7.1\nepisode: 2282   score: 6.0   memory length: 555356   epsilon: 0.09839314000850005    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 7.09\nepisode: 2283   score: 8.0   memory length: 555826   epsilon: 0.09746254000850069    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2284   score: 5.0   memory length: 556096   epsilon: 0.09692794000850105    steps: 270    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2285   score: 4.0   memory length: 556337   epsilon: 0.09645076000850138    steps: 241    lr: 2.560000000000001e-06     evaluation reward: 7.07\nepisode: 2286   score: 7.0   memory length: 556687   epsilon: 0.09575776000850185    steps: 350    lr: 2.560000000000001e-06     evaluation reward: 7.08\nepisode: 2287   score: 12.0   memory length: 557272   epsilon: 0.09459946000850264    steps: 585    lr: 2.560000000000001e-06     evaluation reward: 7.13\nepisode: 2288   score: 5.0   memory length: 557562   epsilon: 0.09402526000850303    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 7.12\nepisode: 2289   score: 7.0   memory length: 557940   epsilon: 0.09327682000850354    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 7.12\nepisode: 2290   score: 5.0   memory length: 558227   epsilon: 0.09270856000850393    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 7.05\nepisode: 2291   score: 13.0   memory length: 558747   epsilon: 0.09167896000850463    steps: 520    lr: 2.560000000000001e-06     evaluation reward: 7.1\nepisode: 2292   score: 7.0   memory length: 559133   epsilon: 0.09091468000850515    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 7.12\nepisode: 2293   score: 10.0   memory length: 559661   epsilon: 0.08986924000850587    steps: 528    lr: 2.560000000000001e-06     evaluation reward: 7.15\nepisode: 2294   score: 5.0   memory length: 559986   epsilon: 0.0892257400085063    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 7.14\nepisode: 2295   score: 6.0   memory length: 560327   epsilon: 0.08855056000850677    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 7.15\nepisode: 2296   score: 10.0   memory length: 560866   epsilon: 0.08748334000850749    steps: 539    lr: 2.560000000000001e-06     evaluation reward: 7.12\nepisode: 2297   score: 9.0   memory length: 561331   epsilon: 0.08656264000850812    steps: 465    lr: 2.560000000000001e-06     evaluation reward: 7.17\nepisode: 2298   score: 8.0   memory length: 561806   epsilon: 0.08562214000850876    steps: 475    lr: 2.560000000000001e-06     evaluation reward: 7.18\nepisode: 2299   score: 8.0   memory length: 562251   epsilon: 0.08474104000850936    steps: 445    lr: 2.560000000000001e-06     evaluation reward: 7.22\nepisode: 2300   score: 7.0   memory length: 562644   epsilon: 0.0839629000085099    steps: 393    lr: 2.560000000000001e-06     evaluation reward: 7.21\nepisode: 2301   score: 5.0   memory length: 562933   epsilon: 0.08339068000851028    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 7.21\nepisode: 2302   score: 6.0   memory length: 563275   epsilon: 0.08271352000851075    steps: 342    lr: 2.560000000000001e-06     evaluation reward: 7.22\nepisode: 2303   score: 5.0   memory length: 563563   epsilon: 0.08214328000851114    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 7.23\nepisode: 2304   score: 9.0   memory length: 564021   epsilon: 0.08123644000851175    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 7.25\nepisode: 2305   score: 6.0   memory length: 564375   epsilon: 0.08053552000851223    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 7.26\nepisode: 2306   score: 10.0   memory length: 564750   epsilon: 0.07979302000851274    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 7.29\nepisode: 2307   score: 5.0   memory length: 565034   epsilon: 0.07923070000851312    steps: 284    lr: 2.560000000000001e-06     evaluation reward: 7.29\nepisode: 2308   score: 14.0   memory length: 565547   epsilon: 0.07821496000851381    steps: 513    lr: 2.560000000000001e-06     evaluation reward: 7.36\nepisode: 2309   score: 6.0   memory length: 565904   epsilon: 0.0775081000085143    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 7.37\nepisode: 2310   score: 4.0   memory length: 566164   epsilon: 0.07699330000851465    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 7.35\nepisode: 2311   score: 7.0   memory length: 566568   epsilon: 0.0761933800085152    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 7.35\nepisode: 2312   score: 4.0   memory length: 566809   epsilon: 0.07571620000851552    steps: 241    lr: 2.560000000000001e-06     evaluation reward: 7.32\nepisode: 2313   score: 7.0   memory length: 567190   epsilon: 0.07496182000851603    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 7.3\nepisode: 2314   score: 5.0   memory length: 567478   epsilon: 0.07439158000851642    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 7.31\nepisode: 2315   score: 10.0   memory length: 568002   epsilon: 0.07335406000851713    steps: 524    lr: 2.560000000000001e-06     evaluation reward: 7.36\nepisode: 2316   score: 5.0   memory length: 568347   epsilon: 0.0726709600085176    steps: 345    lr: 2.560000000000001e-06     evaluation reward: 7.34\nepisode: 2317   score: 12.0   memory length: 568887   epsilon: 0.07160176000851833    steps: 540    lr: 2.560000000000001e-06     evaluation reward: 7.39\nepisode: 2318   score: 6.0   memory length: 569206   epsilon: 0.07097014000851876    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 7.38\nepisode: 2319   score: 9.0   memory length: 569662   epsilon: 0.07006726000851937    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 7.4\nepisode: 2320   score: 8.0   memory length: 570093   epsilon: 0.06921388000851995    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 7.42\nepisode: 2321   score: 3.0   memory length: 570322   epsilon: 0.06876046000852026    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 7.35\nepisode: 2322   score: 9.0   memory length: 570664   epsilon: 0.06808330000852073    steps: 342    lr: 2.560000000000001e-06     evaluation reward: 7.39\nepisode: 2323   score: 7.0   memory length: 571068   epsilon: 0.06728338000852127    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 7.41\nepisode: 2324   score: 8.0   memory length: 571496   epsilon: 0.06643594000852185    steps: 428    lr: 2.560000000000001e-06     evaluation reward: 7.42\nepisode: 2325   score: 7.0   memory length: 571837   epsilon: 0.06576076000852231    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 7.43\nepisode: 2326   score: 6.0   memory length: 572189   epsilon: 0.06506380000852278    steps: 352    lr: 2.560000000000001e-06     evaluation reward: 7.36\nepisode: 2327   score: 7.0   memory length: 572532   epsilon: 0.06438466000852325    steps: 343    lr: 2.560000000000001e-06     evaluation reward: 7.39\nepisode: 2328   score: 9.0   memory length: 573035   epsilon: 0.06338872000852393    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 7.41\nepisode: 2329   score: 8.0   memory length: 573450   epsilon: 0.06256702000852449    steps: 415    lr: 2.560000000000001e-06     evaluation reward: 7.47\nepisode: 2330   score: 6.0   memory length: 573791   epsilon: 0.06189184000852495    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 7.47\nepisode: 2331   score: 5.0   memory length: 574115   epsilon: 0.061250320008525386    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 7.43\nepisode: 2332   score: 16.0   memory length: 574677   epsilon: 0.060137560008526145    steps: 562    lr: 2.560000000000001e-06     evaluation reward: 7.53\nepisode: 2333   score: 6.0   memory length: 575050   epsilon: 0.05939902000852665    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 7.49\nepisode: 2334   score: 16.0   memory length: 575599   epsilon: 0.05831200000852739    steps: 549    lr: 2.560000000000001e-06     evaluation reward: 7.58\nepisode: 2335   score: 7.0   memory length: 575958   epsilon: 0.057601180008527875    steps: 359    lr: 2.560000000000001e-06     evaluation reward: 7.6\nepisode: 2336   score: 8.0   memory length: 576413   epsilon: 0.05670028000852849    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 7.58\nepisode: 2337   score: 7.0   memory length: 576780   epsilon: 0.055973620008528985    steps: 367    lr: 2.560000000000001e-06     evaluation reward: 7.59\nepisode: 2338   score: 2.0   memory length: 576959   epsilon: 0.055619200008529227    steps: 179    lr: 2.560000000000001e-06     evaluation reward: 7.52\nepisode: 2339   score: 8.0   memory length: 577418   epsilon: 0.054710380008529846    steps: 459    lr: 2.560000000000001e-06     evaluation reward: 7.49\nepisode: 2340   score: 6.0   memory length: 577768   epsilon: 0.05401738000853032    steps: 350    lr: 2.560000000000001e-06     evaluation reward: 7.51\nepisode: 2341   score: 10.0   memory length: 578291   epsilon: 0.052981840008531025    steps: 523    lr: 2.560000000000001e-06     evaluation reward: 7.54\nepisode: 2342   score: 10.0   memory length: 578688   epsilon: 0.05219578000853156    steps: 397    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2343   score: 7.0   memory length: 579077   epsilon: 0.05142556000853209    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2344   score: 9.0   memory length: 579544   epsilon: 0.05050090000853272    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 7.59\nepisode: 2345   score: 8.0   memory length: 579983   epsilon: 0.04963168000853331    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2346   score: 8.0   memory length: 580480   epsilon: 0.04864762000853398    steps: 497    lr: 2.560000000000001e-06     evaluation reward: 7.58\nepisode: 2347   score: 9.0   memory length: 580999   epsilon: 0.04762000000853468    steps: 519    lr: 2.560000000000001e-06     evaluation reward: 7.57\nepisode: 2348   score: 7.0   memory length: 581401   epsilon: 0.046824040008535225    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 7.55\nepisode: 2349   score: 7.0   memory length: 581728   epsilon: 0.04617658000853567    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 7.55\nepisode: 2350   score: 3.0   memory length: 581960   epsilon: 0.04571722000853598    steps: 232    lr: 2.560000000000001e-06     evaluation reward: 7.51\nepisode: 2351   score: 7.0   memory length: 582310   epsilon: 0.04502422000853645    steps: 350    lr: 2.560000000000001e-06     evaluation reward: 7.5\nepisode: 2352   score: 8.0   memory length: 582731   epsilon: 0.04419064000853702    steps: 421    lr: 2.560000000000001e-06     evaluation reward: 7.51\nepisode: 2353   score: 5.0   memory length: 583043   epsilon: 0.04357288000853744    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 7.49\nepisode: 2354   score: 6.0   memory length: 583410   epsilon: 0.04284622000853794    steps: 367    lr: 2.560000000000001e-06     evaluation reward: 7.48\nepisode: 2355   score: 7.0   memory length: 583799   epsilon: 0.042076000008538464    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 7.48\nepisode: 2356   score: 5.0   memory length: 584089   epsilon: 0.041501800008538856    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 7.47\nepisode: 2357   score: 5.0   memory length: 584401   epsilon: 0.04088404000853928    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 7.43\nepisode: 2358   score: 8.0   memory length: 584854   epsilon: 0.03998710000853989    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 7.46\nepisode: 2359   score: 9.0   memory length: 585338   epsilon: 0.03902878000854054    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 7.49\nepisode: 2360   score: 7.0   memory length: 585724   epsilon: 0.038264500008541064    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 7.5\nepisode: 2361   score: 9.0   memory length: 586227   epsilon: 0.03726856000854174    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 7.53\nepisode: 2362   score: 12.0   memory length: 586813   epsilon: 0.036108280008542534    steps: 586    lr: 2.560000000000001e-06     evaluation reward: 7.58\nepisode: 2363   score: 7.0   memory length: 587200   epsilon: 0.03534202000854306    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 7.59\nepisode: 2364   score: 6.0   memory length: 587558   epsilon: 0.03463318000854354    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 7.51\nepisode: 2365   score: 5.0   memory length: 587832   epsilon: 0.03409066000854391    steps: 274    lr: 2.560000000000001e-06     evaluation reward: 7.47\nepisode: 2366   score: 12.0   memory length: 588341   epsilon: 0.0330828400085446    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 7.49\nepisode: 2367   score: 10.0   memory length: 588843   epsilon: 0.032088880008545276    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 7.53\nepisode: 2368   score: 7.0   memory length: 589255   epsilon: 0.03127312000854583    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 7.49\nepisode: 2369   score: 7.0   memory length: 589643   epsilon: 0.030504880008546356    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 7.48\nepisode: 2370   score: 9.0   memory length: 590144   epsilon: 0.029512900008547033    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 7.5\nepisode: 2371   score: 6.0   memory length: 590470   epsilon: 0.028867420008547473    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 7.5\nepisode: 2372   score: 7.0   memory length: 590856   epsilon: 0.028103140008547994    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 7.5\nepisode: 2373   score: 11.0   memory length: 591262   epsilon: 0.027299260008548543    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 7.52\nepisode: 2374   score: 13.0   memory length: 591799   epsilon: 0.026236000008549268    steps: 537    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2375   score: 7.0   memory length: 592188   epsilon: 0.025465780008549793    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 7.57\nepisode: 2376   score: 9.0   memory length: 592663   epsilon: 0.024525280008550435    steps: 475    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2377   score: 12.0   memory length: 593116   epsilon: 0.023628340008551046    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2378   score: 7.0   memory length: 593486   epsilon: 0.022895740008551546    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 7.56\nepisode: 2379   score: 6.0   memory length: 593846   epsilon: 0.022182940008552032    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 7.53\nepisode: 2380   score: 10.0   memory length: 594218   epsilon: 0.021446380008552535    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 7.58\nepisode: 2381   score: 11.0   memory length: 594743   epsilon: 0.020406880008553244    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 7.64\nepisode: 2382   score: 11.0   memory length: 595171   epsilon: 0.01955944000855382    steps: 428    lr: 2.560000000000001e-06     evaluation reward: 7.69\nepisode: 2383   score: 7.0   memory length: 595541   epsilon: 0.01882684000855432    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 7.68\nepisode: 2384   score: 11.0   memory length: 595947   epsilon: 0.01802296000855487    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 7.74\nepisode: 2385   score: 6.0   memory length: 596302   epsilon: 0.01732006000855535    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 7.76\nepisode: 2386   score: 6.0   memory length: 596638   epsilon: 0.016654780008555803    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 7.75\nepisode: 2387   score: 8.0   memory length: 597057   epsilon: 0.01582516000855637    steps: 419    lr: 2.560000000000001e-06     evaluation reward: 7.71\nepisode: 2388   score: 10.0   memory length: 597455   epsilon: 0.015037120008556391    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 7.76\nepisode: 2389   score: 9.0   memory length: 597911   epsilon: 0.014134240008556216    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 7.78\nepisode: 2390   score: 9.0   memory length: 598366   epsilon: 0.013233340008556041    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 7.82\nepisode: 2391   score: 6.0   memory length: 598687   epsilon: 0.012597760008555918    steps: 321    lr: 2.560000000000001e-06     evaluation reward: 7.75\nepisode: 2392   score: 5.0   memory length: 598960   epsilon: 0.012057220008555813    steps: 273    lr: 2.560000000000001e-06     evaluation reward: 7.73\nepisode: 2393   score: 10.0   memory length: 599358   epsilon: 0.01126918000855566    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 7.73\nepisode: 2394   score: 11.0   memory length: 599915   epsilon: 0.010166320008555446    steps: 557    lr: 2.560000000000001e-06     evaluation reward: 7.79\nepisode: 2395   score: 5.0   memory length: 600205   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.78\nepisode: 2396   score: 5.0   memory length: 600495   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.73\nepisode: 2397   score: 7.0   memory length: 600879   epsilon: 0.009998020008555413    steps: 384    lr: 1.0240000000000005e-06     evaluation reward: 7.71\nepisode: 2398   score: 7.0   memory length: 601253   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 7.7\nepisode: 2399   score: 6.0   memory length: 601597   epsilon: 0.009998020008555413    steps: 344    lr: 1.0240000000000005e-06     evaluation reward: 7.68\nepisode: 2400   score: 8.0   memory length: 601970   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 7.69\nepisode: 2401   score: 9.0   memory length: 602442   epsilon: 0.009998020008555413    steps: 472    lr: 1.0240000000000005e-06     evaluation reward: 7.73\nepisode: 2402   score: 4.0   memory length: 602683   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.71\nepisode: 2403   score: 13.0   memory length: 603274   epsilon: 0.009998020008555413    steps: 591    lr: 1.0240000000000005e-06     evaluation reward: 7.79\nepisode: 2404   score: 4.0   memory length: 603514   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.74\nepisode: 2405   score: 6.0   memory length: 603852   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 7.74\nepisode: 2406   score: 9.0   memory length: 604376   epsilon: 0.009998020008555413    steps: 524    lr: 1.0240000000000005e-06     evaluation reward: 7.73\nepisode: 2407   score: 11.0   memory length: 604795   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 7.79\nepisode: 2408   score: 7.0   memory length: 605185   epsilon: 0.009998020008555413    steps: 390    lr: 1.0240000000000005e-06     evaluation reward: 7.72\nepisode: 2409   score: 7.0   memory length: 605553   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 7.73\nepisode: 2410   score: 8.0   memory length: 606028   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 7.77\nepisode: 2411   score: 4.0   memory length: 606268   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.74\nepisode: 2412   score: 8.0   memory length: 606725   epsilon: 0.009998020008555413    steps: 457    lr: 1.0240000000000005e-06     evaluation reward: 7.78\nepisode: 2413   score: 6.0   memory length: 607038   epsilon: 0.009998020008555413    steps: 313    lr: 1.0240000000000005e-06     evaluation reward: 7.77\nepisode: 2414   score: 6.0   memory length: 607351   epsilon: 0.009998020008555413    steps: 313    lr: 1.0240000000000005e-06     evaluation reward: 7.78\nepisode: 2415   score: 4.0   memory length: 607592   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.72\nepisode: 2416   score: 11.0   memory length: 608134   epsilon: 0.009998020008555413    steps: 542    lr: 1.0240000000000005e-06     evaluation reward: 7.78\nepisode: 2417   score: 12.0   memory length: 608679   epsilon: 0.009998020008555413    steps: 545    lr: 1.0240000000000005e-06     evaluation reward: 7.78\nepisode: 2418   score: 3.0   memory length: 608910   epsilon: 0.009998020008555413    steps: 231    lr: 1.0240000000000005e-06     evaluation reward: 7.75\nepisode: 2419   score: 7.0   memory length: 609253   epsilon: 0.009998020008555413    steps: 343    lr: 1.0240000000000005e-06     evaluation reward: 7.73\nepisode: 2420   score: 13.0   memory length: 609811   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 7.78\nepisode: 2421   score: 4.0   memory length: 610051   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.79\nepisode: 2422   score: 6.0   memory length: 610410   epsilon: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     evaluation reward: 7.76\nepisode: 2423   score: 8.0   memory length: 610816   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 7.77\nepisode: 2424   score: 4.0   memory length: 611056   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.73\nepisode: 2425   score: 4.0   memory length: 611296   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.7\nepisode: 2426   score: 5.0   memory length: 611586   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.69\nepisode: 2427   score: 5.0   memory length: 611874   epsilon: 0.009998020008555413    steps: 288    lr: 1.0240000000000005e-06     evaluation reward: 7.67\nepisode: 2428   score: 9.0   memory length: 612222   epsilon: 0.009998020008555413    steps: 348    lr: 1.0240000000000005e-06     evaluation reward: 7.67\nepisode: 2429   score: 7.0   memory length: 612646   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 7.66\nepisode: 2430   score: 9.0   memory length: 613136   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 7.69\nepisode: 2431   score: 8.0   memory length: 613557   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 7.72\nepisode: 2432   score: 8.0   memory length: 613949   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 7.64\nepisode: 2433   score: 11.0   memory length: 614353   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 7.69\nepisode: 2434   score: 14.0   memory length: 614857   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 7.67\nepisode: 2435   score: 4.0   memory length: 615097   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.64\nepisode: 2436   score: 6.0   memory length: 615452   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 7.62\nepisode: 2437   score: 10.0   memory length: 615975   epsilon: 0.009998020008555413    steps: 523    lr: 1.0240000000000005e-06     evaluation reward: 7.65\nepisode: 2438   score: 6.0   memory length: 616296   epsilon: 0.009998020008555413    steps: 321    lr: 1.0240000000000005e-06     evaluation reward: 7.69\nepisode: 2439   score: 9.0   memory length: 616688   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 7.7\nepisode: 2440   score: 6.0   memory length: 617048   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 7.7\nepisode: 2441   score: 4.0   memory length: 617288   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.64\nepisode: 2442   score: 7.0   memory length: 617633   epsilon: 0.009998020008555413    steps: 345    lr: 1.0240000000000005e-06     evaluation reward: 7.61\nepisode: 2443   score: 7.0   memory length: 618056   epsilon: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     evaluation reward: 7.61\nepisode: 2444   score: 6.0   memory length: 618352   epsilon: 0.009998020008555413    steps: 296    lr: 1.0240000000000005e-06     evaluation reward: 7.58\nepisode: 2445   score: 4.0   memory length: 618592   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.54\nepisode: 2446   score: 4.0   memory length: 618832   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.5\nepisode: 2447   score: 4.0   memory length: 619072   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2448   score: 7.0   memory length: 619513   epsilon: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2449   score: 7.0   memory length: 619884   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2450   score: 5.0   memory length: 620174   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.47\nepisode: 2451   score: 6.0   memory length: 620512   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 7.46\nepisode: 2452   score: 6.0   memory length: 620887   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 7.44\nepisode: 2453   score: 7.0   memory length: 621310   epsilon: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     evaluation reward: 7.46\nepisode: 2454   score: 8.0   memory length: 621744   epsilon: 0.009998020008555413    steps: 434    lr: 1.0240000000000005e-06     evaluation reward: 7.48\nepisode: 2455   score: 4.0   memory length: 621984   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2456   score: 6.0   memory length: 622312   epsilon: 0.009998020008555413    steps: 328    lr: 1.0240000000000005e-06     evaluation reward: 7.46\nepisode: 2457   score: 8.0   memory length: 622763   epsilon: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     evaluation reward: 7.49\nepisode: 2458   score: 9.0   memory length: 623187   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 7.5\nepisode: 2459   score: 11.0   memory length: 623678   epsilon: 0.009998020008555413    steps: 491    lr: 1.0240000000000005e-06     evaluation reward: 7.52\nepisode: 2460   score: 11.0   memory length: 624232   epsilon: 0.009998020008555413    steps: 554    lr: 1.0240000000000005e-06     evaluation reward: 7.56\nepisode: 2461   score: 8.0   memory length: 624664   epsilon: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     evaluation reward: 7.55\nepisode: 2462   score: 8.0   memory length: 625084   epsilon: 0.009998020008555413    steps: 420    lr: 1.0240000000000005e-06     evaluation reward: 7.51\nepisode: 2463   score: 11.0   memory length: 625553   epsilon: 0.009998020008555413    steps: 469    lr: 1.0240000000000005e-06     evaluation reward: 7.55\nepisode: 2464   score: 7.0   memory length: 625959   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 7.56\nepisode: 2465   score: 4.0   memory length: 626199   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.55\nepisode: 2466   score: 5.0   memory length: 626489   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.48\nepisode: 2467   score: 6.0   memory length: 626868   epsilon: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     evaluation reward: 7.44\nepisode: 2468   score: 9.0   memory length: 627341   epsilon: 0.009998020008555413    steps: 473    lr: 1.0240000000000005e-06     evaluation reward: 7.46\nepisode: 2469   score: 6.0   memory length: 627664   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2470   score: 5.0   memory length: 627954   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.41\nepisode: 2471   score: 10.0   memory length: 628312   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2472   score: 8.0   memory length: 628752   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 7.46\nepisode: 2473   score: 4.0   memory length: 628992   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.39\nepisode: 2474   score: 10.0   memory length: 629489   epsilon: 0.009998020008555413    steps: 497    lr: 1.0240000000000005e-06     evaluation reward: 7.36\nepisode: 2475   score: 4.0   memory length: 629729   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.33\nepisode: 2476   score: 7.0   memory length: 630119   epsilon: 0.009998020008555413    steps: 390    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2477   score: 6.0   memory length: 630463   epsilon: 0.009998020008555413    steps: 344    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2478   score: 6.0   memory length: 630816   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 7.24\nepisode: 2479   score: 5.0   memory length: 631106   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2480   score: 5.0   memory length: 631396   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2481   score: 9.0   memory length: 631792   epsilon: 0.009998020008555413    steps: 396    lr: 1.0240000000000005e-06     evaluation reward: 7.16\nepisode: 2482   score: 5.0   memory length: 632083   epsilon: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     evaluation reward: 7.1\nepisode: 2483   score: 6.0   memory length: 632440   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 7.09\nepisode: 2484   score: 5.0   memory length: 632730   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.03\nepisode: 2485   score: 12.0   memory length: 633139   epsilon: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     evaluation reward: 7.09\nepisode: 2486   score: 10.0   memory length: 633628   epsilon: 0.009998020008555413    steps: 489    lr: 1.0240000000000005e-06     evaluation reward: 7.13\nepisode: 2487   score: 6.0   memory length: 633950   epsilon: 0.009998020008555413    steps: 322    lr: 1.0240000000000005e-06     evaluation reward: 7.11\nepisode: 2488   score: 7.0   memory length: 634341   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 7.08\nepisode: 2489   score: 5.0   memory length: 634655   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 7.04\nepisode: 2490   score: 7.0   memory length: 635047   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 7.02\nepisode: 2491   score: 9.0   memory length: 635551   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 7.05\nepisode: 2492   score: 7.0   memory length: 635919   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 7.07\nepisode: 2493   score: 13.0   memory length: 636303   epsilon: 0.009998020008555413    steps: 384    lr: 1.0240000000000005e-06     evaluation reward: 7.1\nepisode: 2494   score: 12.0   memory length: 636775   epsilon: 0.009998020008555413    steps: 472    lr: 1.0240000000000005e-06     evaluation reward: 7.11\nepisode: 2495   score: 6.0   memory length: 637110   epsilon: 0.009998020008555413    steps: 335    lr: 1.0240000000000005e-06     evaluation reward: 7.12\nepisode: 2496   score: 6.0   memory length: 637483   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 7.13\nepisode: 2497   score: 9.0   memory length: 637971   epsilon: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2498   score: 7.0   memory length: 638362   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2499   score: 6.0   memory length: 638723   epsilon: 0.009998020008555413    steps: 361    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2500   score: 4.0   memory length: 638964   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.11\nepisode: 2501   score: 8.0   memory length: 639385   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 7.1\nepisode: 2502   score: 9.0   memory length: 639810   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2503   score: 10.0   memory length: 640291   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 7.12\nepisode: 2504   score: 8.0   memory length: 640666   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 7.16\nepisode: 2505   score: 11.0   memory length: 641248   epsilon: 0.009998020008555413    steps: 582    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2506   score: 5.0   memory length: 641562   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 7.17\nepisode: 2507   score: 9.0   memory length: 641927   epsilon: 0.009998020008555413    steps: 365    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2508   score: 12.0   memory length: 642529   epsilon: 0.009998020008555413    steps: 602    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2509   score: 10.0   memory length: 642891   epsilon: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2510   score: 6.0   memory length: 643274   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2511   score: 9.0   memory length: 643757   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2512   score: 3.0   memory length: 643967   epsilon: 0.009998020008555413    steps: 210    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2513   score: 8.0   memory length: 644403   epsilon: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2514   score: 7.0   memory length: 644792   epsilon: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     evaluation reward: 7.24\nepisode: 2515   score: 4.0   memory length: 645032   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.24\nepisode: 2516   score: 5.0   memory length: 645346   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2517   score: 11.0   memory length: 645723   epsilon: 0.009998020008555413    steps: 377    lr: 1.0240000000000005e-06     evaluation reward: 7.17\nepisode: 2518   score: 6.0   memory length: 646106   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2519   score: 7.0   memory length: 646517   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2520   score: 9.0   memory length: 646944   epsilon: 0.009998020008555413    steps: 427    lr: 1.0240000000000005e-06     evaluation reward: 7.16\nepisode: 2521   score: 8.0   memory length: 647418   epsilon: 0.009998020008555413    steps: 474    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2522   score: 8.0   memory length: 647874   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 7.22\nepisode: 2523   score: 4.0   memory length: 648114   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2524   score: 7.0   memory length: 648457   epsilon: 0.009998020008555413    steps: 343    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2525   score: 6.0   memory length: 648814   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2526   score: 8.0   memory length: 649196   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2527   score: 9.0   memory length: 649662   epsilon: 0.009998020008555413    steps: 466    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2528   score: 4.0   memory length: 649903   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2529   score: 9.0   memory length: 650372   epsilon: 0.009998020008555413    steps: 469    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2530   score: 9.0   memory length: 650738   epsilon: 0.009998020008555413    steps: 366    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2531   score: 11.0   memory length: 651296   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2532   score: 8.0   memory length: 651698   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2533   score: 4.0   memory length: 651955   epsilon: 0.009998020008555413    steps: 257    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2534   score: 7.0   memory length: 652383   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 7.16\nepisode: 2535   score: 7.0   memory length: 652794   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 7.19\nepisode: 2536   score: 6.0   memory length: 653169   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 7.19\nepisode: 2537   score: 5.0   memory length: 653492   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 7.14\nepisode: 2538   score: 7.0   memory length: 653819   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2539   score: 4.0   memory length: 654059   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.1\nepisode: 2540   score: 6.0   memory length: 654403   epsilon: 0.009998020008555413    steps: 344    lr: 1.0240000000000005e-06     evaluation reward: 7.1\nepisode: 2541   score: 4.0   memory length: 654643   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.1\nepisode: 2542   score: 12.0   memory length: 655232   epsilon: 0.009998020008555413    steps: 589    lr: 1.0240000000000005e-06     evaluation reward: 7.15\nepisode: 2543   score: 8.0   memory length: 655641   epsilon: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     evaluation reward: 7.16\nepisode: 2544   score: 9.0   memory length: 656147   epsilon: 0.009998020008555413    steps: 506    lr: 1.0240000000000005e-06     evaluation reward: 7.19\nepisode: 2545   score: 10.0   memory length: 656655   epsilon: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2546   score: 8.0   memory length: 657104   epsilon: 0.009998020008555413    steps: 449    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2547   score: 8.0   memory length: 657523   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 7.33\nepisode: 2548   score: 5.0   memory length: 657833   epsilon: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2549   score: 8.0   memory length: 658239   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 7.32\nepisode: 2550   score: 7.0   memory length: 658607   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 7.34\nepisode: 2551   score: 9.0   memory length: 659032   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 7.37\nepisode: 2552   score: 11.0   memory length: 659523   epsilon: 0.009998020008555413    steps: 491    lr: 1.0240000000000005e-06     evaluation reward: 7.42\nepisode: 2553   score: 11.0   memory length: 660033   epsilon: 0.009998020008555413    steps: 510    lr: 1.0240000000000005e-06     evaluation reward: 7.46\nepisode: 2554   score: 3.0   memory length: 660243   epsilon: 0.009998020008555413    steps: 210    lr: 1.0240000000000005e-06     evaluation reward: 7.41\nepisode: 2555   score: 5.0   memory length: 660558   epsilon: 0.009998020008555413    steps: 315    lr: 1.0240000000000005e-06     evaluation reward: 7.42\nepisode: 2556   score: 9.0   memory length: 661066   epsilon: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     evaluation reward: 7.45\nepisode: 2557   score: 5.0   memory length: 661356   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.42\nepisode: 2558   score: 5.0   memory length: 661670   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 7.38\nepisode: 2559   score: 7.0   memory length: 662061   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 7.34\nepisode: 2560   score: 9.0   memory length: 662486   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 7.32\nepisode: 2561   score: 7.0   memory length: 662875   epsilon: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2562   score: 5.0   memory length: 663165   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2563   score: 9.0   memory length: 663672   epsilon: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2564   score: 6.0   memory length: 664055   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2565   score: 6.0   memory length: 664422   epsilon: 0.009998020008555413    steps: 367    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2566   score: 6.0   memory length: 664761   epsilon: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2567   score: 9.0   memory length: 665185   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2568   score: 6.0   memory length: 665568   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2569   score: 8.0   memory length: 665982   epsilon: 0.009998020008555413    steps: 414    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2570   score: 6.0   memory length: 666301   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2571   score: 7.0   memory length: 666708   epsilon: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2572   score: 6.0   memory length: 667035   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2573   score: 4.0   memory length: 667275   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2574   score: 7.0   memory length: 667639   epsilon: 0.009998020008555413    steps: 364    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2575   score: 6.0   memory length: 668014   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2576   score: 4.0   memory length: 668254   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.22\nepisode: 2577   score: 7.0   memory length: 668645   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2578   score: 11.0   memory length: 669085   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2579   score: 5.0   memory length: 669375   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2580   score: 6.0   memory length: 669709   epsilon: 0.009998020008555413    steps: 334    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2581   score: 6.0   memory length: 670029   epsilon: 0.009998020008555413    steps: 320    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2582   score: 8.0   memory length: 670430   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2583   score: 8.0   memory length: 670882   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2584   score: 7.0   memory length: 671250   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 7.33\nepisode: 2585   score: 11.0   memory length: 671808   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 7.32\nepisode: 2586   score: 6.0   memory length: 672191   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2587   score: 7.0   memory length: 672580   epsilon: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2588   score: 5.0   memory length: 672889   epsilon: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2589   score: 6.0   memory length: 673227   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2590   score: 7.0   memory length: 673638   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2591   score: 10.0   memory length: 674142   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2592   score: 7.0   memory length: 674510   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2593   score: 11.0   memory length: 675071   epsilon: 0.009998020008555413    steps: 561    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2594   score: 6.0   memory length: 675406   epsilon: 0.009998020008555413    steps: 335    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2595   score: 6.0   memory length: 675747   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2596   score: 5.0   memory length: 676071   epsilon: 0.009998020008555413    steps: 324    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2597   score: 7.0   memory length: 676441   epsilon: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2598   score: 6.0   memory length: 676781   epsilon: 0.009998020008555413    steps: 340    lr: 1.0240000000000005e-06     evaluation reward: 7.17\nepisode: 2599   score: 7.0   memory length: 677171   epsilon: 0.009998020008555413    steps: 390    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2600   score: 11.0   memory length: 677665   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2601   score: 7.0   memory length: 678051   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 7.24\nepisode: 2602   score: 10.0   memory length: 678566   epsilon: 0.009998020008555413    steps: 515    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2603   score: 11.0   memory length: 679071   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2604   score: 13.0   memory length: 679677   epsilon: 0.009998020008555413    steps: 606    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2605   score: 9.0   memory length: 680171   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2606   score: 5.0   memory length: 680485   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 7.29\nepisode: 2607   score: 6.0   memory length: 680847   epsilon: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2608   score: 7.0   memory length: 681255   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2609   score: 6.0   memory length: 681638   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 7.17\nepisode: 2610   score: 7.0   memory length: 682039   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2611   score: 3.0   memory length: 682249   epsilon: 0.009998020008555413    steps: 210    lr: 1.0240000000000005e-06     evaluation reward: 7.12\nepisode: 2612   score: 10.0   memory length: 682750   epsilon: 0.009998020008555413    steps: 501    lr: 1.0240000000000005e-06     evaluation reward: 7.19\nepisode: 2613   score: 6.0   memory length: 683090   epsilon: 0.009998020008555413    steps: 340    lr: 1.0240000000000005e-06     evaluation reward: 7.17\nepisode: 2614   score: 6.0   memory length: 683431   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 7.16\nepisode: 2615   score: 10.0   memory length: 683905   epsilon: 0.009998020008555413    steps: 474    lr: 1.0240000000000005e-06     evaluation reward: 7.22\nepisode: 2616   score: 10.0   memory length: 684406   epsilon: 0.009998020008555413    steps: 501    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2617   score: 6.0   memory length: 684747   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 7.22\nepisode: 2618   score: 6.0   memory length: 685066   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 7.22\nepisode: 2619   score: 10.0   memory length: 685558   epsilon: 0.009998020008555413    steps: 492    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2620   score: 16.0   memory length: 686053   epsilon: 0.009998020008555413    steps: 495    lr: 1.0240000000000005e-06     evaluation reward: 7.32\nepisode: 2621   score: 4.0   memory length: 686293   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2622   score: 8.0   memory length: 686700   epsilon: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2623   score: 4.0   memory length: 686964   epsilon: 0.009998020008555413    steps: 264    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2624   score: 9.0   memory length: 687450   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2625   score: 7.0   memory length: 687858   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2626   score: 9.0   memory length: 688282   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 7.32\nepisode: 2627   score: 7.0   memory length: 688640   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2628   score: 4.0   memory length: 688881   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2629   score: 9.0   memory length: 689332   epsilon: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     evaluation reward: 7.3\nepisode: 2630   score: 7.0   memory length: 689702   epsilon: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2631   score: 4.0   memory length: 689965   epsilon: 0.009998020008555413    steps: 263    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2632   score: 7.0   memory length: 690357   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2633   score: 4.0   memory length: 690598   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.2\nepisode: 2634   score: 4.0   memory length: 690839   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.17\nepisode: 2635   score: 11.0   memory length: 691244   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 7.21\nepisode: 2636   score: 12.0   memory length: 691715   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2637   score: 9.0   memory length: 692173   epsilon: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2638   score: 4.0   memory length: 692413   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2639   score: 8.0   memory length: 692819   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 7.32\nepisode: 2640   score: 10.0   memory length: 693366   epsilon: 0.009998020008555413    steps: 547    lr: 1.0240000000000005e-06     evaluation reward: 7.36\nepisode: 2641   score: 4.0   memory length: 693607   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.36\nepisode: 2642   score: 9.0   memory length: 694135   epsilon: 0.009998020008555413    steps: 528    lr: 1.0240000000000005e-06     evaluation reward: 7.33\nepisode: 2643   score: 10.0   memory length: 694624   epsilon: 0.009998020008555413    steps: 489    lr: 1.0240000000000005e-06     evaluation reward: 7.35\nepisode: 2644   score: 8.0   memory length: 695061   epsilon: 0.009998020008555413    steps: 437    lr: 1.0240000000000005e-06     evaluation reward: 7.34\nepisode: 2645   score: 7.0   memory length: 695456   epsilon: 0.009998020008555413    steps: 395    lr: 1.0240000000000005e-06     evaluation reward: 7.31\nepisode: 2646   score: 5.0   memory length: 695746   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.28\nepisode: 2647   score: 7.0   memory length: 696138   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 7.27\nepisode: 2648   score: 4.0   memory length: 696379   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.26\nepisode: 2649   score: 7.0   memory length: 696749   epsilon: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     evaluation reward: 7.25\nepisode: 2650   score: 5.0   memory length: 697080   epsilon: 0.009998020008555413    steps: 331    lr: 1.0240000000000005e-06     evaluation reward: 7.23\nepisode: 2651   score: 5.0   memory length: 697370   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 7.19\nepisode: 2652   score: 6.0   memory length: 697744   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 7.14\nepisode: 2653   score: 10.0   memory length: 698136   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 7.13\nepisode: 2654   score: 9.0   memory length: 698568   epsilon: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     evaluation reward: 7.19\nepisode: 2655   score: 4.0   memory length: 698808   epsilon: 0.009998020008555413    steps: 240    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2656   score: 4.0   memory length: 699049   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 7.13\nepisode: 2657   score: 10.0   memory length: 699538   epsilon: 0.009998020008555413    steps: 489    lr: 1.0240000000000005e-06     evaluation reward: 7.18\nepisode: 2658   score: 10.0   memory length: 700039   epsilon: 0.009998020008555413    steps: 501    lr: 4.0960000000000023e-07     evaluation reward: 7.23\nepisode: 2659   score: 10.0   memory length: 700453   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 7.26\nepisode: 2660   score: 10.0   memory length: 700848   epsilon: 0.009998020008555413    steps: 395    lr: 4.0960000000000023e-07     evaluation reward: 7.27\nepisode: 2661   score: 5.0   memory length: 701138   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.25\nepisode: 2662   score: 16.0   memory length: 701651   epsilon: 0.009998020008555413    steps: 513    lr: 4.0960000000000023e-07     evaluation reward: 7.36\nepisode: 2663   score: 11.0   memory length: 702169   epsilon: 0.009998020008555413    steps: 518    lr: 4.0960000000000023e-07     evaluation reward: 7.38\nepisode: 2664   score: 11.0   memory length: 702726   epsilon: 0.009998020008555413    steps: 557    lr: 4.0960000000000023e-07     evaluation reward: 7.43\nepisode: 2665   score: 10.0   memory length: 703203   epsilon: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     evaluation reward: 7.47\nepisode: 2666   score: 12.0   memory length: 703674   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 7.53\nepisode: 2667   score: 8.0   memory length: 704114   epsilon: 0.009998020008555413    steps: 440    lr: 4.0960000000000023e-07     evaluation reward: 7.52\nepisode: 2668   score: 10.0   memory length: 704618   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 7.56\nepisode: 2669   score: 8.0   memory length: 705024   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 7.56\nepisode: 2670   score: 7.0   memory length: 705434   epsilon: 0.009998020008555413    steps: 410    lr: 4.0960000000000023e-07     evaluation reward: 7.57\nepisode: 2671   score: 8.0   memory length: 705859   epsilon: 0.009998020008555413    steps: 425    lr: 4.0960000000000023e-07     evaluation reward: 7.58\nepisode: 2672   score: 11.0   memory length: 706379   epsilon: 0.009998020008555413    steps: 520    lr: 4.0960000000000023e-07     evaluation reward: 7.63\nepisode: 2673   score: 6.0   memory length: 706718   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 7.65\nepisode: 2674   score: 8.0   memory length: 707157   epsilon: 0.009998020008555413    steps: 439    lr: 4.0960000000000023e-07     evaluation reward: 7.66\nepisode: 2675   score: 8.0   memory length: 707560   epsilon: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     evaluation reward: 7.68\nepisode: 2676   score: 6.0   memory length: 707905   epsilon: 0.009998020008555413    steps: 345    lr: 4.0960000000000023e-07     evaluation reward: 7.7\nepisode: 2677   score: 7.0   memory length: 708264   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 7.7\nepisode: 2678   score: 4.0   memory length: 708504   epsilon: 0.009998020008555413    steps: 240    lr: 4.0960000000000023e-07     evaluation reward: 7.63\nepisode: 2679   score: 9.0   memory length: 708909   epsilon: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     evaluation reward: 7.67\nepisode: 2680   score: 7.0   memory length: 709316   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.68\nepisode: 2681   score: 6.0   memory length: 709666   epsilon: 0.009998020008555413    steps: 350    lr: 4.0960000000000023e-07     evaluation reward: 7.68\nepisode: 2682   score: 5.0   memory length: 709956   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.65\nepisode: 2683   score: 14.0   memory length: 710641   epsilon: 0.009998020008555413    steps: 685    lr: 4.0960000000000023e-07     evaluation reward: 7.71\nepisode: 2684   score: 14.0   memory length: 711178   epsilon: 0.009998020008555413    steps: 537    lr: 4.0960000000000023e-07     evaluation reward: 7.78\nepisode: 2685   score: 10.0   memory length: 711647   epsilon: 0.009998020008555413    steps: 469    lr: 4.0960000000000023e-07     evaluation reward: 7.77\nepisode: 2686   score: 6.0   memory length: 711988   epsilon: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     evaluation reward: 7.77\nepisode: 2687   score: 5.0   memory length: 712276   epsilon: 0.009998020008555413    steps: 288    lr: 4.0960000000000023e-07     evaluation reward: 7.75\nepisode: 2688   score: 8.0   memory length: 712657   epsilon: 0.009998020008555413    steps: 381    lr: 4.0960000000000023e-07     evaluation reward: 7.78\nepisode: 2689   score: 7.0   memory length: 713009   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 7.79\nepisode: 2690   score: 6.0   memory length: 713368   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 7.78\nepisode: 2691   score: 16.0   memory length: 713878   epsilon: 0.009998020008555413    steps: 510    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2692   score: 9.0   memory length: 714372   epsilon: 0.009998020008555413    steps: 494    lr: 4.0960000000000023e-07     evaluation reward: 7.86\nepisode: 2693   score: 4.0   memory length: 714612   epsilon: 0.009998020008555413    steps: 240    lr: 4.0960000000000023e-07     evaluation reward: 7.79\nepisode: 2694   score: 12.0   memory length: 715088   epsilon: 0.009998020008555413    steps: 476    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2695   score: 9.0   memory length: 715561   epsilon: 0.009998020008555413    steps: 473    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2696   score: 4.0   memory length: 715801   epsilon: 0.009998020008555413    steps: 240    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2697   score: 8.0   memory length: 716203   epsilon: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2698   score: 8.0   memory length: 716628   epsilon: 0.009998020008555413    steps: 425    lr: 4.0960000000000023e-07     evaluation reward: 7.9\nepisode: 2699   score: 6.0   memory length: 716988   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 7.89\nepisode: 2700   score: 16.0   memory length: 717593   epsilon: 0.009998020008555413    steps: 605    lr: 4.0960000000000023e-07     evaluation reward: 7.94\nepisode: 2701   score: 10.0   memory length: 718072   epsilon: 0.009998020008555413    steps: 479    lr: 4.0960000000000023e-07     evaluation reward: 7.97\nepisode: 2702   score: 6.0   memory length: 718395   epsilon: 0.009998020008555413    steps: 323    lr: 4.0960000000000023e-07     evaluation reward: 7.93\nepisode: 2703   score: 6.0   memory length: 718734   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2704   score: 5.0   memory length: 719022   epsilon: 0.009998020008555413    steps: 288    lr: 4.0960000000000023e-07     evaluation reward: 7.8\nepisode: 2705   score: 4.0   memory length: 719262   epsilon: 0.009998020008555413    steps: 240    lr: 4.0960000000000023e-07     evaluation reward: 7.75\nepisode: 2706   score: 12.0   memory length: 719819   epsilon: 0.009998020008555413    steps: 557    lr: 4.0960000000000023e-07     evaluation reward: 7.82\nepisode: 2707   score: 6.0   memory length: 720139   epsilon: 0.009998020008555413    steps: 320    lr: 4.0960000000000023e-07     evaluation reward: 7.82\nepisode: 2708   score: 7.0   memory length: 720508   epsilon: 0.009998020008555413    steps: 369    lr: 4.0960000000000023e-07     evaluation reward: 7.82\nepisode: 2709   score: 5.0   memory length: 720798   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.81\nepisode: 2710   score: 7.0   memory length: 721195   epsilon: 0.009998020008555413    steps: 397    lr: 4.0960000000000023e-07     evaluation reward: 7.81\nepisode: 2711   score: 10.0   memory length: 721715   epsilon: 0.009998020008555413    steps: 520    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2712   score: 11.0   memory length: 722278   epsilon: 0.009998020008555413    steps: 563    lr: 4.0960000000000023e-07     evaluation reward: 7.89\nepisode: 2713   score: 9.0   memory length: 722621   epsilon: 0.009998020008555413    steps: 343    lr: 4.0960000000000023e-07     evaluation reward: 7.92\nepisode: 2714   score: 6.0   memory length: 723004   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 7.92\nepisode: 2715   score: 6.0   memory length: 723363   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2716   score: 6.0   memory length: 723745   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2717   score: 7.0   memory length: 724115   epsilon: 0.009998020008555413    steps: 370    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2718   score: 6.0   memory length: 724434   epsilon: 0.009998020008555413    steps: 319    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2719   score: 7.0   memory length: 724807   epsilon: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     evaluation reward: 7.82\nepisode: 2720   score: 7.0   memory length: 725215   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 7.73\nepisode: 2721   score: 7.0   memory length: 725584   epsilon: 0.009998020008555413    steps: 369    lr: 4.0960000000000023e-07     evaluation reward: 7.76\nepisode: 2722   score: 8.0   memory length: 726025   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 7.76\nepisode: 2723   score: 5.0   memory length: 726315   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.77\nepisode: 2724   score: 8.0   memory length: 726692   epsilon: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     evaluation reward: 7.76\nepisode: 2725   score: 6.0   memory length: 727031   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 7.75\nepisode: 2726   score: 15.0   memory length: 727690   epsilon: 0.009998020008555413    steps: 659    lr: 4.0960000000000023e-07     evaluation reward: 7.81\nepisode: 2727   score: 6.0   memory length: 728012   epsilon: 0.009998020008555413    steps: 322    lr: 4.0960000000000023e-07     evaluation reward: 7.8\nepisode: 2728   score: 8.0   memory length: 728447   epsilon: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     evaluation reward: 7.84\nepisode: 2729   score: 10.0   memory length: 728981   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 7.85\nepisode: 2730   score: 10.0   memory length: 729373   epsilon: 0.009998020008555413    steps: 392    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2731   score: 4.0   memory length: 729613   epsilon: 0.009998020008555413    steps: 240    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2732   score: 7.0   memory length: 730001   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2733   score: 8.0   memory length: 730378   epsilon: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     evaluation reward: 7.92\nepisode: 2734   score: 8.0   memory length: 730755   epsilon: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     evaluation reward: 7.96\nepisode: 2735   score: 7.0   memory length: 731161   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 7.92\nepisode: 2736   score: 12.0   memory length: 731637   epsilon: 0.009998020008555413    steps: 476    lr: 4.0960000000000023e-07     evaluation reward: 7.92\nepisode: 2737   score: 5.0   memory length: 731935   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 7.88\nepisode: 2738   score: 9.0   memory length: 732376   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 7.93\nepisode: 2739   score: 5.0   memory length: 732663   epsilon: 0.009998020008555413    steps: 287    lr: 4.0960000000000023e-07     evaluation reward: 7.9\nepisode: 2740   score: 6.0   memory length: 732991   epsilon: 0.009998020008555413    steps: 328    lr: 4.0960000000000023e-07     evaluation reward: 7.86\nepisode: 2741   score: 7.0   memory length: 733398   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.89\nepisode: 2742   score: 7.0   memory length: 733805   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2743   score: 10.0   memory length: 734308   epsilon: 0.009998020008555413    steps: 503    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2744   score: 12.0   memory length: 734899   epsilon: 0.009998020008555413    steps: 591    lr: 4.0960000000000023e-07     evaluation reward: 7.91\nepisode: 2745   score: 7.0   memory length: 735256   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 7.91\nepisode: 2746   score: 7.0   memory length: 735644   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.93\nepisode: 2747   score: 7.0   memory length: 736031   epsilon: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     evaluation reward: 7.93\nepisode: 2748   score: 12.0   memory length: 736523   epsilon: 0.009998020008555413    steps: 492    lr: 4.0960000000000023e-07     evaluation reward: 8.01\nepisode: 2749   score: 8.0   memory length: 736909   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 8.02\nepisode: 2750   score: 8.0   memory length: 737364   epsilon: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     evaluation reward: 8.05\nepisode: 2751   score: 5.0   memory length: 737655   epsilon: 0.009998020008555413    steps: 291    lr: 4.0960000000000023e-07     evaluation reward: 8.05\nepisode: 2752   score: 11.0   memory length: 738060   epsilon: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     evaluation reward: 8.1\nepisode: 2753   score: 8.0   memory length: 738479   epsilon: 0.009998020008555413    steps: 419    lr: 4.0960000000000023e-07     evaluation reward: 8.08\nepisode: 2754   score: 10.0   memory length: 738871   epsilon: 0.009998020008555413    steps: 392    lr: 4.0960000000000023e-07     evaluation reward: 8.09\nepisode: 2755   score: 5.0   memory length: 739176   epsilon: 0.009998020008555413    steps: 305    lr: 4.0960000000000023e-07     evaluation reward: 8.1\nepisode: 2756   score: 11.0   memory length: 739717   epsilon: 0.009998020008555413    steps: 541    lr: 4.0960000000000023e-07     evaluation reward: 8.17\nepisode: 2757   score: 7.0   memory length: 740121   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 8.14\nepisode: 2758   score: 7.0   memory length: 740490   epsilon: 0.009998020008555413    steps: 369    lr: 4.0960000000000023e-07     evaluation reward: 8.11\nepisode: 2759   score: 7.0   memory length: 740897   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 8.08\nepisode: 2760   score: 6.0   memory length: 741236   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 8.04\nepisode: 2761   score: 7.0   memory length: 741593   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 8.06\nepisode: 2762   score: 6.0   memory length: 741952   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 7.96\nepisode: 2763   score: 8.0   memory length: 742391   epsilon: 0.009998020008555413    steps: 439    lr: 4.0960000000000023e-07     evaluation reward: 7.93\nepisode: 2764   score: 5.0   memory length: 742681   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.87\nepisode: 2765   score: 6.0   memory length: 743064   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 7.83\nepisode: 2766   score: 5.0   memory length: 743362   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 7.76\nepisode: 2767   score: 6.0   memory length: 743728   epsilon: 0.009998020008555413    steps: 366    lr: 4.0960000000000023e-07     evaluation reward: 7.74\nepisode: 2768   score: 4.0   memory length: 744028   epsilon: 0.009998020008555413    steps: 300    lr: 4.0960000000000023e-07     evaluation reward: 7.68\nepisode: 2769   score: 4.0   memory length: 744287   epsilon: 0.009998020008555413    steps: 259    lr: 4.0960000000000023e-07     evaluation reward: 7.64\nepisode: 2770   score: 6.0   memory length: 744628   epsilon: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     evaluation reward: 7.63\nepisode: 2771   score: 10.0   memory length: 745101   epsilon: 0.009998020008555413    steps: 473    lr: 4.0960000000000023e-07     evaluation reward: 7.65\nepisode: 2772   score: 13.0   memory length: 745580   epsilon: 0.009998020008555413    steps: 479    lr: 4.0960000000000023e-07     evaluation reward: 7.67\nepisode: 2773   score: 6.0   memory length: 745939   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 7.67\nepisode: 2774   score: 5.0   memory length: 746230   epsilon: 0.009998020008555413    steps: 291    lr: 4.0960000000000023e-07     evaluation reward: 7.64\nepisode: 2775   score: 5.0   memory length: 746520   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.61\nepisode: 2776   score: 6.0   memory length: 746861   epsilon: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     evaluation reward: 7.61\nepisode: 2777   score: 11.0   memory length: 747432   epsilon: 0.009998020008555413    steps: 571    lr: 4.0960000000000023e-07     evaluation reward: 7.65\nepisode: 2778   score: 5.0   memory length: 747720   epsilon: 0.009998020008555413    steps: 288    lr: 4.0960000000000023e-07     evaluation reward: 7.66\nepisode: 2779   score: 5.0   memory length: 748018   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 7.62\nepisode: 2780   score: 3.0   memory length: 748231   epsilon: 0.009998020008555413    steps: 213    lr: 4.0960000000000023e-07     evaluation reward: 7.58\nepisode: 2781   score: 5.0   memory length: 748521   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 7.57\nepisode: 2782   score: 7.0   memory length: 748931   epsilon: 0.009998020008555413    steps: 410    lr: 4.0960000000000023e-07     evaluation reward: 7.59\nepisode: 2783   score: 5.0   memory length: 749229   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 7.5\nepisode: 2784   score: 8.0   memory length: 749670   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 7.44\nepisode: 2785   score: 6.0   memory length: 750008   epsilon: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     evaluation reward: 7.4\nepisode: 2786   score: 10.0   memory length: 750404   epsilon: 0.009998020008555413    steps: 396    lr: 4.0960000000000023e-07     evaluation reward: 7.44\nepisode: 2787   score: 5.0   memory length: 750702   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 7.44\nepisode: 2788   score: 9.0   memory length: 751230   epsilon: 0.009998020008555413    steps: 528    lr: 4.0960000000000023e-07     evaluation reward: 7.45\nepisode: 2789   score: 8.0   memory length: 751690   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 7.46\nepisode: 2790   score: 11.0   memory length: 752226   epsilon: 0.009998020008555413    steps: 536    lr: 4.0960000000000023e-07     evaluation reward: 7.51\nepisode: 2791   score: 6.0   memory length: 752546   epsilon: 0.009998020008555413    steps: 320    lr: 4.0960000000000023e-07     evaluation reward: 7.41\nepisode: 2792   score: 7.0   memory length: 752953   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.39\nepisode: 2793   score: 11.0   memory length: 753516   epsilon: 0.009998020008555413    steps: 563    lr: 4.0960000000000023e-07     evaluation reward: 7.46\nepisode: 2794   score: 10.0   memory length: 754039   epsilon: 0.009998020008555413    steps: 523    lr: 4.0960000000000023e-07     evaluation reward: 7.44\nepisode: 2795   score: 10.0   memory length: 754529   epsilon: 0.009998020008555413    steps: 490    lr: 4.0960000000000023e-07     evaluation reward: 7.45\nepisode: 2796   score: 5.0   memory length: 754817   epsilon: 0.009998020008555413    steps: 288    lr: 4.0960000000000023e-07     evaluation reward: 7.46\nepisode: 2797   score: 7.0   memory length: 755161   epsilon: 0.009998020008555413    steps: 344    lr: 4.0960000000000023e-07     evaluation reward: 7.45\nepisode: 2798   score: 7.0   memory length: 755568   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.44\nepisode: 2799   score: 8.0   memory length: 755955   epsilon: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     evaluation reward: 7.46\nepisode: 2800   score: 7.0   memory length: 756358   epsilon: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     evaluation reward: 7.37\nepisode: 2801   score: 9.0   memory length: 756701   epsilon: 0.009998020008555413    steps: 343    lr: 4.0960000000000023e-07     evaluation reward: 7.36\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualize Agent Performance","metadata":{}},{"cell_type":"markdown","source":"BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n\nPlease save your model before running this portion of the code.","metadata":{}},{"cell_type":"code","source":"torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:26:41.373412Z","iopub.execute_input":"2024-05-01T17:26:41.373979Z","iopub.status.idle":"2024-05-01T17:26:41.406784Z","shell.execute_reply.started":"2024-05-01T17:26:41.373927Z","shell.execute_reply":"2024-05-01T17:26:41.404811Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:31:46.423259Z","iopub.execute_input":"2024-05-01T17:31:46.423640Z","iopub.status.idle":"2024-05-01T17:32:13.540065Z","shell.execute_reply.started":"2024-05-01T17:31:46.423609Z","shell.execute_reply":"2024-05-01T17:32:13.538953Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting moviepy\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.33.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\nRequirement already satisfied: setuptools in /root/.local/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (69.5.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\nDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=ad6e5994900e8514d6dac71abbe6e4e3251f15b8e35d9d26f2a08e4d4df60c54\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\nSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport gym\nimport torch\nimport pylab\nimport random\nimport numpy as np\nfrom collections import deque\nfrom datetime import datetime\nfrom copy import deepcopy\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.tensorboard import SummaryWriter\nfrom utils import find_max_lives, check_live, get_frame, get_init_state\nfrom model import DQN, DQN_LSTM\nfrom config import *\n\nimport matplotlib.pyplot as plt\n# %load_ext autoreload\n# %autoreload 2\n\nfrom gym.wrappers import RecordVideo # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\nimport glob\nimport io\nimport base64\n\nfrom IPython.display import HTML\nfrom IPython import display as ipythondisplay\n\nfrom pyvirtualdisplay import Display\n\nenv = gym.make('BreakoutDeterministic-v4', render_mode='rgb_array')\nstate = env.reset()\nnumber_lives = find_max_lives(env)\nstate_size = env.observation_space.shape\naction_size = 3 #fire, left, and right\n\n# Displaying the game live\ndef show_state(env, step=0, info=\"\"):\n    plt.figure(3)\n    plt.clf()\n    plt.imshow(env.render(mode='rgb_array'))\n    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n    plt.axis('off')\n\n    ipythondisplay.clear_output(wait=True)\n    ipythondisplay.display(plt.gcf())\n    \n# Recording the game and replaying the game afterwards\ndef show_video():\n    mp4list = glob.glob('video/*.mp4')\n    if len(mp4list) > 0:\n        mp4 = mp4list[0]\n        video = io.open(mp4, 'r+b').read()\n        encoded = base64.b64encode(video)\n        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n             </video>'''.format(encoded.decode('ascii'))))\n    else: \n        print(\"Could not find video\")\n    \n\ndef wrap_env(env):\n    env = RecordVideo(env, './video')\n    return env","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:35:37.112835Z","iopub.execute_input":"2024-05-01T17:35:37.113181Z","iopub.status.idle":"2024-05-01T17:35:54.316072Z","shell.execute_reply.started":"2024-05-01T17:35:37.113152Z","shell.execute_reply":"2024-05-01T17:35:54.314692Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-01 17:35:43.653019: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-01 17:35:43.653130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-01 17:35:43.790238: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_max_lives, check_live, get_frame, get_init_state\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQN, DQN_LSTM\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"],"ename":"ModuleNotFoundError","evalue":"No module named 'utils'","output_type":"error"}]},{"cell_type":"code","source":"from agent import Agent\naction_size = 3 \n\ndisplay = Display(visible=0, size=(300, 200))\ndisplay.start()\n\n# Load agent\nagent = Agent(action_size)\nagent.load_policy_net(\"./save_model/breakout_dqn.pth\")\nagent.epsilon = 0.0 # Set agent to only exploit the best action\n\nenv = wrap_env(env)\n\ndone = False\nscore = 0\nstep = 0\nstate, _ = env.reset()\nnext_state = state\nlife = number_lives\nhistory = np.zeros([5, 84, 84], dtype=np.uint8)\nget_init_state(history, state, HISTORY_SIZE)\nframe = 0\nwhile not done:\n#     show_state(env,step) # uncommenting this provides another way to visualize the game\n    step += 1\n    frame += 1\n\n    # Perform a fire action if ball is no longer on screen\n    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n        action = 0\n    else:\n        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n    state = next_state\n    \n    next_state, reward, done, _, info = env.step(action + 1)\n        \n    frame_next_state = get_frame(next_state)\n    history[4, :, :] = frame_next_state\n    terminal_state = check_live(life, info['lives'])\n        \n    life = info['lives']\n    r = np.clip(reward, -1, 1) \n    r = reward\n\n    # Store the transition in memory \n    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n    # Start training after random sample generation\n    score += reward\n    \n    history[:4, :, :] = history[1:, :, :]\nenv.close()\nshow_video()\ndisplay.stop()","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:35:54.316896Z","iopub.status.idle":"2024-05-01T17:35:54.317255Z","shell.execute_reply.started":"2024-05-01T17:35:54.317070Z","shell.execute_reply":"2024-05-01T17:35:54.317083Z"},"trusted":true},"execution_count":null,"outputs":[]}]}